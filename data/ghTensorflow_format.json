{
    "Data Name": "Github Data for Tensorflow",
    "Creation Date": "2015-11-07T01:19:20Z",
    "Data Range Start": "2015-11-09T14:21:11Z",
    "Data Range End": "2022-11-22T16:10:10Z",
    "Version Information": 1.0,
    "Provenance Information": "Utlizes data/gh_Issues.json, data/gh_Pulls.json and dynamic requests to the Github API",
    "Predicted Symbols": [
        "tbd"
    ],
    "Prediction Period": "tbd",
    "Entities": [
        {
            "Id": 657617,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-22T16:10:10Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T16:10:39Z",
                    "Valid To": "2022-11-22T16:10:39Z"
                },
                {
                    "Contribution Type": "Pull Request",
                    "Valid From": "2022-11-22T16:10:10Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2011-03-08T12:22:53Z",
                    "Valid To": "2022-11-17T01:30:34Z"
                }
            ]
        },
        {
            "Id": 323199,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T17:17:08Z",
                    "Valid To": "2022-11-22T17:17:08Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2010-07-05T11:26:31Z",
                    "Valid To": "2022-11-30T16:29:27Z"
                }
            ]
        },
        {
            "Id": 1710528,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-22T13:41:46Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T13:43:52Z",
                    "Valid To": "2022-11-22T13:43:52Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2012-05-06T12:17:54Z",
                    "Valid To": "2022-11-23T20:55:11Z"
                }
            ]
        },
        {
            "Id": 75139937,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-22T13:14:42Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-23T16:18:15Z",
                    "Valid To": "2022-11-23T16:18:15Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-23T19:19:58Z",
                    "Valid To": "2022-11-23T19:21:33Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-24T19:05:18Z",
                    "Valid To": "2022-11-24T19:05:18Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2020-11-27T18:56:06Z",
                    "Valid To": "2022-11-23T16:16:38Z"
                }
            ]
        },
        {
            "Id": 45509728,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-23T03:50:24Z",
                    "Valid To": "2022-11-23T03:50:24Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2018-12-01T09:24:38Z",
                    "Valid To": "2022-11-14T14:46:44Z"
                }
            ]
        },
        {
            "Id": 111861663,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-23T16:53:25Z",
                    "Valid To": "2022-11-23T16:53:25Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-08-23T09:11:26Z",
                    "Valid To": "2022-10-21T09:42:57Z"
                }
            ]
        },
        {
            "Id": 45509728,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-23T21:53:04Z",
                    "Valid To": "2022-11-23T21:53:04Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2018-12-01T09:24:38Z",
                    "Valid To": "2022-11-14T14:46:44Z"
                }
            ]
        },
        {
            "Id": 111861663,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-25T02:33:00Z",
                    "Valid To": "2022-11-25T02:33:00Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-08-23T09:11:26Z",
                    "Valid To": "2022-10-21T09:42:57Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-25T08:27:28Z",
                    "Valid To": "2022-11-25T08:27:28Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 55463253,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T23:41:29Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T16:08:14Z",
                    "Valid To": "2022-11-22T16:11:20Z"
                },
                {
                    "Contribution Type": "Pull Request",
                    "Valid From": "2022-11-21T23:41:29Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2019-09-17T20:24:33Z",
                    "Valid To": "2022-12-05T21:43:46Z"
                }
            ]
        },
        {
            "Id": 19536781,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T23:41:06Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-27T07:16:16Z",
                    "Valid To": "2022-11-27T19:55:13Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-27T19:59:31Z",
                    "Valid To": "2022-11-27T20:00:35Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-28T23:33:50Z",
                    "Valid To": "2022-11-28T23:33:50Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2016-05-23T17:05:35Z",
                    "Valid To": "2022-06-17T16:40:30Z"
                }
            ]
        },
        {
            "Id": 8497170,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-23T00:28:23Z",
                    "Valid To": "2022-11-23T00:28:23Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2014-08-19T23:57:50Z",
                    "Valid To": "2022-12-01T00:03:31Z"
                }
            ]
        },
        {
            "Id": 84765720,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-26T03:53:44Z",
                    "Valid To": "2022-11-26T03:53:44Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-05-25T06:43:50Z",
                    "Valid To": "2022-11-22T11:35:04Z"
                }
            ]
        },
        {
            "Id": 8497170,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-28T17:59:39Z",
                    "Valid To": "2022-11-28T18:04:44Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2014-08-19T23:57:50Z",
                    "Valid To": "2022-12-01T00:03:31Z"
                }
            ]
        },
        {
            "Id": 8497170,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-28T23:36:20Z",
                    "Valid To": "2022-11-28T23:36:20Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2014-08-19T23:57:50Z",
                    "Valid To": "2022-12-01T00:03:31Z"
                }
            ]
        },
        {
            "Id": 38714576,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T23:17:42Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T00:25:31Z",
                    "Valid To": "2022-11-22T00:25:31Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-25T04:43:01Z",
                    "Valid To": "2022-11-25T04:47:33Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2018-04-25T05:53:01Z",
                    "Valid To": "2022-11-21T23:24:12Z"
                }
            ]
        },
        {
            "Id": 81610181,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T12:54:34Z",
                    "Valid To": "2022-11-22T12:54:34Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-03-30T06:09:15Z",
                    "Valid To": "2022-11-05T23:12:28Z"
                }
            ]
        },
        {
            "Id": 29215195,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T22:35:25Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Request",
                    "Valid From": "2022-11-21T22:35:25Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2017-06-05T23:20:45Z",
                    "Valid To": "2022-10-24T17:00:08Z"
                }
            ]
        },
        {
            "Id": 118690585,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T22:09:56Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Request",
                    "Valid From": "2022-11-21T22:09:56Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-11-20T20:06:49Z",
                    "Valid To": "2022-11-28T22:40:09Z"
                }
            ]
        },
        {
            "Id": 48215717,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-23T09:14:09Z",
                    "Valid To": "2022-11-23T09:14:09Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Average Followers",
                    "Committer Type": null,
                    "Valid From": "2019-03-04T15:21:55Z",
                    "Valid To": "2022-12-05T08:21:48Z"
                }
            ]
        },
        {
            "Id": 26332583,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T20:58:44Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-28T04:10:11Z",
                    "Valid To": "2022-11-28T04:10:11Z"
                },
                {
                    "Contribution Type": "Pull Request",
                    "Valid From": "2022-11-21T20:58:44Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2017-03-10T18:34:15Z",
                    "Valid To": "2022-11-21T21:01:57Z"
                }
            ]
        },
        {
            "Id": 55858104,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T20:58:47Z",
                    "Valid To": "2022-11-21T20:58:47Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-09-26T21:40:56Z",
                    "Valid To": "2019-09-26T21:40:56Z"
                }
            ]
        },
        {
            "Id": 6442822,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T19:40:05Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Request",
                    "Valid From": "2022-11-21T19:40:05Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2014-01-19T12:31:04Z",
                    "Valid To": "2022-12-06T22:12:08Z"
                }
            ]
        },
        {
            "Id": 67419721,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T18:37:33Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T00:25:25Z",
                    "Valid To": "2022-11-22T00:26:24Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2020-06-25T11:49:21Z",
                    "Valid To": "2022-08-09T12:24:43Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-23T06:31:02Z",
                    "Valid To": "2022-11-23T06:31:02Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 105635332,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T16:47:45Z",
                    "Valid To": "2022-11-22T17:50:03Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T18:26:55Z",
                    "Valid To": "2022-11-22T02:41:06Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T17:49:17Z",
                    "Valid To": "2022-11-22T17:49:17Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-05-16T08:55:57Z",
                    "Valid To": "2022-11-22T07:45:41Z"
                }
            ]
        },
        {
            "Id": 111861663,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T18:06:48Z",
                    "Valid To": "2022-11-21T18:06:48Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-08-23T09:11:26Z",
                    "Valid To": "2022-10-21T09:42:57Z"
                }
            ]
        },
        {
            "Id": 74714236,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T14:03:03Z",
                    "Valid To": "2022-11-22T09:41:03Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T14:14:02Z",
                    "Valid To": "2022-11-21T14:14:02Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T14:22:32Z",
                    "Valid To": "2022-11-21T14:22:32Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T09:41:03Z",
                    "Valid To": "2022-11-22T09:41:03Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2020-11-19T11:33:34Z",
                    "Valid To": "2022-11-27T17:43:42Z"
                }
            ]
        },
        {
            "Id": 81610181,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T07:56:54Z",
                    "Valid To": "2022-11-22T07:56:54Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-03-30T06:09:15Z",
                    "Valid To": "2022-11-05T23:12:28Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T09:41:05Z",
                    "Valid To": "2022-11-22T09:41:05Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T09:42:03Z",
                    "Valid To": "2022-11-22T09:42:03Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 96806369,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T12:00:10Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2021-12-29T03:19:39Z",
                    "Valid To": "2022-11-28T12:07:38Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T01:19:06Z",
                    "Valid To": "2022-11-22T03:28:55Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-29T04:16:19Z",
                    "Valid To": "2022-11-29T04:16:19Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-06T05:16:20Z",
                    "Valid To": "2022-12-06T05:16:20Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-06T05:16:23Z",
                    "Valid To": "2022-12-06T05:16:23Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 913790,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T11:20:11Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Request",
                    "Valid From": "2022-11-21T11:20:11Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2011-07-13T22:26:34Z",
                    "Valid To": "2022-12-05T22:14:20Z"
                }
            ]
        },
        {
            "Id": 92745698,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T10:13:28Z",
                    "Valid To": "2022-11-21T10:33:29Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-10-18T16:30:39Z",
                    "Valid To": "2022-11-30T11:03:07Z"
                }
            ]
        },
        {
            "Id": 24700291,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T09:40:36Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Average Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2016-12-21T15:16:00Z",
                    "Valid To": "2022-12-06T11:18:59Z"
                }
            ]
        },
        {
            "Id": 81610181,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T07:54:36Z",
                    "Valid To": "2022-11-22T07:54:36Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-03-30T06:09:15Z",
                    "Valid To": "2022-11-05T23:12:28Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-29T08:16:19Z",
                    "Valid To": "2022-11-29T08:16:19Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-06T08:16:25Z",
                    "Valid To": "2022-12-06T08:16:25Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-06T08:16:31Z",
                    "Valid To": "2022-12-06T08:16:31Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 44562106,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T09:31:58Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-23T19:12:56Z",
                    "Valid To": "2022-11-23T19:54:57Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-25T09:14:40Z",
                    "Valid To": "2022-11-25T09:14:40Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-28T16:46:35Z",
                    "Valid To": "2022-11-28T16:46:35Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2018-10-29T04:17:10Z",
                    "Valid To": "2022-10-29T14:07:54Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T10:22:42Z",
                    "Valid To": "2022-11-24T06:10:07Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-24T03:40:27Z",
                    "Valid To": "2022-11-30T06:42:55Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-28T05:41:32Z",
                    "Valid To": "2022-11-28T05:43:05Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 116063290,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-28T07:44:49Z",
                    "Valid To": "2022-11-28T07:44:49Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-10-18T07:24:20Z",
                    "Valid To": "2022-12-06T10:18:07Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-28T16:46:40Z",
                    "Valid To": "2022-11-28T16:46:40Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 57779173,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T06:35:21Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T19:42:22Z",
                    "Valid To": "2022-11-21T19:42:22Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-24T07:03:29Z",
                    "Valid To": "2022-11-24T07:03:29Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-24T19:26:46Z",
                    "Valid To": "2022-11-24T19:26:46Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-25T18:17:15Z",
                    "Valid To": "2022-11-25T18:17:15Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2019-11-15T01:01:23Z",
                    "Valid To": "2022-11-22T00:47:37Z"
                }
            ]
        },
        {
            "Id": 111861663,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T17:52:51Z",
                    "Valid To": "2022-11-21T17:52:51Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-08-23T09:11:26Z",
                    "Valid To": "2022-10-21T09:42:57Z"
                }
            ]
        },
        {
            "Id": 111861663,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-23T17:15:02Z",
                    "Valid To": "2022-11-23T17:15:02Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-08-23T09:11:26Z",
                    "Valid To": "2022-10-21T09:42:57Z"
                }
            ]
        },
        {
            "Id": 116063290,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-24T11:31:06Z",
                    "Valid To": "2022-11-24T11:31:26Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-10-18T07:24:20Z",
                    "Valid To": "2022-12-06T10:18:07Z"
                }
            ]
        },
        {
            "Id": 116063290,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-25T07:45:24Z",
                    "Valid To": "2022-11-28T03:10:29Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-10-18T07:24:20Z",
                    "Valid To": "2022-12-06T10:18:07Z"
                }
            ]
        },
        {
            "Id": 116063290,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-28T03:44:44Z",
                    "Valid To": "2022-11-28T03:44:44Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-10-18T07:24:20Z",
                    "Valid To": "2022-12-06T10:18:07Z"
                }
            ]
        },
        {
            "Id": 100826172,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T05:30:01Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T05:35:42Z",
                    "Valid To": "2022-11-21T05:35:42Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-03-03T06:06:55Z",
                    "Valid To": "2022-11-21T05:29:54Z"
                }
            ]
        },
        {
            "Id": 81610181,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T14:31:01Z",
                    "Valid To": "2022-11-21T14:31:01Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-03-30T06:09:15Z",
                    "Valid To": "2022-11-05T23:12:28Z"
                }
            ]
        },
        {
            "Id": 81610181,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T14:32:00Z",
                    "Valid To": "2022-11-21T14:32:00Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-03-30T06:09:15Z",
                    "Valid To": "2022-11-05T23:12:28Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-28T15:16:19Z",
                    "Valid To": "2022-11-28T15:16:19Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-05T16:16:20Z",
                    "Valid To": "2022-12-05T16:16:20Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-05T16:16:23Z",
                    "Valid To": "2022-12-05T16:16:23Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 15100009,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T00:36:18Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T00:39:01Z",
                    "Valid To": "2022-11-21T00:39:01Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-27T07:06:07Z",
                    "Valid To": "2022-11-27T07:06:28Z"
                },
                {
                    "Contribution Type": "Pull Request",
                    "Valid From": "2022-11-21T00:36:18Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2015-10-13T04:29:58Z",
                    "Valid To": "2022-12-01T03:36:21Z"
                }
            ]
        },
        {
            "Id": 48215717,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-26T05:48:25Z",
                    "Valid To": "2022-11-26T05:48:25Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Average Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2019-03-04T15:21:55Z",
                    "Valid To": "2022-12-05T08:21:48Z"
                }
            ]
        },
        {
            "Id": 15100009,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-21T00:19:21Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T00:38:49Z",
                    "Valid To": "2022-11-21T00:38:49Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-27T07:05:45Z",
                    "Valid To": "2022-11-27T07:05:45Z"
                },
                {
                    "Contribution Type": "Pull Request",
                    "Valid From": "2022-11-21T00:19:21Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": null,
                    "Valid From": "2015-10-13T04:29:58Z",
                    "Valid To": "2022-12-01T03:36:21Z"
                }
            ]
        },
        {
            "Id": 2053858,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-20T18:44:28Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T22:41:26Z",
                    "Valid To": "2022-11-21T22:41:26Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-24T15:20:35Z",
                    "Valid To": "2022-11-24T15:20:35Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-04T20:33:15Z",
                    "Valid To": "2022-12-04T20:33:15Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Average Followers",
                    "Committer Type": null,
                    "Valid From": "2012-07-27T20:00:15Z",
                    "Valid To": "2022-11-20T18:20:32Z"
                }
            ]
        },
        {
            "Id": 17670772,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T06:27:01Z",
                    "Valid To": "2022-11-21T06:27:01Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2016-03-05T10:16:39Z",
                    "Valid To": "2022-10-20T13:31:02Z"
                }
            ]
        },
        {
            "Id": 81610181,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T14:25:00Z",
                    "Valid To": "2022-11-21T14:25:00Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2021-03-30T06:09:15Z",
                    "Valid To": "2022-11-05T23:12:28Z"
                }
            ]
        },
        {
            "Id": 17670772,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T07:07:48Z",
                    "Valid To": "2022-11-22T07:07:48Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2016-03-05T10:16:39Z",
                    "Valid To": "2022-10-20T13:31:02Z"
                }
            ]
        },
        {
            "Id": 81610181,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-28T13:36:36Z",
                    "Valid To": "2022-11-28T13:36:36Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2021-03-30T06:09:15Z",
                    "Valid To": "2022-11-05T23:12:28Z"
                }
            ]
        },
        {
            "Id": 38817737,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-20T16:15:50Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T05:09:53Z",
                    "Valid To": "2022-11-21T05:09:53Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-26T08:06:44Z",
                    "Valid To": "2022-11-26T08:06:44Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-28T13:09:37Z",
                    "Valid To": "2022-11-28T13:09:37Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-01T02:00:44Z",
                    "Valid To": "2022-12-01T02:00:44Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2018-04-28T18:49:19Z",
                    "Valid To": "2022-10-15T07:50:02Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T03:30:32Z",
                    "Valid To": "2022-11-22T03:30:32Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 67798621,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-25T10:36:34Z",
                    "Valid To": "2022-11-25T10:36:34Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2020-07-03T16:14:42Z",
                    "Valid To": "2022-11-23T10:43:12Z"
                }
            ]
        },
        {
            "Id": 67798621,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-28T12:32:23Z",
                    "Valid To": "2022-11-28T12:32:23Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2020-07-03T16:14:42Z",
                    "Valid To": "2022-11-23T10:43:12Z"
                }
            ]
        },
        {
            "Id": 73069040,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-29T20:09:59Z",
                    "Valid To": "2022-11-29T20:09:59Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2020-10-18T14:47:17Z",
                    "Valid To": "2022-11-10T23:29:26Z"
                }
            ]
        },
        {
            "Id": 26105224,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-20T15:45:02Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T11:11:11Z",
                    "Valid To": "2022-11-22T11:11:11Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-24T07:05:23Z",
                    "Valid To": "2022-11-24T07:06:25Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2017-03-01T05:21:02Z",
                    "Valid To": "2022-11-21T11:56:43Z"
                }
            ]
        },
        {
            "Id": 111861663,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T17:58:55Z",
                    "Valid To": "2022-11-21T17:58:55Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-08-23T09:11:26Z",
                    "Valid To": "2022-10-21T09:42:57Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-24T04:15:12Z",
                    "Valid To": "2022-11-24T04:15:12Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 17670772,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-20T13:16:10Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-25T13:11:54Z",
                    "Valid To": "2022-11-25T13:11:54Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2016-03-05T10:16:39Z",
                    "Valid To": "2022-10-20T13:31:02Z"
                }
            ]
        },
        {
            "Id": 81610181,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T11:19:43Z",
                    "Valid To": "2022-11-21T11:19:43Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-03-30T06:09:15Z",
                    "Valid To": "2022-11-05T23:12:28Z"
                }
            ]
        },
        {
            "Id": 81610181,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-28T13:39:22Z",
                    "Valid To": "2022-11-28T13:39:22Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-03-30T06:09:15Z",
                    "Valid To": "2022-11-05T23:12:28Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-05T14:16:19Z",
                    "Valid To": "2022-12-05T14:16:19Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 22030060,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-20T03:29:04Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2016-09-06T14:07:30Z",
                    "Valid To": "2022-09-21T02:06:47Z"
                }
            ]
        },
        {
            "Id": 95025816,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-20T08:31:04Z",
                    "Valid To": "2022-11-20T08:31:04Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-11-25T10:30:17Z",
                    "Valid To": "2022-11-20T08:46:13Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T04:36:11Z",
                    "Valid To": "2022-11-21T12:14:50Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-28T12:16:19Z",
                    "Valid To": "2022-11-28T12:16:19Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-05T13:16:23Z",
                    "Valid To": "2022-12-05T13:16:23Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-05T13:16:27Z",
                    "Valid To": "2022-12-05T13:16:27Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 53497039,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-19T16:34:26Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Average Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2019-07-30T22:20:52Z",
                    "Valid To": "2022-11-23T00:00:20Z"
                }
            ]
        },
        {
            "Id": 111861663,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T17:17:53Z",
                    "Valid To": "2022-11-21T17:17:53Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-08-23T09:11:26Z",
                    "Valid To": "2022-10-21T09:42:57Z"
                }
            ]
        },
        {
            "Id": 2458806,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-19T16:28:39Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-19T16:52:10Z",
                    "Valid To": "2022-11-19T17:14:20Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T21:20:34Z",
                    "Valid To": "2022-11-21T21:20:34Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T21:27:32Z",
                    "Valid To": "2022-11-21T21:27:32Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-24T15:40:37Z",
                    "Valid To": "2022-11-24T15:40:37Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Average Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2012-09-30T19:43:51Z",
                    "Valid To": "2022-11-19T16:19:31Z"
                }
            ]
        },
        {
            "Id": 81610181,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T07:58:43Z",
                    "Valid To": "2022-11-21T07:58:43Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-03-30T06:09:15Z",
                    "Valid To": "2022-11-05T23:12:28Z"
                }
            ]
        },
        {
            "Id": 116063290,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-24T15:27:30Z",
                    "Valid To": "2022-11-24T15:27:30Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-10-18T07:24:20Z",
                    "Valid To": "2022-12-06T10:18:07Z"
                }
            ]
        },
        {
            "Id": 33950866,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-19T12:53:43Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-25T02:57:13Z",
                    "Valid To": "2022-11-25T02:57:13Z"
                },
                {
                    "Contribution Type": "Pull Request",
                    "Valid From": "2022-11-19T12:53:43Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2017-11-24T07:15:21Z",
                    "Valid To": "2022-04-06T01:58:36Z"
                }
            ]
        },
        {
            "Id": 48215717,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-24T23:24:03Z",
                    "Valid To": "2022-11-24T23:24:03Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Average Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2019-03-04T15:21:55Z",
                    "Valid To": "2022-12-05T08:21:48Z"
                }
            ]
        },
        {
            "Id": 33950866,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-19T12:36:22Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2017-11-24T07:15:21Z",
                    "Valid To": "2022-04-06T01:58:36Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T03:46:41Z",
                    "Valid To": "2022-11-22T09:17:29Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T09:17:52Z",
                    "Valid To": "2022-11-22T09:17:52Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 42224728,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-19T06:09:14Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Request",
                    "Valid From": "2022-11-19T06:09:14Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2018-08-09T00:36:38Z",
                    "Valid To": "2022-06-29T17:55:37Z"
                }
            ]
        },
        {
            "Id": 59843233,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-18T16:08:12Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-23T08:04:02Z",
                    "Valid To": "2022-11-23T08:04:30Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-24T08:38:45Z",
                    "Valid To": "2022-11-24T08:51:45Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2020-01-13T18:29:24Z",
                    "Valid To": "2022-11-18T14:19:38Z"
                }
            ]
        },
        {
            "Id": 111861663,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T16:41:24Z",
                    "Valid To": "2022-11-21T16:41:24Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-08-23T09:11:26Z",
                    "Valid To": "2022-10-21T09:42:57Z"
                }
            ]
        },
        {
            "Id": 111861663,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-23T17:01:08Z",
                    "Valid To": "2022-11-23T17:01:08Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-08-23T09:11:26Z",
                    "Valid To": "2022-10-21T09:42:57Z"
                }
            ]
        },
        {
            "Id": 111861663,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-28T06:11:11Z",
                    "Valid To": "2022-11-28T06:11:11Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-08-23T09:11:26Z",
                    "Valid To": "2022-10-21T09:42:57Z"
                }
            ]
        },
        {
            "Id": 14215174,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-18T15:42:56Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2015-09-10T09:26:48Z",
                    "Valid To": "2022-03-15T13:36:14Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T08:56:58Z",
                    "Valid To": "2022-11-21T08:56:58Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 15980055,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-18T15:07:02Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-18T17:12:24Z",
                    "Valid To": "2022-11-18T17:12:24Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2015-11-23T11:45:40Z",
                    "Valid To": "2022-11-18T17:08:28Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T04:11:58Z",
                    "Valid To": "2022-11-21T07:15:37Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-28T07:16:19Z",
                    "Valid To": "2022-11-28T07:16:19Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 19637339,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-30T22:33:50Z",
                    "Valid To": "2022-11-30T22:33:50Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2016-05-29T18:05:08Z",
                    "Valid To": "2022-12-05T13:56:56Z"
                }
            ]
        },
        {
            "Id": 19637339,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-30T23:44:34Z",
                    "Valid To": "2022-11-30T23:44:34Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2016-05-29T18:05:08Z",
                    "Valid To": "2022-12-05T13:56:56Z"
                }
            ]
        },
        {
            "Id": 67419721,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-18T13:38:41Z",
                    "Valid To": "2022-11-21T18:40:40Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T18:40:39Z",
                    "Valid To": "2022-11-21T18:40:39Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2020-06-25T11:49:21Z",
                    "Valid To": "2022-08-09T12:24:43Z"
                }
            ]
        },
        {
            "Id": 105795148,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-19T12:29:34Z",
                    "Valid To": "2022-11-19T12:29:34Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-05-18T12:58:42Z",
                    "Valid To": "2022-11-22T03:59:08Z"
                }
            ]
        },
        {
            "Id": 111861663,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T16:34:51Z",
                    "Valid To": "2022-11-21T16:34:51Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-08-23T09:11:26Z",
                    "Valid To": "2022-10-21T09:42:57Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T18:40:41Z",
                    "Valid To": "2022-11-21T18:40:41Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 95025816,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-18T12:10:40Z",
                    "Valid To": "2022-11-20T08:32:53Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-18T22:35:53Z",
                    "Valid To": "2022-11-18T22:35:53Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-19T01:20:52Z",
                    "Valid To": "2022-11-19T01:20:52Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-19T05:06:31Z",
                    "Valid To": "2022-11-19T05:06:31Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-19T12:10:16Z",
                    "Valid To": "2022-11-19T12:10:16Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-19T12:22:50Z",
                    "Valid To": "2022-11-19T12:22:50Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-19T12:24:24Z",
                    "Valid To": "2022-11-19T12:24:24Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-20T08:32:50Z",
                    "Valid To": "2022-11-20T08:32:50Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-11-25T10:30:17Z",
                    "Valid To": "2022-11-20T08:46:13Z"
                }
            ]
        },
        {
            "Id": 116063290,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-18T13:19:21Z",
                    "Valid To": "2022-11-18T13:19:21Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-10-18T07:24:20Z",
                    "Valid To": "2022-12-06T10:18:07Z"
                }
            ]
        },
        {
            "Id": 116063290,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-19T04:10:50Z",
                    "Valid To": "2022-11-19T04:10:50Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-10-18T07:24:20Z",
                    "Valid To": "2022-12-06T10:18:07Z"
                }
            ]
        },
        {
            "Id": 116063290,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-19T11:28:38Z",
                    "Valid To": "2022-11-19T11:28:38Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-10-18T07:24:20Z",
                    "Valid To": "2022-12-06T10:18:07Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-20T08:32:54Z",
                    "Valid To": "2022-11-20T08:32:54Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 87115287,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-18T08:48:08Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2021-07-08T06:59:57Z",
                    "Valid To": "2022-11-22T04:11:06Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-19T01:33:38Z",
                    "Valid To": "2022-11-19T01:33:38Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 12981474,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-18T00:23:19Z",
                    "Valid To": "2022-11-18T09:05:26Z"
                },
                {
                    "Contribution Type": "Pull Request",
                    "Valid From": "2022-11-18T00:23:19Z",
                    "Valid To": "2022-11-18T09:05:26Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2015-06-20T19:52:02Z",
                    "Valid To": "2022-11-01T18:38:04Z"
                }
            ]
        },
        {
            "Id": null,
            "Symbols": [
                {
                    "Contribution Type": "Pull Merger",
                    "Valid From": "2022-11-18T09:05:26Z",
                    "Valid To": "2022-11-18T09:05:26Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2019-10-18T20:47:54Z",
                    "Valid To": "2019-10-18T20:47:54Z"
                }
            ]
        },
        {
            "Id": 38138022,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-17T16:31:00Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-17T17:15:09Z",
                    "Valid To": "2022-11-17T17:15:09Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T12:08:00Z",
                    "Valid To": "2022-11-22T12:08:00Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T12:09:00Z",
                    "Valid To": "2022-11-22T12:09:00Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-23T23:39:21Z",
                    "Valid To": "2022-11-23T23:39:21Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2018-04-06T15:51:35Z",
                    "Valid To": "2022-07-28T16:56:20Z"
                }
            ]
        },
        {
            "Id": 111861663,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T02:37:45Z",
                    "Valid To": "2022-11-21T02:37:45Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-08-23T09:11:26Z",
                    "Valid To": "2022-10-21T09:42:57Z"
                }
            ]
        },
        {
            "Id": 111861663,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-23T10:12:40Z",
                    "Valid To": "2022-11-23T10:12:40Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-08-23T09:11:26Z",
                    "Valid To": "2022-10-21T09:42:57Z"
                }
            ]
        },
        {
            "Id": 111861663,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-24T09:01:19Z",
                    "Valid To": "2022-11-24T09:01:19Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-08-23T09:11:26Z",
                    "Valid To": "2022-10-21T09:42:57Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-01T09:16:19Z",
                    "Valid To": "2022-12-01T09:16:19Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 61427290,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-17T10:17:39Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T21:19:54Z",
                    "Valid To": "2022-11-21T21:19:54Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2020-02-24T17:14:57Z",
                    "Valid To": "2022-12-03T17:29:34Z"
                }
            ]
        },
        {
            "Id": 116063290,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T08:10:55Z",
                    "Valid To": "2022-11-21T08:10:55Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-10-18T07:24:20Z",
                    "Valid To": "2022-12-06T10:18:07Z"
                }
            ]
        },
        {
            "Id": 116063290,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T16:18:31Z",
                    "Valid To": "2022-11-21T16:19:33Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-10-18T07:24:20Z",
                    "Valid To": "2022-12-06T10:18:07Z"
                }
            ]
        },
        {
            "Id": 116063290,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-29T13:28:36Z",
                    "Valid To": "2022-11-29T13:28:36Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-10-18T07:24:20Z",
                    "Valid To": "2022-12-06T10:18:07Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-17T08:54:58Z",
                    "Valid To": "2022-11-17T12:21:58Z"
                },
                {
                    "Contribution Type": "Pull Request",
                    "Valid From": "2022-11-17T08:54:58Z",
                    "Valid To": "2022-11-17T12:21:58Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 20158647,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-16T18:19:09Z",
                    "Valid To": "2022-11-16T19:27:58Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2016-06-27T02:02:32Z",
                    "Valid To": "2022-09-29T14:50:26Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-17T04:06:13Z",
                    "Valid To": "2022-11-17T04:06:13Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T08:44:20Z",
                    "Valid To": "2022-11-21T08:44:20Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 25738889,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-16T18:11:12Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2017-02-13T09:01:51Z",
                    "Valid To": "2022-02-17T14:37:15Z"
                }
            ]
        },
        {
            "Id": 111861663,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-17T10:55:25Z",
                    "Valid To": "2022-11-17T10:55:25Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-08-23T09:11:26Z",
                    "Valid To": "2022-10-21T09:42:57Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-24T11:02:31Z",
                    "Valid To": "2022-11-24T11:02:31Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-01T11:16:22Z",
                    "Valid To": "2022-12-01T11:16:22Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-01T11:16:26Z",
                    "Valid To": "2022-12-01T11:16:26Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 8885699,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-16T15:23:07Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T17:53:36Z",
                    "Valid To": "2022-11-22T17:53:36Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2014-09-23T19:35:30Z",
                    "Valid To": "2022-12-06T18:55:26Z"
                }
            ]
        },
        {
            "Id": 116063290,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-17T12:52:52Z",
                    "Valid To": "2022-11-17T12:58:48Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-10-18T07:24:20Z",
                    "Valid To": "2022-12-06T10:18:07Z"
                }
            ]
        },
        {
            "Id": 116063290,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-23T12:38:38Z",
                    "Valid To": "2022-11-23T12:38:38Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-10-18T07:24:20Z",
                    "Valid To": "2022-12-06T10:18:07Z"
                }
            ]
        },
        {
            "Id": 1107341,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-24T15:58:56Z",
                    "Valid To": "2022-11-24T15:58:56Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2011-10-06T12:10:14Z",
                    "Valid To": "2022-08-17T12:03:59Z"
                }
            ]
        },
        {
            "Id": 1107341,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-24T16:24:12Z",
                    "Valid To": "2022-11-24T16:24:12Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2011-10-06T12:10:14Z",
                    "Valid To": "2022-08-17T12:03:59Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-01T17:16:19Z",
                    "Valid To": "2022-12-01T17:16:19Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 323199,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-01T17:23:30Z",
                    "Valid To": "2022-12-01T17:23:30Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2010-07-05T11:26:31Z",
                    "Valid To": "2022-11-30T16:29:27Z"
                }
            ]
        },
        {
            "Id": 66660475,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-02T00:35:17Z",
                    "Valid To": "2022-12-02T00:35:17Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2020-06-09T04:37:44Z",
                    "Valid To": "2022-10-27T03:09:23Z"
                }
            ]
        },
        {
            "Id": 10442001,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-02T16:25:10Z",
                    "Valid To": "2022-12-02T16:25:10Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2015-01-07T23:05:07Z",
                    "Valid To": "2022-11-21T11:09:49Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-06T00:23:27Z",
                    "Valid To": "2022-12-06T00:23:27Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 78156688,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-16T14:16:37Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-21T16:10:38Z",
                    "Valid To": "2022-11-21T16:10:38Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-29T13:20:46Z",
                    "Valid To": "2022-11-29T13:20:46Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-02T19:48:49Z",
                    "Valid To": "2022-12-02T19:48:49Z"
                },
                {
                    "Contribution Type": "Pull Request",
                    "Valid From": "2022-11-16T14:16:37Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-01-28T14:07:17Z",
                    "Valid To": "2022-11-22T18:54:56Z"
                }
            ]
        },
        {
            "Id": 5112267,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-29T14:33:25Z",
                    "Valid To": "2022-11-29T14:33:25Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2013-07-29T10:31:26Z",
                    "Valid To": "2022-10-25T09:29:32Z"
                }
            ]
        },
        {
            "Id": 60800749,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-16T13:54:48Z",
                    "Valid To": "2022-11-16T21:23:13Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-16T13:59:01Z",
                    "Valid To": "2022-11-16T13:59:01Z"
                },
                {
                    "Contribution Type": "Pull Request",
                    "Valid From": "2022-11-16T13:54:48Z",
                    "Valid To": "2022-11-16T21:23:13Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2020-02-08T00:01:52Z",
                    "Valid To": "2022-12-03T21:22:02Z"
                }
            ]
        },
        {
            "Id": null,
            "Symbols": [
                {
                    "Contribution Type": "Pull Merger",
                    "Valid From": "2022-11-16T21:23:13Z",
                    "Valid To": "2022-11-16T21:23:13Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2019-10-18T20:47:54Z",
                    "Valid To": "2019-10-18T20:47:54Z"
                }
            ]
        },
        {
            "Id": 9656425,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-16T09:33:42Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-16T13:43:21Z",
                    "Valid To": "2022-11-16T13:46:03Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-17T11:21:21Z",
                    "Valid To": "2022-11-17T11:21:21Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2014-11-10T12:48:12Z",
                    "Valid To": "2022-10-18T06:09:05Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-16T13:09:29Z",
                    "Valid To": "2022-11-16T13:34:09Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-16T16:06:20Z",
                    "Valid To": "2022-11-16T16:06:20Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-12-06T03:08:40Z"
                }
            ]
        },
        {
            "Id": 73069040,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-17T20:56:37Z",
                    "Valid To": "2022-11-17T20:56:37Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2020-10-18T14:47:17Z",
                    "Valid To": "2022-11-10T23:29:26Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-24T21:02:31Z",
                    "Valid To": "2022-11-24T21:02:31Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-01T21:16:20Z",
                    "Valid To": "2022-12-01T21:16:20Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 56610014,
            "Symbols": [
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-01T21:16:23Z",
                    "Valid To": "2022-12-01T21:16:23Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2019-10-15T20:29:19Z",
                    "Valid To": "2022-04-26T20:13:31Z"
                }
            ]
        },
        {
            "Id": 106367904,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-16T01:16:16Z",
                    "Valid To": "2022-11-16T01:17:12Z"
                },
                {
                    "Contribution Type": "Pull Request",
                    "Valid From": "2022-11-16T01:16:16Z",
                    "Valid To": "2022-11-16T01:17:12Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-05-27T05:25:55Z",
                    "Valid To": "2022-11-11T02:52:41Z"
                }
            ]
        },
        {
            "Id": null,
            "Symbols": [
                {
                    "Contribution Type": "Pull Merger",
                    "Valid From": "2022-11-16T01:17:12Z",
                    "Valid To": "2022-11-16T01:17:12Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2010-07-05T11:26:31Z",
                    "Valid To": "2022-11-30T16:29:27Z"
                }
            ]
        },
        {
            "Id": 3444368,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-11-16T01:02:38Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-11-22T22:32:14Z",
                    "Valid To": "2022-11-22T22:32:14Z"
                },
                {
                    "Contribution Type": "Issue Commenter",
                    "Valid From": "2022-12-01T20:06:00Z",
                    "Valid To": "2022-12-01T20:06:00Z"
                },
                {
                    "Contribution Type": "Pull Request",
                    "Valid From": "2022-11-16T01:02:38Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2013-02-01T02:32:23Z",
                    "Valid To": "2022-11-16T00:55:46Z"
                }
            ]
        }
    ],
    "Data": [
        {
            "Timestamp": "2022-11-22T16:10:10Z",
            "EntityIds": [
                657617,
                48215717,
                323199
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "7MV8RH1N53F2"
            ],
            "Context": "Make fuzztest fuzzer ready for OSS-Fuzz. The goal here is to make the fuzztest fuzzers run in the OSS-Fuzz infrastructure. I'm starting with a single fuzzer to confirm it all works.\r\n\r\nI also updated the googletest dependency, will this have any negative impact?\r\n\r\nCross-referencing https://github.com/google/oss-fuzz/pull/8992 in the OSS-Fuzz repo.\r\n\r\nSigned-off-by: David Korczynski <david@adalogics.com>"
        },
        {
            "Timestamp": "2022-11-22T16:10:39Z",
            "EntityIds": [
                657617,
                48215717,
                323199
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "7MV8RH1N53F2"
            ],
            "Context": "@mihaimaruseac could you assist here?"
        },
        {
            "Timestamp": "2022-11-22T17:17:08Z",
            "EntityIds": [
                657617,
                48215717,
                323199
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "7MV8RH1N53F2"
            ],
            "Context": "Seems right to me. Might need to also change internal copybara rules, etc. but can take care of it."
        },
        {
            "Timestamp": "2022-11-22T16:10:10Z",
            "EntityIds": [
                657617,
                48215717,
                323199
            ],
            "Symbol": "Pull Request",
            "Relational ID": [
                "7MV8RH1N53F2"
            ],
            "Context": "Make fuzztest fuzzer ready for OSS-Fuzz. The goal here is to make the fuzztest fuzzers run in the OSS-Fuzz infrastructure. I'm starting with a single fuzzer to confirm it all works.\r\n\r\nI also updated the googletest dependency, will this have any negative impact?\r\n\r\nCross-referencing https://github.com/google/oss-fuzz/pull/8992 in the OSS-Fuzz repo.\r\n\r\nSigned-off-by: David Korczynski <david@adalogics.com>"
        },
        {
            "Timestamp": "2022-11-22T13:41:46Z",
            "EntityIds": [
                1710528,
                31752514,
                68572250,
                81610181
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "8U1JPU3WAL7L"
            ],
            "Context": "SigmoidGrad legalization. <details><summary>Click to expand!</summary> \r\n \r\n ### Issue Type\r\n\r\nBug\r\n\r\n### Source\r\n\r\nsource\r\n\r\n### Tensorflow Version\r\n\r\nmaster\r\n\r\n### Custom Code\r\n\r\nYes\r\n\r\n### OS Platform and Distribution\r\n\r\n_No response_\r\n\r\n### Mobile device\r\n\r\n_No response_\r\n\r\n### Python version\r\n\r\n_No response_\r\n\r\n### Bazel version\r\n\r\n_No response_\r\n\r\n### GCC/Compiler version\r\n\r\n_No response_\r\n\r\n### CUDA/cuDNN version\r\n\r\n_No response_\r\n\r\n### GPU model and memory\r\n\r\n_No response_\r\n\r\n### Current Behaviour?\r\n\r\nWe had a legalization error with the MLIR bridge with the sigmoid in the focal loss:\r\nhttps://github.com/keras-team/keras-cv/blob/master/keras_cv/losses/focal.py#L82\r\n\r\n\r\n### Standalone code to reproduce the issue\r\n\r\nhttps://colab.research.google.com/gist/ianstenbit/6cbcf6e034fbf63e22208f3d9a479297/sigmoid-loss-issue-retinanet-on-tpu.ipynb\r\n\r\nSee also:\r\nhttps://github.com/keras-team/keras-cv/issues/1018\r\n\r\n\r\n### Relevant log output\r\n\r\n```python\r\n(0) INVALID_ARGUMENT: {{function_node __inference_train_function_133447}} TF to XLA legalization failed: <unknown>:0: error: loc(fused[\"SigmoidGrad:\", \"gradient_tape/FocalLoss/Sigmoid/SigmoidGrad\"]): 'mhlo.constant' op result #0 must be statically shaped tensor of floating-point or pred (AKA boolean or 1-bit integer) or 8/16/32/64-bit signless integer or 8/16/32/64-bit unsigned integer or complex type with 32-bit float or 64-bit float elements values, but got 'tensor<?x?x20xf32>'\r\n<unknown>:0: note: loc(fused[\"SigmoidGrad:\", \"gradient_tape/FocalLoss/Sigmoid/SigmoidGrad\"]): see current operation: %5996 = \"mhlo.constant\"() {value = dense<1.000000e+00> : tensor<?x?x20xf32>} : () -> tensor<?x?x20xf32>\r\n```\r\n</details>"
        },
        {
            "Timestamp": "2022-11-22T13:43:52Z",
            "EntityIds": [
                1710528,
                31752514,
                68572250,
                81610181
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "8U1JPU3WAL7L"
            ],
            "Context": "/cc @ukoxyz\r\n"
        },
        {
            "Timestamp": "2022-11-22T13:14:42Z",
            "EntityIds": [
                75139937,
                111861663,
                45509728,
                111861663,
                45509728,
                111861663,
                56610014
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "ZHHZ7FMJ4ZDV"
            ],
            "Context": "AttributeError: 'Tensor' object has no attribute 'ndim'. Hello,\r\n\r\nI'm doing data augmentation on tensorflow. With tf.image it works, but when I add code with tf.keras.preprocessing I have this error:\r\n\r\nAttributeError: 'Tensor' object has no attribute 'ndim'\r\n\r\nHere is my code :\r\n```\r\ndef process_single_sample_train(img_path, label):\r\n\r\n    # 1. Read image\r\n    img = tf.io.read_file(img_path)\r\n\r\n    # 2. Decode and convert to grayscale\r\n    img = tf.io.decode_png(img, channels=3) # channels = 1 for grayscale\r\n\r\n    # 3. Convert to float32 in [0, 1] range\r\n    img = tf.image.convert_image_dtype(img, tf.float32)\r\n\r\n    # 4. Resize to the desired size\r\n    img = tf.image.resize(img, [32, 128])\r\n    \r\n    # 5. Augment\r\n    rand_ = tf.random.uniform(shape=(), minval=0, maxval=1)\r\n    if rand_ < 0.8:\r\n        img = tf.image.random_contrast(img, lower=0.7, upper=1)\r\n        \r\n        ## THIS LINE CAUSES THE BUG\r\n        img = tf.convert_to_tensor(tf.keras.preprocessing.image.random_rotation(img, rg=5))\r\n        \r\n    return {\"image\": img, \"label\": label}\r\n```\r\nBug when I run this : \r\n```\r\ntrain_dataset = (\r\n    train_dataset.map(\r\n        process_single_sample_train, num_parallel_calls=tf.data.experimental.AUTOTUNE\r\n    )\r\n    .batch(batch_size)\r\n    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n)\r\n```\r\n"
        },
        {
            "Timestamp": "2022-11-23T03:50:24Z",
            "EntityIds": [
                75139937,
                111861663,
                45509728,
                111861663,
                45509728,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ZHHZ7FMJ4ZDV"
            ],
            "Context": "Hi,\r\n\r\n```\r\n## THIS LINE CAUSES THE BUG\r\n        img = tf.convert_to_tensor(tf.keras.preprocessing.image.random_rotation(img, rg=5))\r\n```\r\n\r\nThe documentation [page](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/random_rotation) tells that `tf.keras.preprocessing.image.random_rotation` is depricated and does not work on tensors. So it is better to use `tf.keras.layers.RandomRotation` instead ([documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomRotation), [usage](https://www.tensorflow.org/guide/keras/preprocessing_layers)).\r\n\r\nHope this helps."
        },
        {
            "Timestamp": "2022-11-23T16:18:15Z",
            "EntityIds": [
                75139937,
                111861663,
                45509728,
                111861663,
                45509728,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ZHHZ7FMJ4ZDV"
            ],
            "Context": "Ok thank you @pavankumarsai18 . This must be used in the network or else it can be used in my process_single_sample_train function?"
        },
        {
            "Timestamp": "2022-11-23T16:53:25Z",
            "EntityIds": [
                75139937,
                111861663,
                45509728,
                111861663,
                45509728,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ZHHZ7FMJ4ZDV"
            ],
            "Context": "@AntoineChauviere \r\n Can  you  please try `img = tf.convert_to_tensor(tf.keras.layers.RandomRotation(img, rg=5))` instead of `img = tf.convert_to_tensor(tf.keras.preprocessing.image.random_rotation(img, rg=5))`, please find gist [here](https://colab.research.google.com/gist/tiruk007/dee0b99342ffe7b82808be557f7cc9a7/untitled30.ipynb) for reference and let us know if it helps.\r\n\r\nThank you !"
        },
        {
            "Timestamp": "2022-11-23T19:19:58Z",
            "EntityIds": [
                75139937,
                111861663,
                45509728,
                111861663,
                45509728,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ZHHZ7FMJ4ZDV"
            ],
            "Context": "@pavankumarsai18 thank you, I think we have to instantiate the layer like this and apply it to an image, for example:\r\n\r\n```\r\nlayer_rotate = tf.keras.layers.RandomRotation(factor=(-0.3, 0.2))\r\nimage_rotate = layer_rotate(image)\r\n```\r\n\r\nBut I don't see any difference, in fact : \r\n\r\n image == image_rotate\r\n\r\nDo you have an idea ?"
        },
        {
            "Timestamp": "2022-11-23T21:53:04Z",
            "EntityIds": [
                75139937,
                111861663,
                45509728,
                111861663,
                45509728,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ZHHZ7FMJ4ZDV"
            ],
            "Context": "Hi, \r\n\r\nFollowing the documentation, we need to augment the data by random rotation ...\r\n\r\n```\r\ndata_augmentation = tf.keras.Sequential([tf.keras.layers.RandomRotation(factor=(-0.3, 0.2))])\r\nimg_rotated       = data_augmentation(img)\r\n```\r\n\r\nThe good thing about using `tf.keras.Sequential` is that you can use multiple effects, and also batch process. As mentioned in [documentation](https://www.tensorflow.org/guide/keras/preprocessing_layers), we can do random flips, random zoom, and random rotations. You can define all these modifications in `data_augmentation` and batch process `train_dataset`, or if you want to stick with just one image at a time you can follow the code I mentioned earlier.\r\n\r\n```\r\ndata_augmentation = keras.Sequential(\r\n    [\r\n        layers.RandomFlip(\"horizontal\"),\r\n        layers.RandomRotation(0.1),\r\n        layers.RandomZoom(0.1),\r\n    ]\r\n)\r\n...\r\n...\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\r\ntrain_dataset = train_dataset.batch(16).map(lambda x, y: (data_augmentation(x), y))\r\n```\r\n\r\nHope this helps!!!!\r\n"
        },
        {
            "Timestamp": "2022-11-24T19:05:18Z",
            "EntityIds": [
                75139937,
                111861663,
                45509728,
                111861663,
                45509728,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ZHHZ7FMJ4ZDV"
            ],
            "Context": "Ok it works perfectly, thank you very much @pavankumarsai18 !"
        },
        {
            "Timestamp": "2022-11-25T02:33:00Z",
            "EntityIds": [
                75139937,
                111861663,
                45509728,
                111861663,
                45509728,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ZHHZ7FMJ4ZDV"
            ],
            "Context": "@AntoineChauviere \r\nCan you please close the issue if it is resolved.\r\n\r\nThank you!\r\n"
        },
        {
            "Timestamp": "2022-11-25T08:27:28Z",
            "EntityIds": [
                75139937,
                111861663,
                45509728,
                111861663,
                45509728,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ZHHZ7FMJ4ZDV"
            ],
            "Context": "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58644\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58644\">No</a>\n"
        },
        {
            "Timestamp": "2022-11-21T23:41:29Z",
            "EntityIds": [
                55463253,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "GMOIQDGCXKOF"
            ],
            "Context": "Support the quantization of custom ops. Propagates the _tfl_quant_trait as attribute into the newly created custom op instead of as custom_option. It also forces the pruning of unused custom ops in the PostQuantizePass by assuming all custom ops have no side effect. This is a temporary solution due to the difficulty to set the enable-no-side-effect option through the Python API.\r\n"
        },
        {
            "Timestamp": "2022-11-22T16:08:14Z",
            "EntityIds": [
                55463253,
                48215717
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "GMOIQDGCXKOF"
            ],
            "Context": "current ([quick fix](https://github.com/tensorflow/tensorflow/pull/58643/files#diff-0ac843ac5080848d1055158d209de9c42bbfd875beb533ba1f76bfc93255ff0dR352)) get the dangling tfl.custom op pruned.\r\nTo have a proper solution we have to pass the enable-no-side-effect option to the tfl-post-quantize pass [here](https://github.com/tensorflow/tensorflow/blob/cda16a3382eb59a64c767d7ed2dd78791e230e6b/tensorflow/compiler/mlir/lite/transforms/passes.td#L250). It seems though there is no way to do it with the Python API currently.\r\n\r\nOne way to use it would be to build the flatbuffer_translate and tf-opt binaries:\r\n`bazel build -c opt //tensorflow/compiler/mlir/lite:flatbuffer_translate //tensorflow/compiler/mlir:tf-opt`\r\n\r\nAnd then use them as follow:\r\n\r\n`./bazel-bin/tensorflow/compiler/mlir/lite/flatbuffer_translate --tflite-flatbuffer-to-mlir model_int8.tflite | ./bazel-bin/tensorflow/compiler/mlir/tf-opt -tfl-post-quantize=\"enable-no-side-effect=exp_sin=true\" | ./bazel-bin/tensorflow/compiler/mlir/lite/flatbuffer_translate --mlir-to-tflite-flatbuffer > model_int8_pruned.tflite`\r\n\r\n\r\nWe can annotate multiple custom ops like so: `enable-no-side-effect=op1=true,op2=true,op3=true`"
        },
        {
            "Timestamp": "2022-11-21T23:41:29Z",
            "EntityIds": [
                55463253,
                48215717
            ],
            "Symbol": "Pull Request",
            "Relational ID": [
                "GMOIQDGCXKOF"
            ],
            "Context": "Support the quantization of custom ops. Propagates the _tfl_quant_trait as attribute into the newly created custom op instead of as custom_option. It also forces the pruning of unused custom ops in the PostQuantizePass by assuming all custom ops have no side effect. This is a temporary solution due to the difficulty to set the enable-no-side-effect option through the Python API.\r\n"
        },
        {
            "Timestamp": "2022-11-21T23:41:06Z",
            "EntityIds": [
                19536781,
                111861663,
                8497170,
                84765720,
                8497170,
                8497170
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "YCYFQJXV8X0L"
            ],
            "Context": "MoviNet has memory leak. <details><summary>Click to expand!</summary> \r\n \r\n ### Issue Type\r\n\r\nBug\r\n\r\n### Source\r\n\r\nbinary\r\n\r\n### Tensorflow Version\r\n\r\n2.10.0\r\n\r\n### Custom Code\r\n\r\nYes\r\n\r\n### OS Platform and Distribution\r\n\r\nWindows 10 (recreated in Ubuntu 20.4)\r\n\r\n### Mobile device\r\n\r\nNA\r\n\r\n### Python version\r\n\r\n3.9\r\n\r\n### Bazel version\r\n\r\n_No response_\r\n\r\n### GCC/Compiler version\r\n\r\n_No response_\r\n\r\n### CUDA/cuDNN version\r\n\r\n11.2 / 8.1\r\n\r\n### GPU model and memory\r\n\r\n_No response_\r\n\r\n### Current Behaviour?\r\n\r\nRepeated inference calls to MoviNet (loaded from SavedModel) continuously increase memory usage until a crash occurs.\r\n\r\n\r\n\r\n### Standalone code to reproduce the issue\r\n\r\n\r\nThe process to recreate is somewhat long, so full code cannot be provided. The steps are:\r\n\r\n1. Create movinet network:\r\n```shell\r\n    from official.projects.movinet.modeling import movinet, movinet_layers, movinet_model\r\n    backbone = movinet.Movinet(model_id=model_id)   # output_states=False\r\n    model = movinet_model.MovinetClassifier(backbone=backbone, num_classes=600, output_states=False)\r\n    model.build([1, 1, 1, 1, 3])\r\n\r\n    checkpoint_dir = download_and_extract_file(model_id=model_id)\r\n    checkpoint_path = os.path.join(checkpoint_dir, 'ckpt-1')\r\n    checkpoint = tf.train.Checkpoint(model=model)\r\n    status = checkpoint.restore(checkpoint_path)\r\n    status.assert_existing_objects_matched()\r\n\r\n    model = build_classifier(backbone=backbone, input_shape= input_shape, num_classes=n_output_classes,\r\n                             movinet_layers_to_freeze = movinet_layers_to_freeze)\r\n```\r\n\r\n2. Fine-tune the model\r\n\r\n3. Convert to savedmodel:\r\n```\r\ntf.keras.models.save_model(self.net, path, signatures=None)\r\n```\r\n\r\n4. Load savedmodel:\r\n```\r\nmodel = tf.keras.models.load_model(savedmodel_path, custom_objects={'tf': tf, 'K': tf.keras.backend})\r\n```\r\n\r\n5. Perform inference in a for loop:\r\n```\r\nfor i in range(n_samples):\r\n    out[i] = model(input[i], training=training)\r\n```\r\n\r\n\r\n### Relevant log output\r\n\r\nI have ran this from my Windows PC, as well as EC2 instances with and without a GPU. I used ClearML to log machine stats over iterations and saw the following:\r\n\r\nCPU-Only:\r\n![image](https://user-images.githubusercontent.com/19536781/203179971-490e64f6-b198-43c6-a2dc-500c8190ccae.png)\r\n\r\nNote that in the beginning, there is alot of writing to disk (orange) while RAM stays constant (blue). After a certain amount of writing to disk, RAM starts being used until it is depleted and program crashes. \r\n\r\nGPU:\r\nThe same behavior appears on GPU machines, with the addition that when it starts writing to RAM, GPU starts filling up as well (top plot, blue/green lines):\r\n![image](https://user-images.githubusercontent.com/19536781/203180382-19affc22-bd43-4dc0-8a48-e97e7e80422d.png)\r\n\r\nI have tried this on my windows machine as well, and observed the same behavior (RAM usage increasing until crash occurs) in Task Manager. \r\n\r\n```\r\n</details>"
        },
        {
            "Timestamp": "2022-11-23T00:28:23Z",
            "EntityIds": [
                19536781,
                111861663,
                8497170,
                84765720,
                8497170,
                8497170
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "YCYFQJXV8X0L"
            ],
            "Context": "Thank you for the detailed info, it's quite useful.\r\n\r\nI've not been aware of any memory leaks throughout my testing of MoViNet, but I could give you some pointers on helping you diagnose the issue.\r\n\r\n1. Which version of the model are you using? If it's the default a non-streaming version, then it would be very strange to experience any kind of memory leak, as the model itself should not be storing anything. If you made any of your own modifications, please give a short description.\r\n2. Given that this issue has not been brought up before (to the best of my knowledge), could you try exporting and running the model with an earlier version of TensorFlow, i.e., a version built more than 6 months ago? Perhaps a newly introduced bug in TF is introducing the memory leak.\r\n3. How are you doing the savedmodel export? Can you try running the original savedmodel or TF Lite model from TF Hub? If the original exported model does not have the issue, then there might be some bug in the export logic with `tf.keras.models.save_model`. I've had some weird issues before when running `save_model`, so it might be worth investigating.\r\n4. Is your own internal logic saving anything between loops? Does the issue go away if you swap out the model with a trivial savedmodel that takes the input image and outputs a label?\r\n\r\nI hope these help. If you can try to give more info from some of the above steps, this can help me provide more targeted assistance.\r\n\r\n"
        },
        {
            "Timestamp": "2022-11-26T03:53:44Z",
            "EntityIds": [
                19536781,
                111861663,
                8497170,
                84765720,
                8497170,
                8497170
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "YCYFQJXV8X0L"
            ],
            "Context": "@rsandler00 Could you please refer the comment above and provide the update on this ?\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-27T07:16:16Z",
            "EntityIds": [
                19536781,
                111861663,
                8497170,
                84765720,
                8497170,
                8497170
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "YCYFQJXV8X0L"
            ],
            "Context": "1. Not sure what you mean by \"model version\", but I am using a2. I load it as described above:\r\n```\r\n backbone = movinet.Movinet(model_id=model_id)   # output_states=False\r\n    model = movinet_model.MovinetClassifier(backbone=backbone, num_classes=600, output_states=False)\r\n```\r\n2. I tested w/ 2.8.1 ad had the same issue\r\n3. To convert to savedmodel I do:\r\n```\r\ntf.keras.models.save_model(self.net, path, signatures=None)\r\n```\r\nI have not tried w/ hub version, but I will do so soon\r\n\r\n4. I thoroughly tested w/ other models and very basic for loops, and that is not the issue. \r\n\r\n"
        },
        {
            "Timestamp": "2022-11-27T19:59:31Z",
            "EntityIds": [
                19536781,
                111861663,
                8497170,
                84765720,
                8497170,
                8497170
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "YCYFQJXV8X0L"
            ],
            "Context": "Ok, I was just able to fully reproduce the issue w/ the SavedModel from TFHub. \r\n\r\nI downloaded the following SavedModel file: https://tfhub.dev/tensorflow/movinet/a2/base/kinetics-600/classification/3\r\n\r\n\r\nAnd reproduced w/ this code:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport psutil\r\nfrom tqdm import tqdm\r\n\r\n# This import is critical for savedmodel to load correctly cuz of weird TF savedmodel voodoo...\r\nfrom official.projects.movinet.modeling import movinet, movinet_layers, movinet_model\r\n\r\n# path to DLd SM file from https://tfhub.dev/tensorflow/movinet/a2/base/kinetics-600/classification/3\r\nsavedmodel_path = 'C:\\\\Users\\\\Administrator\\\\Downloads\\sm'  \r\n\r\nmodel = tf.keras.models.load_model(savedmodel_path, custom_objects={'tf': tf, 'K': tf.keras.backend})\r\ninput = np.random.random((1, 20, 256, 256, 3))\r\nfor i in tqdm(range(30)):\r\n    if i % 3 == 0:\r\n        mem_info = psutil.virtual_memory()._asdict()\r\n        print(f'(i={i}) RAM Used: {mem_info[\"used\"] / 1e9:.2f} GB ({mem_info[\"percent\"]}%)')\r\n    model(input)\r\n```\r\n\r\nThis is my full console output. Notice RAM printouts at the end - in 30 samples my RAM usage went from 69.3% to 72.7%. This trend continues until crash due to no RAM...\r\n\r\n```\r\nC:\\code\\ai_dev\\venv\\Scripts\\python.exe \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2021.3\\plugins\\python-ce\\helpers\\pydev\\pydevd.py\" --multiproc --qt-support=auto --client 127.0.0.1 --port 62770 --file C:/Users/Administrator/AppData/Roaming/JetBrains/PyCharmCE2021.3/scratches/scratch_1.py\r\nConnected to pydev debugger (build 213.5744.248)\r\nC:\\code\\ai_dev\\venv\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.4.0 and strictly below 2.7.0 (nightly versions are not supported). \r\n The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \r\nSome things might work, some things might not.\r\nIf you were to encounter a bug, do not file an issue.\r\nIf you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \r\nYou can find the compatibility matrix in TensorFlow Addon's readme:\r\nhttps://github.com/tensorflow/addons\r\n  warnings.warn(\r\nimport sys; print('Python %s on %s' % (sys.version, sys.platform))\r\nmodel = tf.keras.models.load_model(savedmodel_path, custom_objects={'tf': tf, 'K': tf.keras.backend})\r\nPython 3.8.9 (tags/v3.8.9:a743f81, Apr  6 2021, 14:02:34) [MSC v.1928 64 bit (AMD64)]\r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 7.30.1 -- An enhanced Interactive Python. Type '?' for help.\r\nPyDev console: using IPython 7.30.1\r\nPython 3.8.9 (tags/v3.8.9:a743f81, Apr  6 2021, 14:02:34) [MSC v.1928 64 bit (AMD64)] on win32\r\n2022-11-27 11:53:08.375774: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2022-11-27 11:53:08.695317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7440 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0a:00.0, compute capability: 8.6\r\n  0%|          | 0/30 [00:00<?, ?it/s]2022-11-27 11:53:37.042835: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x27b9ed76e10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n(i=0) RAM Used: 20.93 GB (61.1%)\r\n2022-11-27 11:53:37.042982: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\r\n2022-11-27 11:53:37.645016: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\r\n2022-11-27 11:53:39.400588: I tensorflow/compiler/jit/xla_compilation_cache.cc:476] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\r\n2022-11-27 11:53:40.230562: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 40 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 16 input_feature_map_count: 40 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:40.313617: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 16 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 40 input_feature_map_count: 16 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\nWARNING:tensorflow:5 out of the last 5 calls to <bound method Conv.call of <official.vision.modeling.layers.nn_layers.Conv3D object at 0x0000027B9B049A00>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nWARNING:tensorflow:5 out of the last 5 calls to <bound method Conv.call of <official.vision.modeling.layers.nn_layers.Conv3D object at 0x0000027B9B049A00>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nWARNING:tensorflow:6 out of the last 6 calls to <bound method Conv.call of <official.vision.modeling.layers.nn_layers.Conv3D object at 0x0000027B9B15C3A0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nWARNING:tensorflow:6 out of the last 6 calls to <bound method Conv.call of <official.vision.modeling.layers.nn_layers.Conv3D object at 0x0000027B9B15C3A0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n2022-11-27 11:53:40.904291: W tensorflow/compiler/xla/service/gpu/gpu_conv_algorithm_picker.cc:727] None of the algorithms provided by cuDNN heuristics worked; trying fallback algorithms.  Conv: (f32[1,20,64,64,40]{3,2,1,4,0}, u8[0]{0}) custom-call(f32[1,20,64,64,40]{3,2,1,4,0}, f32[3,3,3,1,40]{2,1,0,3,4}), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=b012f_012io->b012f, feature_group_count=40, custom_call_target=\"__cudnn$convForward\", backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\r\n2022-11-27 11:53:42.140495: W tensorflow/compiler/xla/service/gpu/gpu_conv_algorithm_picker.cc:727] None of the algorithms provided by cuDNN heuristics worked; trying fallback algorithms.  Conv: (f32[1,20,64,64,64]{3,2,1,4,0}, u8[0]{0}) custom-call(f32[1,20,64,64,64]{3,2,1,4,0}, f32[3,3,3,1,64]{2,1,0,3,4}), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=b012f_012io->b012f, feature_group_count=64, custom_call_target=\"__cudnn$convForward\", backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\r\n2022-11-27 11:53:42.457439: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 64 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 16 input_feature_map_count: 64 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:42.526737: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 16 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 64 input_feature_map_count: 16 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:43.005281: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 96 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 24 input_feature_map_count: 96 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:43.080687: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 24 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 96 input_feature_map_count: 24 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:43.557255: W tensorflow/compiler/xla/service/gpu/gpu_conv_algorithm_picker.cc:727] None of the algorithms provided by cuDNN heuristics worked; trying fallback algorithms.  Conv: (f32[1,20,32,32,120]{3,2,1,4,0}, u8[0]{0}) custom-call(f32[1,20,32,32,120]{3,2,1,4,0}, f32[3,3,3,1,120]{2,1,0,3,4}), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=b012f_012io->b012f, feature_group_count=120, custom_call_target=\"__cudnn$convForward\", backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\r\n2022-11-27 11:53:43.766094: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 120 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 32 input_feature_map_count: 120 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:43.840040: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 32 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 120 input_feature_map_count: 32 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:44.196746: W tensorflow/compiler/xla/service/gpu/gpu_conv_algorithm_picker.cc:727] None of the algorithms provided by cuDNN heuristics worked; trying fallback algorithms.  Conv: (f32[1,20,32,32,96]{3,2,1,4,0}, u8[0]{0}) custom-call(f32[1,20,32,32,96]{3,2,1,4,0}, f32[3,3,3,1,96]{2,1,0,3,4}), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=b012f_012io->b012f, feature_group_count=96, custom_call_target=\"__cudnn$convForward\", backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\r\n2022-11-27 11:53:45.005478: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 240 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 64 input_feature_map_count: 240 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:45.076900: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 64 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 240 input_feature_map_count: 64 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:45.779619: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 160 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 40 input_feature_map_count: 160 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:45.865167: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 40 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 160 input_feature_map_count: 40 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:46.997732: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 192 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 48 input_feature_map_count: 192 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:47.083829: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 48 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 192 input_feature_map_count: 48 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:48.990525: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 144 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 40 input_feature_map_count: 144 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:49.068802: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 40 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 144 input_feature_map_count: 40 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:49.729509: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 480 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 120 input_feature_map_count: 480 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:49.804658: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 120 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 480 input_feature_map_count: 120 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:50.376111: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 384 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 96 input_feature_map_count: 384 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:50.469892: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 96 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 384 input_feature_map_count: 96 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:51.732227: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 576 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 144 input_feature_map_count: 576 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:51.819448: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 144 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 576 input_feature_map_count: 144 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:52.173105: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 640 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 2048 input_feature_map_count: 640 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n2022-11-27 11:53:52.282455: I tensorflow/stream_executor/cuda/cuda_dnn.cc:5025] Disabling cuDNN frontend for the following convolution:\r\n  input: {count: 1 feature_map_count: 2048 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n  filter: {output_feature_map_count: 600 input_feature_map_count: 2048 layout: OutputInputYX shape: 1 1 1 }\r\n  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\r\n  ... because it uses an identity activation.\r\n 10%|\u2588         | 3/30 [00:25<03:14,  7.19s/it](i=3) RAM Used: 23.75 GB (69.3%)\r\n 20%|\u2588\u2588        | 6/30 [00:39<02:10,  5.42s/it](i=6) RAM Used: 23.90 GB (69.7%)\r\n 30%|\u2588\u2588\u2588       | 9/30 [00:53<01:44,  5.00s/it](i=9) RAM Used: 24.04 GB (70.1%)\r\n 40%|\u2588\u2588\u2588\u2588      | 12/30 [01:08<01:28,  4.94s/it](i=12) RAM Used: 24.44 GB (71.3%)\r\n 50%|\u2588\u2588\u2588\u2588\u2588     | 15/30 [01:23<01:13,  4.92s/it](i=15) RAM Used: 24.55 GB (71.6%)\r\n 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 18/30 [01:38<00:59,  4.93s/it](i=18) RAM Used: 24.66 GB (72.0%)\r\n 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 21/30 [01:52<00:43,  4.81s/it](i=21) RAM Used: 24.63 GB (71.9%)\r\n 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 24/30 [02:06<00:28,  4.71s/it](i=24) RAM Used: 24.77 GB (72.3%)\r\n 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 27/30 [02:20<00:13,  4.65s/it](i=27) RAM Used: 24.92 GB (72.7%)\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [02:33<00:00,  5.13s/it]\r\n```\r\n\r\n\r\n"
        },
        {
            "Timestamp": "2022-11-28T17:59:39Z",
            "EntityIds": [
                19536781,
                111861663,
                8497170,
                84765720,
                8497170,
                8497170
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "YCYFQJXV8X0L"
            ],
            "Context": "I suspect there might be some issue with `tf.function` retracing, as evidenced by this warning:\r\n```\r\nWARNING:tensorflow:5 out of the last 5 calls to <bound method Conv.call> triggered tf.function retracing.\r\n```\r\n\r\nIt's very possible that a new graph is being constructed on each call, causing them to build up in memory. We have a [`tf.function`](https://www.tensorflow.org/api_docs/python/tf/function) wrapper around our 3D convolution [here](https://github.com/tensorflow/models/blob/master/official/vision/modeling/layers/nn_layers.py#L1053), which I believe is what is being retraced.\r\n\r\n\r\nI believe by default we recommend wrapping the entire savedmodel in a `tf.function` to optimize the entire graph.\r\n\r\nCan you try something like this in your code?\r\n\r\n```python\r\nmodel = tf.keras.models.load_model(...)\r\nmodel = tf.function(model, jit_compile=True)  # Can also try the reduce_retracing=True option, or set jit_compile=False\r\n```\r\n\r\nI would also try swapping out a2 base with a2 stream ([hub link](https://tfhub.dev/tensorflow/movinet/a2/stream/kinetics-600/classification/3), [docs](https://github.com/tensorflow/models/tree/master/official/projects/movinet#prediction-examples)), as that version uses (2+1)D convolutions and should not have the `tf.function` wrapper.\r\n\r\nLet me know once you've tried a few of these options. Thanks for continuing to provide detailed info!"
        },
        {
            "Timestamp": "2022-11-28T23:33:50Z",
            "EntityIds": [
                19536781,
                111861663,
                8497170,
                84765720,
                8497170,
                8497170
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "YCYFQJXV8X0L"
            ],
            "Context": "@Hyperparticle using \r\n```\r\nmodel = tf.function(model, jit_compile=True)\r\n```\r\nDid indeed solve the problem! Thanks so much! "
        },
        {
            "Timestamp": "2022-11-28T23:36:20Z",
            "EntityIds": [
                19536781,
                111861663,
                8497170,
                84765720,
                8497170,
                8497170
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "YCYFQJXV8X0L"
            ],
            "Context": "Excellent! Glad I could help. Please reopen this issue if you still have a memory leak, or open a new one if you encounter a different issue."
        },
        {
            "Timestamp": "2022-11-21T23:17:42Z",
            "EntityIds": [
                38714576,
                81610181,
                81610181
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "JU4BAATHZLCH"
            ],
            "Context": "tf.io.gfile.rename cause UnicodeError on non-English Windows. <details><summary>Click to expand!</summary> \r\n \r\n ### Issue Type\r\n\r\nBug\r\n\r\n### Source\r\n\r\nbinary\r\n\r\n### Tensorflow Version\r\n\r\ntensorflow-2.9.1\r\n\r\n### Custom Code\r\n\r\nNo\r\n\r\n### OS Platform and Distribution\r\n\r\nWindows 10 Family Chinese\r\n\r\n### Mobile device\r\n\r\n_No response_\r\n\r\n### Python version\r\n\r\n3.10.6 (conda)\r\n\r\n### Bazel version\r\n\r\n_No response_\r\n\r\n### GCC/Compiler version\r\n\r\n_No response_\r\n\r\n### CUDA/cuDNN version\r\n\r\n_No response_\r\n\r\n### GPU model and memory\r\n\r\n_No response_\r\n\r\n### Current Behaviour?\r\n\r\nThe problem is first caused by the rename issue at https://github.com/tensorflow/tensorflow/issues/45980\r\n\r\nEven when this rename error happen, it should produce \r\n\r\n```\r\ntensorflow.python.framework.errors_impl.UnknownError: Failed to rename: <src> <tar> : Access is denied.\r\n; Input/output error`\r\n```\r\n\r\nHowever, when the language of Windows is set to be non-English language, like Chinese, it cause `UnicodeError` like\r\n\r\n```\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xbe in position 143: invalid start byte\r\n```\r\n\r\nI guess the reason is that, the `\"Access is denied\"` is actually the error message formatted by Win32 `FormatError()` (https://learn.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-formatmessage). When `dwLanguageId` is set to be something like `MAKELANGID(NEUTRAL, SUBLANG_DEFAULT)`, it will produce a Chinese encoding error message `\"\u62d2\u7edd\u8bbf\u95ee\"` in `cp936` (`gbk`) encoding when the system code page is `936` (Simplified Chinese with `gbk` encoding). When you want to decode it as python string using `utf-8` encoding, it cause this problem. \r\n\r\nNote `\"\u62d2\u7edd\u8bbf\u95ee\"` in `gbk` is `\"\\xbe\\xdc\\xbe\\xf8\\xb7\\xc3\\xce\\xca\"`.\r\n\r\n\r\n### Standalone code to reproduce the issue\r\n\r\nJust follow the official tutorial at https://www.tensorflow.org/tutorials/images/data_augmentation\r\n\r\n```\r\n(train_ds, val_ds, test_ds), metadata = tfds.load(\r\n    'tf_flowers',\r\n    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\r\n    with_info=True,\r\n    as_supervised=True,\r\n)\r\n```\r\n\r\n\r\n### Relevant log output\r\n\r\n```\r\nWARNING:tensorflow:From <conda_env_path>\\lib\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse eager execution and: \r\n`tf.data.TFRecordDataset(path)`\r\n\r\n---------------------------------------------------------------------------\r\nUnicodeDecodeError                        Traceback (most recent call last)\r\nCell In [2], line 3\r\n      1 # Load Data\r\n----> 3 (train_ds, val_ds, test_ds), metadata = tfds.load(\r\n      4     'tf_flowers',\r\n      5     split = ['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\r\n      6     with_info = True,\r\n      7     as_supervised = True,\r\n      8 )\r\n\r\nFile <conda_env_path>\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py:52, in disallow_positional_args.<locals>.disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     50 _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n     51 _check_required(fn, kwargs)\r\n---> 52 return fn(*args, **kwargs)\r\n\r\nFile <conda_env_path>\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py:300, in load(name, split, data_dir, batch_size, in_memory, shuffle_files, download, as_supervised, decoders, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\r\n    298 if download:\r\n    299   download_and_prepare_kwargs = download_and_prepare_kwargs or {}\r\n--> 300   dbuilder.download_and_prepare(**download_and_prepare_kwargs)\r\n    302 if as_dataset_kwargs is None:\r\n    303   as_dataset_kwargs = {}\r\n\r\nFile <conda_env_path>\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py:52, in disallow_positional_args.<locals>.disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     50 _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n     51 _check_required(fn, kwargs)\r\n---> 52 return fn(*args, **kwargs)\r\n\r\nFile <conda_env_path>\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:281, in DatasetBuilder.download_and_prepare(self, download_dir, download_config)\r\n    278 self._log_download_bytes()\r\n    280 # Create a tmp dir and rename to self._data_dir on successful exit.\r\n--> 281 with file_format_adapter.incomplete_dir(self._data_dir) as tmp_data_dir:\r\n    282   # Temporarily assign _data_dir to tmp_data_dir to avoid having to forward\r\n    283   # it to every sub function.\r\n    284   with utils.temporary_assignment(self, \"_data_dir\", tmp_data_dir):\r\n    285     self._download_and_prepare(\r\n    286         dl_manager=dl_manager,\r\n    287         download_config=download_config)\r\n\r\nFile <conda_env_path>\\lib\\contextlib.py:142, in _GeneratorContextManager.__exit__(self, typ, value, traceback)\r\n    140 if typ is None:\r\n    141     try:\r\n--> 142         next(self.gen)\r\n    143     except StopIteration:\r\n    144         return False\r\n\r\nFile <conda_env_path>\\lib\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py:200, in incomplete_dir(dirname)\r\n    198 try:\r\n    199   yield tmp_dir\r\n--> 200   tf.io.gfile.rename(tmp_dir, dirname)\r\n    201 finally:\r\n    202   if tf.io.gfile.exists(tmp_dir):\r\n\r\nFile <conda_env_path>\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:620, in rename_v2(src, dst, overwrite)\r\n    607 @tf_export(\"io.gfile.rename\")\r\n    608 def rename_v2(src, dst, overwrite=False):\r\n    609   \"\"\"Rename or move a file / directory.\r\n    610 \r\n    611   Args:\r\n   (...)\r\n    618     errors.OpError: If the operation fails.\r\n    619   \"\"\"\r\n--> 620   _pywrap_file_io.RenameFile(\r\n    621       compat.path_to_bytes(src), compat.path_to_bytes(dst), overwrite)\r\n\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xbe in position 143: invalid start byte\r\n```\r\n</details>"
        },
        {
            "Timestamp": "2022-11-22T00:25:31Z",
            "EntityIds": [
                38714576,
                81610181,
                81610181
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "JU4BAATHZLCH"
            ],
            "Context": "Update: Do not need to worry about the rename error. It is caused by a very old `tensorflow-datasets` version. After updating the `1.2.0` version from conda to `4.7.0` version from pip, the rename error disappears.\r\n\r\nNow we only need to solve the encoding error. Many other file errors can reproduce it. Like, try to rename a non-existing file."
        },
        {
            "Timestamp": "2022-11-22T12:54:34Z",
            "EntityIds": [
                38714576,
                81610181,
                81610181
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "JU4BAATHZLCH"
            ],
            "Context": "@E-train-Liu,\r\nCould you please check if tfds-nightly works for you and also please try this code **pip install tensorflow-datasets==4.7.0** for the latest tfds. \r\n\r\nCould you please raise this issue on the TensorFlow Datasets repository as well?\r\nhttps://github.com/tensorflow/datasets/issues\r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-25T04:43:01Z",
            "EntityIds": [
                38714576,
                81610181,
                81610181
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "JU4BAATHZLCH"
            ],
            "Context": "I am sorry for misleading. **I am reporting for the encoding error instead of the rename error.**\r\n\r\nThat is, when there is some filesystem error on windows (including coping a non-existing file or being denied to rename a file), instead of reporting the error normally, it will raise an `UnicodeError` (which may be caused by the encoding mismatch).\r\n\r\nFor example\r\n\r\n```python\r\ntensorflow.io.gfile.copy(\"non_exist_file\", \"non_exist_file_2\")\r\n```\r\nOn `en-US` Windows system (default code page: `1252`), it report the error as expected\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\ntensorflow.python.framework.errors_impl.UnknownError: Failed to copy:  non_exist_file :  No such file or directory.\r\n; `Input/output error`\r\n```\r\n\r\nOn `zh-CN` Windows system (default code page `936`), should work as above. Or if follow the Windows locale, it should work like\r\n\r\n ```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\ntensorflow.python.framework.errors_impl.UnknownError: Failed to copy:  non_exist_file :  \u7cfb\u7edf\u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6587\u4ef6\u3002\r\n; `Input/output error`\r\n```\r\n\r\nHowever, it now produce\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"D:\\Anaconda3\\envs\\sci\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 579, in copy_v2\r\n    _pywrap_file_io.CopyFile(\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 58: invalid continuation byte\r\n```\r\n\r\nI also guessed the cause of this issue, and wrote it in the \"Current Behaviour\" section of the first issue.\r\n\r\nBy the way, as my first P.S. said, I switched to `tensorflow-dataset` `4.7.0`, and the rename error is fixed. But it is not the main content of this issue. Again, sorry for misunderstanding."
        },
        {
            "Timestamp": "2022-11-21T22:35:25Z",
            "EntityIds": [
                29215195,
                38085909,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "2QAMXR85A5D3"
            ],
            "Context": "[INTEL oneDNN] OneDNN Refactoring Part 1: Remove obsolete operations. This PR removes obsolete oneDNN operations (oneDNN blocked format related) as well as MKL layout pass tests and conversion tests (test cases are all related to blocked format).\r\n\r\nResults:\r\n   1. 12 source files are deleted\r\n   2. 8 source files are update (bazel files, tests)\r\n   3. Total 8843 lines of code are cleaned away!"
        },
        {
            "Timestamp": "2022-11-21T22:35:25Z",
            "EntityIds": [
                29215195,
                38085909,
                48215717
            ],
            "Symbol": "Pull Request",
            "Relational ID": [
                "2QAMXR85A5D3"
            ],
            "Context": "[INTEL oneDNN] OneDNN Refactoring Part 1: Remove obsolete operations. This PR removes obsolete oneDNN operations (oneDNN blocked format related) as well as MKL layout pass tests and conversion tests (test cases are all related to blocked format).\r\n\r\nResults:\r\n   1. 12 source files are deleted\r\n   2. 8 source files are update (bazel files, tests)\r\n   3. Total 8843 lines of code are cleaned away!"
        },
        {
            "Timestamp": "2022-11-21T22:09:56Z",
            "EntityIds": [
                118690585,
                48215717,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "1GGERT3V6NWQ"
            ],
            "Context": "[INTEL oneDNN] OneDNN Refactoring Part 1: Remove obsolete operations. This PR removes obsolete oneDNN operations (oneDNN blocked format related) as well as MKL layout pass tests and conversion tests (test cases are all related to blocked format).\r\n\r\nResults:\r\n   1. 12 source files are deleted\r\n   2. 8 source files are update (bazel files, tests)\r\n   3. Total 8843 lines of code are cleaned away!"
        },
        {
            "Timestamp": "2022-11-23T09:14:09Z",
            "EntityIds": [
                118690585,
                48215717,
                48215717
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "1GGERT3V6NWQ"
            ],
            "Context": "Hi @sr5434 It looks like your PR relates to the Keras component. Please submit it to the github.com/keras-team/keras repository instead. Thankyou.\r\n@fchollet, @qlzh727"
        },
        {
            "Timestamp": "2022-11-21T22:09:56Z",
            "EntityIds": [
                118690585,
                48215717,
                48215717
            ],
            "Symbol": "Pull Request",
            "Relational ID": [
                "1GGERT3V6NWQ"
            ],
            "Context": "[INTEL oneDNN] OneDNN Refactoring Part 1: Remove obsolete operations. This PR removes obsolete oneDNN operations (oneDNN blocked format related) as well as MKL layout pass tests and conversion tests (test cases are all related to blocked format).\r\n\r\nResults:\r\n   1. 12 source files are deleted\r\n   2. 8 source files are update (bazel files, tests)\r\n   3. Total 8843 lines of code are cleaned away!"
        },
        {
            "Timestamp": "2022-11-21T20:58:44Z",
            "EntityIds": [
                26332583,
                48215717,
                55858104
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "G1JM0ACHZA46"
            ],
            "Context": "Change per-process mem to use total memory as base. This is to address [this issue](https://github.com/google/jax/issues/4310).\r\nInstead of using free_memory to calculate the amount of memory to assign to the process, we need to use total_memory to be consistent with tf core.\r\nDoc is also updated to reflect it.\r\nThis needs to be included in the release doc too."
        },
        {
            "Timestamp": "2022-11-21T20:58:47Z",
            "EntityIds": [
                26332583,
                48215717,
                55858104
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "G1JM0ACHZA46"
            ],
            "Context": "Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/58638/checks?check_run_id=9626456675) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."
        },
        {
            "Timestamp": "2022-11-28T04:10:11Z",
            "EntityIds": [
                26332583,
                48215717,
                55858104
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "G1JM0ACHZA46"
            ],
            "Context": "> We'll need to update the JAX documentation to reflect this, see: https://jax.readthedocs.io/en/latest/gpu_memory_allocation.html\r\n> \r\n> Can you send a PR to JAX to fix that also?\r\n\r\nGood catch. Opened a [pr](https://github.com/google/jax/pull/13413) on Jax to reflect the change here."
        },
        {
            "Timestamp": "2022-11-21T20:58:44Z",
            "EntityIds": [
                26332583,
                48215717,
                55858104
            ],
            "Symbol": "Pull Request",
            "Relational ID": [
                "G1JM0ACHZA46"
            ],
            "Context": "Change per-process mem to use total memory as base. This is to address [this issue](https://github.com/google/jax/issues/4310).\r\nInstead of using free_memory to calculate the amount of memory to assign to the process, we need to use total_memory to be consistent with tf core.\r\nDoc is also updated to reflect it.\r\nThis needs to be included in the release doc too."
        },
        {
            "Timestamp": "2022-11-21T19:40:05Z",
            "EntityIds": [
                6442822,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "CKMVQZKY4KMI"
            ],
            "Context": "Change per-process mem to use total memory as base. This is to address [this issue](https://github.com/google/jax/issues/4310).\r\nInstead of using free_memory to calculate the amount of memory to assign to the process, we need to use total_memory to be consistent with tf core.\r\nDoc is also updated to reflect it.\r\nThis needs to be included in the release doc too."
        },
        {
            "Timestamp": "2022-11-21T19:40:05Z",
            "EntityIds": [
                6442822,
                48215717
            ],
            "Symbol": "Pull Request",
            "Relational ID": [
                "CKMVQZKY4KMI"
            ],
            "Context": "Change per-process mem to use total memory as base. This is to address [this issue](https://github.com/google/jax/issues/4310).\r\nInstead of using free_memory to calculate the amount of memory to assign to the process, we need to use total_memory to be consistent with tf core.\r\nDoc is also updated to reflect it.\r\nThis needs to be included in the release doc too."
        },
        {
            "Timestamp": "2022-11-21T18:37:33Z",
            "EntityIds": [
                67419721,
                86464649,
                86464649
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "XY6UHWPZJUXY"
            ],
            "Context": "CMake build system Tensorflow Lite v2.11.0 is broken. <details><summary>Click to expand!</summary> \r\n \r\n ### Issue Type\r\n\r\nBuild/Install\r\n\r\n### Source\r\n\r\nsource\r\n\r\n### Tensorflow Version\r\n\r\n2.11.0\r\n\r\n### Custom Code\r\n\r\nNo\r\n\r\n### OS Platform and Distribution\r\n\r\nAndroid\r\n\r\n### Mobile device\r\n\r\nN/A\r\n\r\n### Python version\r\n\r\n3.9\r\n\r\n### Bazel version\r\n\r\nN/A\r\n\r\n### GCC/Compiler version\r\n\r\nAndroid NDK 24\r\n\r\n### CUDA/cuDNN version\r\n\r\nN/A\r\n\r\n### GPU model and memory\r\n\r\nN/A\r\n\r\n### Current Behaviour?\r\n\r\nUnable to cross compile TFLite 2.11.0 for Android, using CMake.\r\n\r\nHere is the command I used to build:\r\n\r\n```shell\r\nmkdir tflite.build.android && cd tflite.build.android\r\n\r\ncmake -G \"Unix Makefiles\" -DCMAKE_SYSTEM_NAME=Android -DANDROID_ABI=arm64-v8a -DANDROID_STL=c++_shared -DANDROID_NATIVE_API_LEVEL=27 -DCMAKE_VERBOSE_MAKEFILE=ON -DCMAKE_TOOLCHAIN_FILE=$HOME/Android/Sdk/ndk/24.0.8215888/build/cmake/android.toolchain.cmake -DTFLITE_ENABLE_XNNPACK=ON -DTFLITE_ENABLE_GPU=ON -DTFLITE_ENABLE_NNAPI=ON -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=OFF ../tensorflow/tensorflow/lite\r\n\r\nmake -j4\r\n```\r\n, and I get the following error:\r\n```\r\n 28%] Linking CXX executable flatc\r\ncd /home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build && /usr/local/bin/cmake -E cmake_link_script CMakeFiles/flatc.dir/link.txt --verbose=1\r\n/home/myname/Android/Sdk/ndk/24.0.8215888/toolchains/llvm/prebuilt/linux-x86_64/bin/clang++ --target=aarch64-none-linux-android27 --sysroot=/home/myname/Android/Sdk/ndk/24.0.8215888/toolchains/llvm/prebuilt/linux-x86_64/sysroot -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security -fexceptions -frtti -stdlib=libc++ -O3 -DNDEBUG -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--fatal-warnings -Qunused-arguments -Wl,--no-undefined  -Wl,--gc-sections CMakeFiles/flatc.dir/src/idl_parser.cpp.o CMakeFiles/flatc.dir/src/idl_gen_text.cpp.o CMakeFiles/flatc.dir/src/reflection.cpp.o CMakeFiles/flatc.dir/src/util.cpp.o CMakeFiles/flatc.dir/src/idl_gen_cpp.cpp.o CMakeFiles/flatc.dir/src/idl_gen_csharp.cpp.o CMakeFiles/flatc.dir/src/idl_gen_dart.cpp.o CMakeFiles/flatc.dir/src/idl_gen_kotlin.cpp.o CMakeFiles/flatc.dir/src/idl_gen_go.cpp.o CMakeFiles/flatc.dir/src/idl_gen_java.cpp.o CMakeFiles/flatc.dir/src/idl_gen_ts.cpp.o CMakeFiles/flatc.dir/src/idl_gen_php.cpp.o CMakeFiles/flatc.dir/src/idl_gen_python.cpp.o CMakeFiles/flatc.dir/src/idl_gen_lobster.cpp.o CMakeFiles/flatc.dir/src/idl_gen_lua.cpp.o CMakeFiles/flatc.dir/src/idl_gen_rust.cpp.o CMakeFiles/flatc.dir/src/idl_gen_fbs.cpp.o CMakeFiles/flatc.dir/src/idl_gen_grpc.cpp.o CMakeFiles/flatc.dir/src/idl_gen_json_schema.cpp.o CMakeFiles/flatc.dir/src/idl_gen_swift.cpp.o CMakeFiles/flatc.dir/src/flatc.cpp.o CMakeFiles/flatc.dir/src/flatc_main.cpp.o CMakeFiles/flatc.dir/src/bfbs_gen_lua.cpp.o CMakeFiles/flatc.dir/src/code_generators.cpp.o CMakeFiles/flatc.dir/grpc/src/compiler/cpp_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/go_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/java_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/python_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/swift_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/ts_generator.cc.o -o flatc   -latomic -lm \r\nRunning scripts/generate_code.py...\r\ncd /home/myname/myworkingdir/tflite.build.android/flatbuffers && /usr/bin/python3.9 scripts/generate_code.py --flatc /home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc --skip-gen-reflection\r\nTraceback (most recent call last):\r\n  File \"/home/myname/myworkingdir/tflite.build.android/flatbuffers/scripts/generate_code.py\", line 148, in <module>\r\n    flatc(\r\n  File \"/home/myname/myworkingdir/tflite.build.android/flatbuffers/scripts/generate_code.py\", line 82, in flatc\r\n    result = subprocess.run(cmd, cwd=str(cwd), check=True)\r\n  File \"/usr/lib/python3.9/subprocess.py\", line 505, in run\r\n    with Popen(*popenargs, **kwargs) as process:\r\n  File \"/usr/lib/python3.9/subprocess.py\", line 951, in __init__\r\n    self._execute_child(args, executable, preexec_fn, close_fds,\r\n  File \"/usr/lib/python3.9/subprocess.py\", line 1821, in _execute_child\r\n    raise child_exception_type(errno_num, err_msg, err_filename)\r\nOSError: [Errno 8] Exec format error: '/home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc'\r\nmake[2]: *** [_deps/flatbuffers-build/CMakeFiles/flatc.dir/build.make:566: _deps/flatbuffers-build/flatc] Error 1\r\nmake[2]: *** Deleting file '_deps/flatbuffers-build/flatc'\r\nmake[2]: Leaving directory '/home/myname/myworkingdir/tflite.build.android'\r\nmake[1]: *** [CMakeFiles/Makefile2:4720: _deps/flatbuffers-build/CMakeFiles/flatc.dir/all] Error 2\r\nmake[1]: Leaving directory '/home/myname/myworkingdir/tflite.build.android'\r\nmake: *** [Makefile:139: all] Error 2\r\n```\r\n\r\nThe problem seems to be that Python tries to invoke the `flatbuffers/scripts/generate_code.py` script, which attempts to run `/home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc`, which does not exist. \r\n\r\nTFLite v2.10.1 builds fine, but as far as I can tell, for v2.10.1m there is no attempt to invoke `generate_code.py` or `_deps/flatbuffers-build/flatc`\r\n\r\nBased on [https://www.tensorflow.org/lite/guide/build_cmake#specifics_of_kernel_unit_tests_cross-compilation](url), I also tried building flatc separately, but I get the following CMake warning when running: `mkdir flatc-native-build && cd flatc-native-build && cmake ../tensorflow/tensorflow/lite/tools/cmake/native_tools/flatbuffers`\r\n\r\n```\r\nCMake Warning at CMakeLists.txt:43 (find_package):\r\n  By not providing \"Findflatbuffers.cmake\" in CMAKE_MODULE_PATH this project\r\n  has asked CMake to find a package configuration file provided by\r\n  \"flatbuffers\", but CMake did not find one.\r\n\r\n  Could not find a package configuration file provided by \"flatbuffers\" with\r\n  any of the following names:\r\n\r\n    flatbuffersConfig.cmake\r\n    flatbuffers-config.cmake\r\n\r\n  Add the installation prefix of \"flatbuffers\" to CMAKE_PREFIX_PATH or set\r\n  \"flatbuffers_DIR\" to a directory containing one of the above files.  If\r\n  \"flatbuffers\" provides a separate development package or SDK, be sure it\r\n  has been installed.\r\n```\r\nsubsequently running `cmake --build .` does not build the flatc executable.\r\n\r\n### Standalone code to reproduce the issue\r\n\r\n```shell\r\nmkdir tflite.build.android && cd tflite.build.android\r\n\r\ncmake -G \"Unix Makefiles\" -DCMAKE_SYSTEM_NAME=Android -DANDROID_ABI=arm64-v8a -DANDROID_STL=c++_shared -DANDROID_NATIVE_API_LEVEL=27 -DCMAKE_VERBOSE_MAKEFILE=ON -DCMAKE_TOOLCHAIN_FILE=$HOME/Android/Sdk/ndk/24.0.8215888/build/cmake/android.toolchain.cmake -DTFLITE_ENABLE_XNNPACK=ON -DTFLITE_ENABLE_GPU=ON -DTFLITE_ENABLE_NNAPI=ON -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=OFF ../tensorflow/tensorflow/lite\r\n\r\nmake -j4\r\n```\r\n\r\n### Relevant log output\r\n\r\n```shell\r\n28%] Linking CXX executable flatc\r\ncd /home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build && /usr/local/bin/cmake -E cmake_link_script CMakeFiles/flatc.dir/link.txt --verbose=1\r\n/home/myname/Android/Sdk/ndk/24.0.8215888/toolchains/llvm/prebuilt/linux-x86_64/bin/clang++ --target=aarch64-none-linux-android27 --sysroot=/home/myname/Android/Sdk/ndk/24.0.8215888/toolchains/llvm/prebuilt/linux-x86_64/sysroot -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security -fexceptions -frtti -stdlib=libc++ -O3 -DNDEBUG -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--fatal-warnings -Qunused-arguments -Wl,--no-undefined  -Wl,--gc-sections CMakeFiles/flatc.dir/src/idl_parser.cpp.o CMakeFiles/flatc.dir/src/idl_gen_text.cpp.o CMakeFiles/flatc.dir/src/reflection.cpp.o CMakeFiles/flatc.dir/src/util.cpp.o CMakeFiles/flatc.dir/src/idl_gen_cpp.cpp.o CMakeFiles/flatc.dir/src/idl_gen_csharp.cpp.o CMakeFiles/flatc.dir/src/idl_gen_dart.cpp.o CMakeFiles/flatc.dir/src/idl_gen_kotlin.cpp.o CMakeFiles/flatc.dir/src/idl_gen_go.cpp.o CMakeFiles/flatc.dir/src/idl_gen_java.cpp.o CMakeFiles/flatc.dir/src/idl_gen_ts.cpp.o CMakeFiles/flatc.dir/src/idl_gen_php.cpp.o CMakeFiles/flatc.dir/src/idl_gen_python.cpp.o CMakeFiles/flatc.dir/src/idl_gen_lobster.cpp.o CMakeFiles/flatc.dir/src/idl_gen_lua.cpp.o CMakeFiles/flatc.dir/src/idl_gen_rust.cpp.o CMakeFiles/flatc.dir/src/idl_gen_fbs.cpp.o CMakeFiles/flatc.dir/src/idl_gen_grpc.cpp.o CMakeFiles/flatc.dir/src/idl_gen_json_schema.cpp.o CMakeFiles/flatc.dir/src/idl_gen_swift.cpp.o CMakeFiles/flatc.dir/src/flatc.cpp.o CMakeFiles/flatc.dir/src/flatc_main.cpp.o CMakeFiles/flatc.dir/src/bfbs_gen_lua.cpp.o CMakeFiles/flatc.dir/src/code_generators.cpp.o CMakeFiles/flatc.dir/grpc/src/compiler/cpp_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/go_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/java_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/python_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/swift_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/ts_generator.cc.o -o flatc   -latomic -lm \r\nRunning scripts/generate_code.py...\r\ncd /home/myname/myworkingdir/tflite.build.android/flatbuffers && /usr/bin/python3.9 scripts/generate_code.py --flatc /home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc --skip-gen-reflection\r\nTraceback (most recent call last):\r\n  File \"/home/myname/myworkingdir/tflite.build.android/flatbuffers/scripts/generate_code.py\", line 148, in <module>\r\n    flatc(\r\n  File \"/home/myname/myworkingdir/tflite.build.android/flatbuffers/scripts/generate_code.py\", line 82, in flatc\r\n    result = subprocess.run(cmd, cwd=str(cwd), check=True)\r\n  File \"/usr/lib/python3.9/subprocess.py\", line 505, in run\r\n    with Popen(*popenargs, **kwargs) as process:\r\n  File \"/usr/lib/python3.9/subprocess.py\", line 951, in __init__\r\n    self._execute_child(args, executable, preexec_fn, close_fds,\r\n  File \"/usr/lib/python3.9/subprocess.py\", line 1821, in _execute_child\r\n    raise child_exception_type(errno_num, err_msg, err_filename)\r\nOSError: [Errno 8] Exec format error: '/home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc'\r\nmake[2]: *** [_deps/flatbuffers-build/CMakeFiles/flatc.dir/build.make:566: _deps/flatbuffers-build/flatc] Error 1\r\nmake[2]: *** Deleting file '_deps/flatbuffers-build/flatc'\r\nmake[2]: Leaving directory '/home/myname/myworkingdir/tflite.build.android'\r\nmake[1]: *** [CMakeFiles/Makefile2:4720: _deps/flatbuffers-build/CMakeFiles/flatc.dir/all] Error 2\r\nmake[1]: Leaving directory '/home/myname/myworkingdir/tflite.build.android'\r\nmake: *** [Makefile:139: all] Error 2\r\n```\r\n</details></details>"
        },
        {
            "Timestamp": "2022-11-22T00:25:25Z",
            "EntityIds": [
                67419721,
                86464649,
                86464649
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "XY6UHWPZJUXY"
            ],
            "Context": "I managed to separately build flatc by:\r\n\r\n```\r\ngit clone https://github.com/google/flatbuffers.git\r\ncd flatbuffers && mkdir build && cd build\r\ncmake -G \"Unix Makefiles\" -DCMAKE_BUILD_TYPE=Release ..\r\nmake -j4\r\n```\r\nThen, when building Tensorflow Lite 2.11.0, I added `-DTFLITE_HOST_TOOLS_DIR=/home/myname/myworkingdir/flatbuffers/build` at configuration:\r\n\r\n```\r\ncmake -G \"Unix Makefiles\" -DCMAKE_SYSTEM_NAME=Android -DANDROID_ABI=arm64-v8a -DANDROID_STL=c++_shared -DANDROID_NATIVE_API_LEVEL=27 -DCMAKE_VERBOSE_MAKEFILE=ON -DCMAKE_TOOLCHAIN_FILE=$HOME/Android/Sdk/ndk/24.0.8215888/build/cmake/android.toolchain.cmake -DTFLITE_ENABLE_XNNPACK=ON -DTFLITE_ENABLE_GPU=ON -DTFLITE_ENABLE_NNAPI=ON -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=OFF -DTFLITE_HOST_TOOLS_DIR=/home/myname/myworkingdir/flatbuffers/build ../tensorflow/tensorflow/lite\r\n```\r\nI get this CMake warning:\r\n```\r\nCMake Warning:\r\n  Manually-specified variables were not used by the project:\r\n\r\n    TFLITE_HOST_TOOLS_DIR\r\n```\r\n, and the exact same error as before when building.\r\n\r\n"
        },
        {
            "Timestamp": "2022-11-23T06:31:02Z",
            "EntityIds": [
                67419721,
                86464649,
                86464649
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "XY6UHWPZJUXY"
            ],
            "Context": "Hi @DwayneDuane !\r\nThanks for sharing your observations.\r\n\r\n@sachinprasadhs !\r\nCould you look at this issue. \r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-21T16:47:45Z",
            "EntityIds": [
                105635332,
                111861663,
                111861663
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "I05VIW9LP90Q"
            ],
            "Context": "Select TensorFlow op(s), included in the given model, is(are) not supported by this interpreter.. <details><summary>Click to expand!</summary> \r\n \r\n ### Issue Type\r\n\r\nOthers\r\n\r\n### Source\r\n\r\nsource\r\n\r\n### Tensorflow Version\r\n\r\n2.10\r\n\r\n### Custom Code\r\n\r\nYes\r\n\r\n### OS Platform and Distribution\r\n\r\nUbuntu 18.04\r\n\r\n### Mobile device\r\n\r\narm64-v8a\r\n\r\n### Python version\r\n\r\n3.7\r\n\r\n### Bazel version\r\n\r\n5.3.0\r\n\r\n### GCC/Compiler version\r\n\r\n7.5\r\n\r\n### CUDA/cuDNN version\r\n\r\n_No response_\r\n\r\n### GPU model and memory\r\n\r\n_No response_\r\n\r\n### Current Behaviour?\r\n\r\n```shell\r\nGot an error \"Select TensorFlow op(s), included in the given model, is(are) not supported by this interpreter. Make sure you apply/link the Flex delegate before inference. For the Android, it can be resolved by adding \"org.tensorflow:tensorflow-lite-select-tf-ops\" dependency. See instructions: https://www.tensorflow.org/lite/guide/ops_select. Node number 83 (FlexErf) failed to prepare.\"\r\n```\r\n\r\n\r\n### Standalone code to reproduce the issue\r\n\r\n```shell\r\nHi, I try to make inference with flex delegate supported tflite model in Android(arm64-v8a) using C++ language. \r\nI have build tensorflowlite_flex lib and TensorflowLite as below using bazel command on ubuntu system : \r\n'''\r\nbazel build -c opt --cxxopt=--std=c++17 tensorflow/lite/delegates/flex:tensorflowlite_flex --config=monolithic --config=android_arm64 --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a\r\nbazel build -c opt --cxxopt=--std=c++17  //tensorflow/lite:tensorflowlite --config=android_arm64 --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a\r\n'''\r\n\r\nI linked that two library using CMake on Android Studio(Windows 10). \r\nSample CMake snippet:\r\n'''\r\nadd_library(tensorflowlite SHARED IMPORTED)\r\nset_target_properties( tensorflowlite PROPERTIES IMPORTED_LOCATION\r\n                    \"${CMAKE_CURRENT_SOURCE_DIR}/tflite_cpp/lib/arm64-v8a/libtensorflowlite.so\")\r\nadd_library(tensorflowlite_flex SHARED IMPORTED)\r\nset_target_properties( tensorflowlite_flex PROPERTIES IMPORTED_LOCATION\r\n                        \"${CMAKE_CURRENT_SOURCE_DIR}/tflite_cpp/lib/arm64-v8a/libtensorflowlite_flex.so\")\r\ntarget_link_libraries(\r\n        privacy_cpp\r\n        tensorflowlite\r\n        -Wl,--no-as-needed # Need --no-as-needed to link tensorflowlite_flex\r\n        tensorflowlite_flex\r\n        android)\r\n'''\r\n\r\nBut the error log shows \"Select TensorFlow op(s), included in the given model, is(are) not supported by this interpreter.\" What am I doing wrong here? Thank you.\r\n'''\r\nAAsset *model_fp= AAssetManager_open(mgr, \"torch_bert.tflite\", AASSET_MODE_STREAMING );\r\nsize_t size = AAsset_getLength(model_fp);\r\nchar * buf = new char[size];\r\nmemmove(buf, AAsset_getBuffer(model_fp), size);\r\nstd::unique_ptr<tflite::FlatBufferModel> model = tflite::FlatBufferModel::BuildFromBuffer((const char*)buf, size);\r\ntflite::ops::builtin::BuiltinOpResolver resolver;\r\ntflite::InterpreterBuilder(*model, resolver)(&interpreter);\r\n'''\r\n```\r\n\r\n\r\n### Relevant log output\r\n\r\n_No response_</details>\r\n<img width=\"908\" alt=\"tflite_error\" src=\"https://user-images.githubusercontent.com/105635332/203116570-e4b7a370-1f07-47c3-93c3-3cc47ec7db7b.png\">\r\n\r\n"
        },
        {
            "Timestamp": "2022-11-21T18:06:48Z",
            "EntityIds": [
                105635332,
                111861663,
                111861663
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "I05VIW9LP90Q"
            ],
            "Context": "@rr191211 \r\nCould you please add this following line before you convert the model:\r\n `converter.target_spec.supported_ops = [\r\n                                                   tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                                     tf.lite.OpsSet.SELECT_TF_OPS ]`\r\nPlease refer to the [Select TensorFlow operators](https://www.tensorflow.org/lite/guide/ops_select) and let us know if it helps.\r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-21T18:26:55Z",
            "EntityIds": [
                105635332,
                111861663,
                111861663
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "I05VIW9LP90Q"
            ],
            "Context": "> @rr191211 Could you please add this following line before you convert the model: `converter.target_spec.supported_ops = [ tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS ]` Please refer to the [Select TensorFlow operators](https://www.tensorflow.org/lite/guide/ops_select) and let us know if it helps.\r\n> \r\n> Thank you!\r\n\r\nThank you for your reply. Yes, I added \u201dtf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS\u201c when I convert tflite model, but still doesnt work. \r\n\r\n  # tf-->tflite\r\n    converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF_PATH)\r\n    converter.target_spec.supported_ops = [\r\n        tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\r\n        tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\r\n        ]\r\n    tflite_model = converter.convert()"
        },
        {
            "Timestamp": "2022-11-22T17:49:17Z",
            "EntityIds": [
                105635332,
                111861663,
                111861663
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "I05VIW9LP90Q"
            ],
            "Context": " I found a way to make it work  as per this https://github.com/tensorflow/tensorflow/issues/57033. "
        },
        {
            "Timestamp": "2022-11-21T14:03:03Z",
            "EntityIds": [
                74714236,
                81610181,
                81610181,
                56610014,
                56610014
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "FX7YB4RXOHZ9"
            ],
            "Context": "Wrong invert code in Keras Normalization Layer. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nsource\n\n### Tensorflow Version\n\ntf 2.10\n\n### Custom Code\n\nNo\n\n### OS Platform and Distribution\n\n_No response_\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n3.10\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nThe following code is an excerpt from `class Normalization` of `keras.layers.Normalization`.\r\n\r\n    def call(self, inputs):\r\n        inputs = self._standardize_inputs(inputs)\r\n        # The base layer automatically casts floating-point inputs, but we\r\n        # explicitly cast here to also allow integer inputs to be passed\r\n        inputs = tf.cast(inputs, self.compute_dtype)\r\n        if self.invert:\r\n            return (inputs + self.mean) * tf.maximum(\r\n                tf.sqrt(self.variance), backend.epsilon()\r\n            )\r\n        else:\r\n            return (inputs - self.mean) / tf.maximum(\r\n                tf.sqrt(self.variance), backend.epsilon()\r\n            )\r\n\r\nThe code in the `self.invert == True` branch does not invert the code in the `self.invert == False` branch as it shall according to the API documentation, which states that \"... layer ... would turn a normalized input back into its original form\".\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nThe correct code is:\r\n\r\n    def call(self, inputs):\r\n        inputs = self._standardize_inputs(inputs)\r\n        # The base layer automatically casts floating-point inputs, but we\r\n        # explicitly cast here to also allow integer inputs to be passed\r\n        inputs = tf.cast(inputs, self.compute_dtype)\r\n        if self.invert:\r\n            return self.mean + inputs * tf.maximum(\r\n                tf.sqrt(self.variance), backend.epsilon()\r\n            )\r\n        else:\r\n            return (inputs - self.mean) / tf.maximum(\r\n                tf.sqrt(self.variance), backend.epsilon()\r\n            )\n```\n\n\n### Relevant log output\n\n_No response_</details>"
        },
        {
            "Timestamp": "2022-11-21T14:14:02Z",
            "EntityIds": [
                74714236,
                81610181,
                81610181,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "FX7YB4RXOHZ9"
            ],
            "Context": "This is my first bug report and I am not sure I have filed all required information correctly, I am afraid. However, the bug is so trivial and obvious to me that I think this might not be necessary."
        },
        {
            "Timestamp": "2022-11-21T14:22:32Z",
            "EntityIds": [
                74714236,
                81610181,
                81610181,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "FX7YB4RXOHZ9"
            ],
            "Context": "The issue is fixed in 2.11. "
        },
        {
            "Timestamp": "2022-11-22T07:56:54Z",
            "EntityIds": [
                74714236,
                81610181,
                81610181,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "FX7YB4RXOHZ9"
            ],
            "Context": "@heptaflar,\r\nGlad the issue is resolved for you, please feel free to move this to closed status. Thank you!"
        },
        {
            "Timestamp": "2022-11-22T09:41:03Z",
            "EntityIds": [
                74714236,
                81610181,
                81610181,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "FX7YB4RXOHZ9"
            ],
            "Context": "OK - closed :-)"
        },
        {
            "Timestamp": "2022-11-22T09:41:05Z",
            "EntityIds": [
                74714236,
                81610181,
                81610181,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "FX7YB4RXOHZ9"
            ],
            "Context": "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58634\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58634\">No</a>\n"
        },
        {
            "Timestamp": "2022-11-22T09:42:03Z",
            "EntityIds": [
                74714236,
                81610181,
                81610181,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "FX7YB4RXOHZ9"
            ],
            "Context": "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58634\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58634\">No</a>\n"
        },
        {
            "Timestamp": "2022-11-21T12:00:10Z",
            "EntityIds": [
                96806369,
                86464649,
                86464649,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "CF47ZQVBBI9T"
            ],
            "Context": "TensorFlow Lite Quantization Debugger Issue. ### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04.3 \r\n- TensorFlow library (version, if pip package or github SHA, if built from source):tensorflow-gpu==2.10.0\r\n\r\n### 2. Code\r\n\r\ndef dense_block(inputs, filters):\r\n\r\n    y = Dense(units=filters,use_bias=False)(inputs)\r\n    y = BatchNormalization()(y)\r\n    return y\r\n\r\ndef model():\r\n    inputs = Input(shape = (112, 112, 3))\r\n    .\r\n    .\r\n    .\r\n    .\r\n    .\r\n    .\r\n    .\r\n    x = dense_block(x, 1)  -> (input_size=1,1,1,256, output_size=1,1,1,1)\r\n    return Model(inputs, x)\r\n\r\n### 3. conversion is successful,but the predicted value of int8 tflite has a large error value with the .pb weights file\r\nIf the conversion is successful, but the generated model is wrong, then state what is wrong:\r\n\r\n- Model produces wrong results and accuracy drop 7~15%.\r\n\r\n### 5. (optional) Any other info / logs\r\n\r\nQuestion1:\r\nMy weights .pb file is successfully quantized into an int8 tflite model.\r\nWhen doing tf.lite.experimental.QuantizationDebugger, the rmse/scale value of the last layer(Conv2D) is 2, which is far more than 0.289, but the rmse/scale values \u200b\u200bin other layers are all It is around 0.289, and if I change the output of the last layer to more nodes, the value of rmse/scale of the last layer will be closer to 0.289.\r\n\r\nDoes anyone know what could be causing this to happen?\r\nthanks!"
        },
        {
            "Timestamp": "2022-11-22T01:19:06Z",
            "EntityIds": [
                96806369,
                86464649,
                86464649,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "CF47ZQVBBI9T"
            ],
            "Context": "Hi @Dnlee17 !\r\nAgreed on your observations on scaling issues in quantization debugger.\r\nWould it be possible to share complete stand alone code as Colab gist to replicate this issue.\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-29T04:16:19Z",
            "EntityIds": [
                96806369,
                86464649,
                86464649,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "CF47ZQVBBI9T"
            ],
            "Context": "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n"
        },
        {
            "Timestamp": "2022-12-06T05:16:20Z",
            "EntityIds": [
                96806369,
                86464649,
                86464649,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "CF47ZQVBBI9T"
            ],
            "Context": "Closing as stale. Please reopen if you'd like to work on this further.\n"
        },
        {
            "Timestamp": "2022-12-06T05:16:23Z",
            "EntityIds": [
                96806369,
                86464649,
                86464649,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "CF47ZQVBBI9T"
            ],
            "Context": "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58633\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58633\">No</a>\n"
        },
        {
            "Timestamp": "2022-11-21T11:20:11Z",
            "EntityIds": [
                913790,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "FNOF8QNSEM1S"
            ],
            "Context": "[ROCm] Fixed gpu_kernel_tiling_test on RowReductionCorrectShmemUsage. Due to LLVM IR's changes, this test is broken and it needs to change accoridingly on ROCm side.\r\n\r\nThanks   /cc @cheshire "
        },
        {
            "Timestamp": "2022-11-21T11:20:11Z",
            "EntityIds": [
                913790,
                48215717
            ],
            "Symbol": "Pull Request",
            "Relational ID": [
                "FNOF8QNSEM1S"
            ],
            "Context": "[ROCm] Fixed gpu_kernel_tiling_test on RowReductionCorrectShmemUsage. Due to LLVM IR's changes, this test is broken and it needs to change accoridingly on ROCm side.\r\n\r\nThanks   /cc @cheshire "
        },
        {
            "Timestamp": "2022-11-21T10:13:28Z",
            "EntityIds": [
                92745698,
                111861663
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "UMP3222IPG72"
            ],
            "Context": "Spam. spam removed"
        },
        {
            "Timestamp": "2022-11-21T09:40:36Z",
            "EntityIds": [
                24700291,
                81610181,
                81610181,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "8DOKM1SBDJEV"
            ],
            "Context": "Bazel build failure. <details><summary>Click to expand!</summary> \r\n \r\n ### Issue Type\r\n\r\nBug\r\n\r\n### Source\r\n\r\nsource\r\n\r\n### Tensorflow Version\r\n\r\n2.4.1\r\n\r\n### Custom Code\r\n\r\nNo\r\n\r\n### OS Platform and Distribution\r\n\r\nLinux Ubuntu 18.04.6 LTS\r\n\r\n### Mobile device\r\n\r\n_No response_\r\n\r\n### Python version\r\n\r\n3.6.9\r\n\r\n### Bazel version\r\n\r\n3.1.0\r\n\r\n### GCC/Compiler version\r\n\r\n7.5.0\r\n\r\n### CUDA/cuDNN version\r\n\r\n_No response_\r\n\r\n### GPU model and memory\r\n\r\nJetson Nano, 32GB of memory\r\n\r\n### Current Behaviour?\r\n\r\nCompiling Tensorflow fails at the end of the process without being able to compile the pooling_ops_gpu file. I am trying to compile Tensorflow in order to enable the tflite_with_xnnpack flag\r\n\r\n\r\n\r\n### Standalone code to reproduce the issue\r\n\r\n```shell\r\nThis is the Tensorflow configuration pre-build \r\n\r\nYou have bazel 3.1.0- (@non-git) installed.\r\nPlease specify the location of python. [Default is /usr/bin/python3]: /usr/bin/python3\r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/lib/python3/dist-packages\r\n  /usr/local/lib/python3.6/dist-packages\r\n  /usr/lib/python3.6/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]: /usr/lib/python3/dist-packages\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: y\r\nTensorRT support will be enabled for TensorFlow.\r\n\r\nFound CUDA 10.2 in:\r\n    /usr/local/cuda-10.2/targets/aarch64-linux/lib\r\n    /usr/local/cuda-10.2/targets/aarch64-linux/include\r\nFound cuDNN 8 in:\r\n    /usr/lib/aarch64-linux-gnu\r\n    /usr/include\r\nFound TensorRT 7 in:\r\n    /usr/lib/aarch64-linux-gnu\r\n    /usr/include/aarch64-linux-gnu\r\n\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as \"x.y\" or \"compute_xy\" to include both virtual and binary GPU code, or as \"sm_xy\" to only include the binary code.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]: 5.3\r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: n\r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: /usr/bin/gcc\r\n\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -Wno-sign-compare]: -Wno-sign-compare\r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\n\r\nAnd this is the bezel build command used \r\n\r\nsudo bazel --host_jvm_args=-Xmx3278m build --config=opt --config=noaws --config=nogcp --config=nohdfs --config=nonccl --config=monolithic --config=cuda --config=v2 --local_cpu_resources=1 --define=tflite_pip_with_flex=true --copt=-ftree-vectorize --copt=-funsafe-math-optimizations --copt=-ftree-loop-vectorize --copt=-fomit-frame-pointer --define tflite_with_xnnpack=true //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n\r\n### Relevant log output\r\n\r\n```shell\r\nERROR: /home/user/tensorflow/tensorflow/core/kernels/BUILD:4193:1: C++ compilation of rule '//tensorflow/core/kernels:pooling_ops_gpu' failed (Exit 4)\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /home/user/tensorflow/tensorflow/python/tools/BUILD:226:1 C++ compilation of rule '//tensorflow/core/kernels:pooling_ops_gpu' failed (Exit 4)\r\nINFO: Elapsed time: 165525.324s, Critical Path: 2097.12s\r\nINFO: 13887 processes: 13887 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n</details>"
        },
        {
            "Timestamp": "2022-11-22T07:54:36Z",
            "EntityIds": [
                24700291,
                81610181,
                81610181,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "8DOKM1SBDJEV"
            ],
            "Context": "@zoythum,\r\nCould you please try installing TensorFlow v2.4 with Complier GCC 7.3.1, Bazel 3.1.0, CUDA 8.0 and Cudnn 11.0 and check if you are facing the same error. For more information please take a look at the tested build [configurations](https://www.tensorflow.org/install/source#gpu). Thank you!\r\n\r\n\r\n\r\n\r\n\r\nVersion | Python version | Compiler | Build tools | cuDNN | CUDA\r\n-- | -- | -- | -- | -- | --\r\ntensorflow-2.4.0 | 3.6-3.8 | GCC 7.3.1 | Bazel 3.1.0 | 8.0 | 11.0\r\n\r\n\r\n\r\n\r\n"
        },
        {
            "Timestamp": "2022-11-29T08:16:19Z",
            "EntityIds": [
                24700291,
                81610181,
                81610181,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "8DOKM1SBDJEV"
            ],
            "Context": "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n"
        },
        {
            "Timestamp": "2022-12-06T08:16:25Z",
            "EntityIds": [
                24700291,
                81610181,
                81610181,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "8DOKM1SBDJEV"
            ],
            "Context": "Closing as stale. Please reopen if you'd like to work on this further.\n"
        },
        {
            "Timestamp": "2022-12-06T08:16:31Z",
            "EntityIds": [
                24700291,
                81610181,
                81610181,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "8DOKM1SBDJEV"
            ],
            "Context": "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58630\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58630\">No</a>\n"
        },
        {
            "Timestamp": "2022-11-21T09:31:58Z",
            "EntityIds": [
                44562106,
                86464649,
                86464649,
                86464649,
                86464649,
                116063290,
                56610014
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "8NCU3549RU5X"
            ],
            "Context": " Cannot build with CUDA support on Windows.. <details><summary>Click to expand!</summary> \r\n \r\n ### Issue Type\r\n\r\nSupport\r\n\r\n### Source\r\n\r\nsource\r\n\r\n### Tensorflow Version\r\n\r\nTF 2.11\r\n\r\n### Custom Code\r\n\r\nNo\r\n\r\n### OS Platform and Distribution\r\n\r\nWindows 11\r\n\r\n### Mobile device\r\n\r\n_No response_\r\n\r\n### Python version\r\n\r\n3.10\r\n\r\n### Bazel version\r\n\r\n5.3.2\r\n\r\n### GCC/Compiler version\r\n\r\nMSVC 14.34.31933\r\n\r\n### CUDA/cuDNN version\r\n\r\n11.8/8.6\r\n\r\n### GPU model and memory\r\n\r\nRTX3090 24GB\r\n\r\n### Current Behaviour?\r\n\r\n```shell\r\nWhen I'm trying to build the latest stable version TensorFlow-GPU (2.11.0) with CUDA on windows as same as we used to do, I find the following Errors\r\n\r\n`WARNING: Cannot build with CUDA support on Windows. Starting in TF 2.11, CUDA build is not supported for Windows. To use TensorFlow GPU on Windows, you will need to build/install TensorFlow in WSL2.`\r\n\r\nThis error prevents me to set further CUDA and GPU info, as the consequence, I cannot build GPU version but only CPU version.\r\n```\r\n\r\n\r\n### Standalone code to reproduce the issue\r\n\r\n```shell\r\nAs a normal compiling procedure:\r\n\r\n\r\npython .\\configure.py\r\n```\r\n\r\n\r\n### Relevant log output\r\n\r\n```shell\r\nYou have bazel 5.3.2- (@non-git) installed.\r\nPlease specify the location of python. [Default is C:\\Users\\<username>\\miniconda3\\envs\\compile\\python.exe]:\r\n\r\nFound possible Python library paths:\r\n  C:\\Users\\<username>\\miniconda3\\envs\\compile\\Lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [C:\\Users\\<username>\\miniconda3\\envs\\compile\\Lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]:\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nWARNING: Cannot build with CUDA support on Windows.\r\nStarting in TF 2.11, CUDA build is not supported for Windows. For using TensorFlow GPU on Windows, you will need to build/install TensorFlow in WSL2.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /arch:AVX]:\r\n```\r\n</details>"
        },
        {
            "Timestamp": "2022-11-21T10:22:42Z",
            "EntityIds": [
                44562106,
                86464649,
                86464649,
                86464649,
                86464649,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "8NCU3549RU5X"
            ],
            "Context": "Hi @Zhaopudark !\r\nIt is correct from 2.11 onwards, we have to rely on [Tensorflow-Direct ML  plugin](https://github.com/microsoft/tensorflow-directml-plugin#tensorflow-directml-plugin-) / Windows Subsystem linux for GPU usage in windows machines.\r\n\r\nAttached relevant [thread ](https://learn.microsoft.com/en-us/windows/ai/directml/gpu-tensorflow-wsl) on Tensorflow direct ML  plugin for reference.\r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-23T19:12:56Z",
            "EntityIds": [
                44562106,
                86464649,
                86464649,
                86464649,
                86464649,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "8NCU3549RU5X"
            ],
            "Context": "@mohantym  Thanks a lot. \r\n\r\nI have been compiling and using the latest version of TensorFlow GPU on Windows for several years, which can always have all features supported on Linux, such as AVX2, XLA .etc., and can work well with other components, such as PowerShell, MySQL, Python, Conda .etc. It can even benefit from automatic GPU overclocking on Windows.\r\n\r\nIt may a little bit disappointing that since TF 2.11 onwards, the original Windows Platform will not be supported by TensorFlow GPU.  Anyway, thanks a lot for contributing to TF and making it better and better.\r\n\r\nNowadays, I have totally changed to WSL2, compiling and using TF2.11 GPU successfully. In my practice, there may be approximately a 4-5% performance loss if compared to the one on the original Window. But the cost is still acceptable.\r\n\r\nWSL2 may always be a less-than-correct and desirable choice.  Most users choose WSL2 may because some of the codes or components they need are not supported on Windows but are supported on Linux, and, they do not necessarily have two separate platforms. But from my point of view,  for most users, the codes and components they want are actually supported on Windows, it just requires them to invest some time to learn extra Windows operations and maintenance, such as the running mechanisms, the syntax of PowerShell or CMD, and the command line mode of other tools on Windows, and then, they can find a good and easy way to realize the desired codes or components on Windows well.\r\n\r\nThat is, the reason for most users not choosing the Window platform may be to save time, but if the Windows community is also active, users don't need to spend much time. And, if we always use new versions, the activity of the community is not so important. Because people who are willing to try new features are always in the minority, there is a limited amount of experience to refer to. Moreover, from my practice, I found the numbers of unexpected compiling bugs of a new TF version on both Linux and Windows are usually similar, which means the maintenance difficulty is probably similar between Linux and Windows.  Therefore, the sudden no-longer-supporting for original Windows is perplexing.\r\n\r\nLong term, if a user of a machine learning framework uses the Window platform, he/she will be seen as a unicorn. This is unfair because there is always someone who does not have that much money to support two separate platforms, or even three, and as a researcher, the Windows platform is naturally the most economical choice in order to cope with clerical work simultaneously. These people are even willing to spend more time learning Windows operation and maintenance for better usage of the machine learning frameworks but are often discriminated against for \"why don't use Mac and Linux servers?\".\r\n\r\nUsers' choices should not be discriminated against, but unfortunately, this no-longer-supporting for original Windows will make Windows users feel more discriminated, even if it is not the official intent. Even though maintaining one more platform will cost more manpower, I still hope the original Windows support will come back. \r\n\r\nThanks again and best wishes."
        },
        {
            "Timestamp": "2022-11-24T03:40:27Z",
            "EntityIds": [
                44562106,
                86464649,
                86464649,
                86464649,
                86464649,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "8NCU3549RU5X"
            ],
            "Context": "Hi @Zhaopudark !\r\nWe are not dropping windows support . You can still use Tensorflow-CPU in windows machines.\r\n\r\nIt is just that GPU support will be maintained by third party colloborators (Intel, AWS, ARM, linaro etc. ) considering the effort to maintain the integrity and  diversity of Tensorflow framework . [Ref](https://blog.tensorflow.org/2022/09/announcing-tensorflow-official-build-collaborators.html?_gl=1*fh5thm*_ga*MTY2ODE2Mjk4MC4xNjY0ODgxMDA0*_ga_W0YLR4190T*MTY2OTI2MTA1OC41Mi4xLjE2NjkyNjEwNjguMC4wLjA.)\r\n\r\n\r\nYou can use Tensorflow-Direct ML plugin in same windows machine as suggested in previous thread. \r\n(Note: A Windows user myself).\r\n\r\nThank you!\r\n\r\n\r\n\r\n"
        },
        {
            "Timestamp": "2022-11-25T09:14:40Z",
            "EntityIds": [
                44562106,
                86464649,
                86464649,
                86464649,
                86464649,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "8NCU3549RU5X"
            ],
            "Context": "@mohantym, thank you.\r\n\r\nI have also tried Tensorflow-Direct ML plugin. Even though it is convenient for its simple configuration, it is still in the development phase with less than complete functionality, such as does not support  XLA, mixed precision .etc. \r\n\r\nSo, now the situation may be that it is not available in a short term to use the latest version of Tensorflow-GPU or its equivalent replacement on Windows native platform as same as the original and without performance loss.\r\n\r\nHope this 'painful' period will end soon. \r\nThank you again, and thanks to all TensorFlow contributors/maintainers for your efforts."
        },
        {
            "Timestamp": "2022-11-28T05:41:32Z",
            "EntityIds": [
                44562106,
                86464649,
                86464649,
                86464649,
                86464649,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "8NCU3549RU5X"
            ],
            "Context": "@Zhaopudark !\r\nThanks for sharing your concern.\r\n\r\n@SuryanarayanaY !\r\nCould you look at this issue.\r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-28T07:44:49Z",
            "EntityIds": [
                44562106,
                86464649,
                86464649,
                86464649,
                86464649,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "8NCU3549RU5X"
            ],
            "Context": "@Zhaopudark,\r\n\r\nYour concerns regarding dropping the TF_GPU support on windows native is well noted and will be escalated to the concern team.But at present it is official from the [documentation](https://www.tensorflow.org/install/pip#windows-native) that:\r\n`TensorFlow 2.10 was the last TensorFlow release that supported GPU on native-Windows. Starting with TensorFlow 2.11, you will need to install [TensorFlow in WSL2](https://tensorflow.org/install/pip#windows-wsl2)` and there is little we can do here for now at least. \r\n\r\nI am not sure whether Windows native support can be extended in Future versions or not but also can't deny it. It's all based on requirements from community and Tensorflow Team is keenly watching the observations,concerns,inputs from community and may act accordingly. For time being as there is little we can do now shall we close this issue ? \r\n\r\nThankyou!\r\n\r\n"
        },
        {
            "Timestamp": "2022-11-28T16:46:35Z",
            "EntityIds": [
                44562106,
                86464649,
                86464649,
                86464649,
                86464649,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "8NCU3549RU5X"
            ],
            "Context": "@SuryanarayanaY \r\nThanks for your detailed information, I will always look forward to a better and widely supported TensorFlow. \r\nAnd, this issue can be closed.\r\nThank you."
        },
        {
            "Timestamp": "2022-11-28T16:46:40Z",
            "EntityIds": [
                44562106,
                86464649,
                86464649,
                86464649,
                86464649,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "8NCU3549RU5X"
            ],
            "Context": "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58629\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58629\">No</a>\n"
        },
        {
            "Timestamp": "2022-11-21T06:35:21Z",
            "EntityIds": [
                57779173,
                111861663,
                111861663,
                111861663,
                116063290,
                116063290,
                116063290
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "SPGA6TKRT5E2"
            ],
            "Context": "tf.distribute.experimental.rpc.Server memory leak on server. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nsource\n\n### Tensorflow Version\n\ntf 2.11\n\n### Custom Code\n\nNo\n\n### OS Platform and Distribution\n\nUbuntu 20.04\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n3.8\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n11.2/8.1\n\n### GPU model and memory\n\nNvidia GeForce RTX 2070 6233MB\n\n### Current Behaviour?\n\n```shell\nRPC works fine with CPU but when switched to GPU, memory increases linearly.\r\n(Memory stays constant after awhile with CPU)\r\n\r\nWhen training model, memory will keep increasing until desktop freezes.\r\n\r\nCode below to reproduce the issue on Google Colab.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\n# import os\r\n# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport portpicker\r\nimport matplotlib.pyplot as plt\r\n\r\nimport time\r\nimport os\r\nimport psutil\r\nprocess = psutil.Process(os.getpid())\r\n\r\n\r\n#tf.debugging.set_log_device_placement(True)\r\n\r\n\r\ndef test_simple():\r\n\r\n    @tf.function(input_signature=[\r\n        tf.TensorSpec([], tf.int32),\r\n        tf.TensorSpec([], tf.int32)])\r\n    @tf.autograph.experimental.do_not_convert  \r\n    def remote_fn(a, b):\r\n        return tf.add(a,b)\r\n\r\n    port = portpicker.pick_unused_port()\r\n    address = \"localhost:{}\".format(port)\r\n    server = tf.distribute.experimental.rpc.Server.create(\"grpc\", address)\r\n    server.register(\"addition\", remote_fn)\r\n    server.start()\r\n\r\n    client = tf.distribute.experimental.rpc.Client.create(\"grpc\",\r\n                address=address, name=\"test_client\")\r\n\r\n    a = np.ones(shape=[100, 256], dtype=np.int32)\r\n    b = np.ones(shape=[100, 256], dtype=np.int32)\r\n\r\n    hist = []\r\n    for i in range(100000):\r\n        result = client.call(\r\n            args=[a,b],\r\n            method_name=\"addition\",\r\n            output_specs=tf.TensorSpec((), tf.int32))\r\n        if result.is_ok():\r\n            result.get_value()\r\n        # value = client.addition_blocking(a,b)\r\n        # print(value)\r\n\r\n        if i % 1000 == 0:\r\n            print(i, \": \", process.memory_info().rss/1024/1024, \"MB\")\r\n            hist.append(process.memory_info().rss/1024/1024)\r\n\r\n    server.close()\r\n    print(\"After shutdown: \", process.memory_info().rss/1024/1024)\r\n    plt.plot(hist)\r\n    plt.show()\r\n\r\n\r\ntest_simple()\n```\n\n\n### Relevant log output\n\n```shell\n909000 :  1414.50390625 MB\r\n910000 :  1414.5078125 MB\r\n911000 :  1414.5078125 MB\r\n912000 :  1414.5078125 MB\r\n913000 :  1414.5078125 MB\r\n914000 :  1414.5078125 MB\r\n915000 :  1414.51171875 MB\r\n916000 :  1414.51171875 MB\r\n917000 :  1414.51171875 MB\r\n918000 :  1414.515625 MB\r\n919000 :  1415.6640625 MB\r\n920000 :  1416.796875 MB\r\n921000 :  1416.796875 MB\r\n922000 :  1416.796875 MB\r\n923000 :  1417.75 MB\r\n924000 :  1418.7109375 MB\r\n925000 :  1418.7109375 MB\r\n926000 :  1418.7109375 MB\r\n927000 :  1418.7109375 MB\r\n928000 :  1418.71484375 MB\r\n929000 :  1418.84765625 MB\r\n930000 :  1418.84765625 MB\r\n931000 :  1418.8515625 MB\r\n932000 :  1418.85546875 MB\r\n933000 :  1419.62890625 MB\r\n934000 :  1419.87890625 MB\r\n935000 :  1420.37890625 MB\r\n936000 :  1420.53125 MB\r\n937000 :  1420.65625 MB\r\n938000 :  1421.83984375 MB\r\n939000 :  1421.84375 MB\r\n940000 :  1422.74609375 MB\r\n941000 :  1422.84375 MB\r\n942000 :  1422.84375 MB\r\n943000 :  1423.3515625 MB\r\n944000 :  1423.8984375 MB\r\n945000 :  1423.91015625 MB\r\n946000 :  1425.5078125 MB\r\n947000 :  1426.109375 MB\r\n948000 :  1426.34765625 MB\r\n949000 :  1426.34765625 MB\r\n950000 :  1426.3515625 MB\r\n951000 :  1426.3515625 MB\r\n952000 :  1427.05859375 MB\r\n953000 :  1427.37890625 MB\r\n954000 :  1427.3828125 MB\r\n955000 :  1428.90234375 MB\r\n956000 :  1429.69140625 MB\r\n957000 :  1429.6953125 MB\r\n958000 :  1430.3046875 MB\r\n959000 :  1432.421875 MB\r\n960000 :  1432.421875 MB\r\n961000 :  1432.421875 MB\r\n962000 :  1432.82421875 MB\r\n963000 :  1432.82421875 MB\r\n964000 :  1432.82421875 MB\r\n965000 :  1433.1328125 MB\r\n966000 :  1433.1328125 MB\r\n967000 :  1433.1328125 MB\r\n968000 :  1433.1328125 MB\r\n969000 :  1434.60546875 MB\r\n970000 :  1434.60546875 MB\r\n971000 :  1434.640625 MB\r\n972000 :  1435.08203125 MB\r\n973000 :  1435.0859375 MB\r\n974000 :  1435.59765625 MB\r\n975000 :  1436.98828125 MB\r\n976000 :  1436.9921875 MB\r\n977000 :  1437.125 MB\r\n978000 :  1437.98828125 MB\r\n979000 :  1441.01953125 MB\r\n980000 :  1441.96875 MB\r\n981000 :  1441.96875 MB\r\n982000 :  1441.97265625 MB\r\n983000 :  1441.97265625 MB\r\n984000 :  1441.97265625 MB\r\n985000 :  1441.97265625 MB\r\n986000 :  1441.97265625 MB\r\n987000 :  1441.97265625 MB\r\n988000 :  1441.97265625 MB\r\n989000 :  1441.97265625 MB\r\n990000 :  1441.9765625 MB\r\n991000 :  1441.9765625 MB\r\n992000 :  1441.98046875 MB\r\n993000 :  1444.41796875 MB\r\n994000 :  1444.78515625 MB\r\n995000 :  1444.78515625 MB\r\n996000 :  1444.78515625 MB\r\n997000 :  1446.05078125 MB\r\n998000 :  1446.05078125 MB\r\n999000 :  1446.05078125 MB\r\nAfter shutdown:  1447.05078125\n```\n</details>"
        },
        {
            "Timestamp": "2022-11-21T17:52:51Z",
            "EntityIds": [
                57779173,
                111861663,
                111861663,
                111861663,
                116063290,
                116063290,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "SPGA6TKRT5E2"
            ],
            "Context": "@YHL04 \r\nI tried to reproduce the issue on Colab by using TF v2.11 but facing a different error. Could you please find the gist [here](https://colab.research.google.com/gist/tiruk007/42c560727caf381e6067e02122d426dc/58628.ipynb) for reference and confirm the same.\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-21T19:42:22Z",
            "EntityIds": [
                57779173,
                111861663,
                111861663,
                111861663,
                116063290,
                116063290,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "SPGA6TKRT5E2"
            ],
            "Context": "If you comment out the two lines it should run without error:\r\n\r\n    # server.close()\r\n    # print(\"After shutdown: \", process.memory_info().rss/1024/1024)\r\n\r\nbut the graph still shows memory increasing linearly"
        },
        {
            "Timestamp": "2022-11-23T17:15:02Z",
            "EntityIds": [
                57779173,
                111861663,
                111861663,
                111861663,
                116063290,
                116063290,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "SPGA6TKRT5E2"
            ],
            "Context": "@sushreebarsa \r\nI was able to reproduce the issue on Colab using TF v2.11. Please find the gist [here](https://colab.research.google.com/gist/tiruk007/05a199a20963576f1bf834d3f482f6da/58628.ipynb) for reference.\r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-24T07:03:29Z",
            "EntityIds": [
                57779173,
                111861663,
                111861663,
                111861663,
                116063290,
                116063290,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "SPGA6TKRT5E2"
            ],
            "Context": "@sushreebarsa @tiruk007 Just wondering if it will be a quick fix or what the plan is since my project is on a deadline...\r\nThank you."
        },
        {
            "Timestamp": "2022-11-24T11:31:06Z",
            "EntityIds": [
                57779173,
                111861663,
                111861663,
                111861663,
                116063290,
                116063290,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "SPGA6TKRT5E2"
            ],
            "Context": "@YHL04 ,\r\nI tested the code both on CPU and GPU.Even with CPU also i observe continuous increase in memory which is conflicting as you confirmed with CPU: `(Memory stays constant after awhile with CPU)` .Please refer to attached [gist](https://colab.research.google.com/gist/SuryanarayanaY/2add4fc6212b0f1206b5728fddf736ce/-58628-cpu.ipynb#scrollTo=XEjjhLzBQAsv) where i observed the same behaviour with CPU also.Please go through and confirm whether the CPU behaviour here is also same of GPU ?\r\nThankyou!"
        },
        {
            "Timestamp": "2022-11-24T19:26:46Z",
            "EntityIds": [
                57779173,
                111861663,
                111861663,
                111861663,
                116063290,
                116063290,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "SPGA6TKRT5E2"
            ],
            "Context": "Uncommented:\r\n\r\n```\r\nimport os\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\r\n```\r\n\r\nTF 2.9 CPU:\r\n\r\n![image](https://user-images.githubusercontent.com/57779173/203851276-797203bd-71a0-4d5f-bc78-1f13891758d8.png)\r\n\r\nTF 2.11 CPU:\r\n\r\n![image](https://user-images.githubusercontent.com/57779173/203852232-846ea5b3-b83a-47a9-af90-f32d6abd7c83.png)\r\n\r\nTF 2.11.0 CPU on my desktop:\r\nCommented out:\r\n\r\n```\r\n        # if result.is_ok():\r\n        #     result.get_value()\r\n        # value = client.addition_blocking(a,b).numpy()\r\n```\r\n\r\n![Figure_1](https://user-images.githubusercontent.com/57779173/203853127-a7c221c6-72aa-45cf-b090-bf6d65270bb3.png)\r\n\r\nNot sure why I wasn't able to reproduce the same result..."
        },
        {
            "Timestamp": "2022-11-25T07:45:24Z",
            "EntityIds": [
                57779173,
                111861663,
                111861663,
                111861663,
                116063290,
                116063290,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "SPGA6TKRT5E2"
            ],
            "Context": "Hi @YHL04 ,\r\nThanks for coming back again to confirm the behaviour on CPU.As you can also confirm the behaviour on CPU also the Memory is in increasing trend,can we confirm that it is not abnormal ? Could you share your opinion.\r\nThankyou!"
        },
        {
            "Timestamp": "2022-11-25T18:17:15Z",
            "EntityIds": [
                57779173,
                111861663,
                111861663,
                111861663,
                116063290,
                116063290,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "SPGA6TKRT5E2"
            ],
            "Context": "Hi @SuryanarayanaY, \r\nI'm not sure why the memory increase would be intended, especially when it ends up freezing the desktop, each Client call is independent and there is no reason to store anything after the Client call.\r\n\r\nIf the behavior is intended, could you please explain why?"
        },
        {
            "Timestamp": "2022-11-28T03:44:44Z",
            "EntityIds": [
                57779173,
                111861663,
                111861663,
                111861663,
                116063290,
                116063290,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "SPGA6TKRT5E2"
            ],
            "Context": "Hi @YHL04 ,\r\n\r\nIam not confirming yet it as intended behaviour. My intention is to confirm with you the whether the behaviour of Memory Increase is there both on CPU and GPU?\r\n\r\n@sachinprasadhs could you please look at the issue.\r\n\r\nThankyou!\r\n"
        },
        {
            "Timestamp": "2022-11-21T05:30:01Z",
            "EntityIds": [
                100826172,
                81610181,
                81610181,
                81610181,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "MV8TC51653ZF"
            ],
            "Context": "Failed to load the native TensorFlow runtime.. Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**:\r\n-   **TensorFlow version (use command below)**:\r\n-   **Python version**:\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n"
        },
        {
            "Timestamp": "2022-11-21T05:35:42Z",
            "EntityIds": [
                100826172,
                81610181,
                81610181,
                81610181,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "MV8TC51653ZF"
            ],
            "Context": "D:\\anaconda\\python.exe E:/\u4e13\u5229\u8bba\u6587/dag_classification_AfterQi.py\r\nTraceback (most recent call last):\r\n  File \"D:\\anaconda\\envs\\PSO\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"E:\\\u4e13\u5229\u8bba\u6587\\dag_classification_AfterQi.py\", line 10, in <module>\r\n    import tensorflow.compat.v1 as tf\r\n  File \"D:\\anaconda\\envs\\PSO\\Lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"D:\\anaconda\\envs\\PSO\\Lib\\site-packages\\tensorflow\\python\\__init__.py\", line 36, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"D:\\anaconda\\envs\\PSO\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 77, in <module>\r\n    raise ImportError(\r\nImportError: Traceback (most recent call last):\r\n  File \"D:\\anaconda\\envs\\PSO\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\r\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.\r\n\r\nProcess finished with exit code 1"
        },
        {
            "Timestamp": "2022-11-21T14:31:01Z",
            "EntityIds": [
                100826172,
                81610181,
                81610181,
                81610181,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "MV8TC51653ZF"
            ],
            "Context": "@tangjl2018,\r\nPlease provide the below details for debugging the issue.\r\nTensorFlow installed from (source or binary):\r\nTensorFlow version (use command below):\r\nPython version:\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version:\r\nGPU model and memory:\r\n "
        },
        {
            "Timestamp": "2022-11-21T14:32:00Z",
            "EntityIds": [
                100826172,
                81610181,
                81610181,
                81610181,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "MV8TC51653ZF"
            ],
            "Context": "Also please try **pip install tensorflow-cpu** instead of **pip install tensorflow** for CPU setup and refer to [Install TensorFlow with pip](https://www.tensorflow.org/install/pip) for GPU setup. Could you please refer to similar https://github.com/tensorflow/tensorflow/issues/45287 and https://github.com/tensorflow/tensorflow/issues/22794 for the reference. Thank you!\r\n\r\nThank you."
        },
        {
            "Timestamp": "2022-11-28T15:16:19Z",
            "EntityIds": [
                100826172,
                81610181,
                81610181,
                81610181,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "MV8TC51653ZF"
            ],
            "Context": "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n"
        },
        {
            "Timestamp": "2022-12-05T16:16:20Z",
            "EntityIds": [
                100826172,
                81610181,
                81610181,
                81610181,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "MV8TC51653ZF"
            ],
            "Context": "Closing as stale. Please reopen if you'd like to work on this further.\n"
        },
        {
            "Timestamp": "2022-12-05T16:16:23Z",
            "EntityIds": [
                100826172,
                81610181,
                81610181,
                81610181,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "MV8TC51653ZF"
            ],
            "Context": "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58627\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58627\">No</a>\n"
        },
        {
            "Timestamp": "2022-11-21T00:36:18Z",
            "EntityIds": [
                15100009,
                48215717,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "SI83L59VMQO0"
            ],
            "Context": "[XLA] Expose channel_id and use_global_device_ids of AllToAll in xla builder. Similar to AllReduce and AllGather, AllToAll also supports `channel_id` and `use_global_device_ids`, but these options are not exposed to the python API.\r\nThis PR exposes these options to the python API of XlaBuilder, following the same logic as AllReduce.\r\n"
        },
        {
            "Timestamp": "2022-11-21T00:39:01Z",
            "EntityIds": [
                15100009,
                48215717,
                48215717
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "SI83L59VMQO0"
            ],
            "Context": "cc @cheshire"
        },
        {
            "Timestamp": "2022-11-26T05:48:25Z",
            "EntityIds": [
                15100009,
                48215717,
                48215717
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "SI83L59VMQO0"
            ],
            "Context": "Hi @merrymercy Can you please check @cheshire's comments and keep us posted ? Thank you!"
        },
        {
            "Timestamp": "2022-11-27T07:06:07Z",
            "EntityIds": [
                15100009,
                48215717,
                48215717
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "SI83L59VMQO0"
            ],
            "Context": "A test case is added. Please review again @gbaned @cheshire "
        },
        {
            "Timestamp": "2022-11-21T00:36:18Z",
            "EntityIds": [
                15100009,
                48215717,
                48215717
            ],
            "Symbol": "Pull Request",
            "Relational ID": [
                "SI83L59VMQO0"
            ],
            "Context": "[XLA] Expose channel_id and use_global_device_ids of AllToAll in xla builder. Similar to AllReduce and AllGather, AllToAll also supports `channel_id` and `use_global_device_ids`, but these options are not exposed to the python API.\r\nThis PR exposes these options to the python API of XlaBuilder, following the same logic as AllReduce.\r\n"
        },
        {
            "Timestamp": "2022-11-21T00:19:21Z",
            "EntityIds": [
                15100009,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "GK6VOQ824M3Z"
            ],
            "Context": "[FIX] Fix integer overflow in XLA nccl thunks (cont.). Change `int` to `int64_t` to prevent integer overflow in XLA NCCL thunks.\r\n\r\nThis PR is the same as #57616. I am sorry that I didn't fix all of them in the first PR. Now I checked all types of `element_count` and confirmed all of them are fixed."
        },
        {
            "Timestamp": "2022-11-21T00:38:49Z",
            "EntityIds": [
                15100009,
                48215717
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "GK6VOQ824M3Z"
            ],
            "Context": "cc @cheshire"
        },
        {
            "Timestamp": "2022-11-27T07:05:45Z",
            "EntityIds": [
                15100009,
                48215717
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "GK6VOQ824M3Z"
            ],
            "Context": "When can we merge this? @cheshire @gbaned"
        },
        {
            "Timestamp": "2022-11-21T00:19:21Z",
            "EntityIds": [
                15100009,
                48215717
            ],
            "Symbol": "Pull Request",
            "Relational ID": [
                "GK6VOQ824M3Z"
            ],
            "Context": "[FIX] Fix integer overflow in XLA nccl thunks (cont.). Change `int` to `int64_t` to prevent integer overflow in XLA NCCL thunks.\r\n\r\nThis PR is the same as #57616. I am sorry that I didn't fix all of them in the first PR. Now I checked all types of `element_count` and confirmed all of them are fixed."
        },
        {
            "Timestamp": "2022-11-20T18:44:28Z",
            "EntityIds": [
                2053858,
                81610181,
                17670772,
                81610181,
                17670772,
                81610181
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "OM4I8TGUIPF4"
            ],
            "Context": "Nesting keras.Models makes tf.gradients() not update while training. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nbinary\n\n### Tensorflow Version\n\n2.10\n\n### Custom Code\n\nNo\n\n### OS Platform and Distribution\n\nLinux Ubuntu 20.04\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n3.8\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nNesting a keras.model  inside another one makes analytic gradients computed with tf.gradients() not update with training. On the toy example presented bellow, the inside network consists of a single multiplication with a trainable variable (i.e. Dense(1, use_bias=False)), computes derivative, and concatenas all 3 so  for input [x] output should be [x,a*x,a] (a is the traibale variable). Training this independently works as expected. \r\nBut if you nest that inside another keras.model(), even a trivial one that multiplies *2, devides /2 (i.e. no change) and then calls the inside model, the gradient computation is unchanged after training. so after you train, the output is [x,a*x,a0] where a0 is the initial weight (1.5 vs 2 in my toy example). \r\nComputing gradients with tf.GradientTape as in here also has the exact same behaviour  https://www.tensorflow.org/guide/advanced_autodiff\r\n\r\nMy 'real world' project involved solving a differential equation using https://github.com/titu1994/tf_SIREN  and switching bewteen training inside and outside model. As gradients dont work properly this way, my workaround was to inline the code of inside model to outside, keep 2 model instances and manual copy weights from one to the other which feels very hacky and I am sure is not indeded.\r\n\r\nTested on tf 2.6,2.8,2.10 , both Ubuntu/Windows and the behaviour is identical everywhere.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nimport numpy as np\r\nimport tensorflow as tf\r\ntf.random.set_seed(0)\r\n\r\nfrom tensorflow.keras.optimizers import Adam,SGD\r\nfrom tensorflow.keras import Input, Model,Sequential\r\nfrom tensorflow.keras.initializers import Constant\r\nfrom tensorflow.keras.layers import Layer, Dense\r\nfrom tensorflow.keras.layers import Concatenate, concatenate\r\n\r\n\r\ntf.compat.v1.disable_eager_execution()\r\n\r\n#trivial network doing multiplication by a single trainable variable\r\ndef inside_network():\r\n    x = Input(1)    \r\n        \r\n    layer=Dense(1,activation='linear',use_bias=False, kernel_initializer=Constant(value=1.5)) \r\n    y=layer(x)    \r\n\r\n    dy=tf.gradients(y,[x])[0]  \r\n    #for weight a, output should be [x, ax, a]\r\n    out= concatenate([x, y, dy],axis=-1)\r\n    \r\n    network = Model(inputs = x, outputs = out, name='inside_network')\r\n    \r\n    return network\r\n\r\ndef outside_network():\r\n    x = Input((1))      \r\n    y=2*x\r\n    y=y*0.5\r\n    model=inside_network()\r\n    y=model(y)\r\n    \r\n    outside_network = Model(inputs = x, outputs = y, name='outside_network')\r\n    return outside_network\r\n    \r\ndef get_first_weights(mod):\r\n    for layer in mod.layers:\r\n        w=layer.get_weights()\r\n        if len(w)>0:\r\n            return w\r\n\r\nNdata=1024\r\nnp.random.seed(0)\r\nxdata=np.random.rand(Ndata,1)\r\nxdata[0:4,0]=np.arange(0,4)\r\na=2.0\r\n\r\ndata_train_target=np.concatenate([xdata, a*xdata, a*np.ones((Ndata,1))],axis=-1)\r\nprint('input :4',xdata[:4,:])\r\nprint('target :4',data_train_target[:4,:])\r\n\r\nmodel1=inside_network()\r\n\r\nmodel1.compile(optimizer=Adam(1e-2),  loss='mae') #\r\nprint('dense layer weights before training',get_first_weights(model1))\r\n\r\nmodel1.fit(xdata,data_train_target,verbose=1,epochs=2,shuffle=True) #,batch_size=bs\r\n   \r\nprint('dense layer weights after training',get_first_weights(model1))\r\n           \r\ndataout=model1.predict(xdata)\r\nprint('dataout',dataout[0:4])\r\nprint('target',data_train_target[0:4,:])\r\n\r\nmodel2=outside_network()\r\n\r\nmodel2.compile(optimizer=Adam(1e-2),  loss='mae') #\r\n\r\nprint('dense layer weights before training',get_first_weights(model2))\r\n\r\n\r\n\r\nmodel2.fit(xdata,data_train_target,verbose=1,epochs=2,shuffle=True)\r\n\r\nprint('dense layer weights after training',get_first_weights(model2))\r\n\r\ndataout2=model2.predict(xdata)\r\nprint('dataout2',dataout2[0:4])\r\nprint(data_train_target[:4,:])\n```\n\n\n### Relevant log output\n\n```shell\ninput :4 [[0.]\r\n [1.]\r\n [2.]\r\n [3.]]\r\ntarget :4 [[0. 0. 2.]\r\n [1. 2. 2.]\r\n [2. 4. 2.]\r\n [3. 6. 2.]]\r\n2022-11-20 18:27:50.249131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-11-20 18:27:50.295560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-11-20 18:27:50.295870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-11-20 18:27:50.298148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-11-20 18:27:50.298388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-11-20 18:27:50.298603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-11-20 18:27:51.014096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-11-20 18:27:51.014341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-11-20 18:27:51.014531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-11-20 18:27:51.014710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8946 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:09:00.0, compute capability: 7.5\r\ndense layer weights before training [array([[1.5]], dtype=float32)]\r\nTrain on 1024 samples\r\nEpoch 1/2\r\n1024/1024 [==============================] - 1s 927us/sample - loss: 0.1731\r\nEpoch 2/2\r\n1024/1024 [==============================] - 0s 43us/sample - loss: 0.0320\r\ndense layer weights after training [array([[2.011962]], dtype=float32)]\r\n/home/flogothetis/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\r\n  updates=self.state_updates,\r\ndataout [[0.       0.       2.011962]\r\n [1.       2.011962 2.011962]\r\n [2.       4.023924 2.011962]\r\n [3.       6.035886 2.011962]]\r\ntarget [[0. 0. 2.]\r\n [1. 2. 2.]\r\n [2. 4. 2.]\r\n [3. 6. 2.]]\r\ndense layer weights before training [array([[1.5]], dtype=float32)]\r\nTrain on 1024 samples\r\nEpoch 1/2\r\n1024/1024 [==============================] - 0s 142us/sample - loss: 0.2240\r\nEpoch 2/2\r\n1024/1024 [==============================] - 0s 58us/sample - loss: 0.1774\r\ndense layer weights after training [array([[2.0133402]], dtype=float32)]\r\ndataout2 [[0.        0.        1.5      ]\r\n [1.        2.0133402 1.5      ]\r\n [2.        4.0266805 1.5      ]\r\n [3.        6.040021  1.5      ]]\r\n[[0. 0. 2.]\r\n [1. 2. 2.]\r\n [2. 4. 2.]\r\n [3. 6. 2.]]\n```\n</details>"
        },
        {
            "Timestamp": "2022-11-21T06:27:01Z",
            "EntityIds": [
                2053858,
                81610181,
                17670772,
                81610181,
                17670772,
                81610181
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "OM4I8TGUIPF4"
            ],
            "Context": "[tf.gradients](https://www.tensorflow.org/api_docs/python/tf/gradients) is only valid in a graph context. In particular, it is valid in the context of a [tf.function](https://www.tensorflow.org/api_docs/python/tf/function) wrapper, where code is executing as a graph."
        },
        {
            "Timestamp": "2022-11-21T14:25:00Z",
            "EntityIds": [
                2053858,
                81610181,
                17670772,
                81610181,
                17670772,
                81610181
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "OM4I8TGUIPF4"
            ],
            "Context": "@fotlogo,\r\nPlease take a look at above comment and also xs and ys are each a Tensor or a list of tensors. grad_ys is a list of Tensor, holding the gradients received by the ys. The list must be the same length as ys.\r\n\r\ngradients() adds ops to the graph to output the derivatives of ys with respect to xs. It returns a list of Tensor of length len(xs) where each tensor is the sum(dy/dx) for y in ys and for x in xs. Thank you!\r\n\r\n"
        },
        {
            "Timestamp": "2022-11-21T22:41:26Z",
            "EntityIds": [
                2053858,
                81610181,
                17670772,
                81610181,
                17670772,
                81610181
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "OM4I8TGUIPF4"
            ],
            "Context": "@svobora thank for the very quick reply! I was under the impression that including layer in a keras.model()  and then calling model.compile() and model.fit() guarantees that the code will run in graph mode. and in any case I have included the 'tf.compat.v1.disable_eager_execution() '  to make sure I only run in graph mode right ?\r\n@tilakrayal there should not be any sizing issues as the code runs fine (otherwise it will have generated a run time error) and indeed the fist part of the code training the inside_network() works exactly as expected  with the gradient being computed correctly (see the first part of my output)\r\nthe problem arises when you nest that code inside another model, and then the gradients are still computed but not being updated after the  training (final collumn of output being 1.5 were it should be 2)"
        },
        {
            "Timestamp": "2022-11-22T07:07:48Z",
            "EntityIds": [
                2053858,
                81610181,
                17670772,
                81610181,
                17670772,
                81610181
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "OM4I8TGUIPF4"
            ],
            "Context": "I think you are making a mistake in treatment of a Network (a sequence of tf layers) and a Model (an object to handle fitting). Just use layer sequences to form networks, then build a single Model on top of the however interconnected networks.\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ntf.random.set_seed(0)\r\n\r\nfrom tensorflow.keras.optimizers import Adam, SGD\r\nfrom tensorflow.keras import Input, Model, Sequential\r\nfrom tensorflow.keras.initializers import Constant\r\nfrom tensorflow.keras.layers import Layer, Dense\r\nfrom tensorflow.keras.layers import Concatenate, concatenate\r\n\r\ntf.compat.v1.disable_eager_execution()\r\n\r\n\r\n# trivial network doing multiplication by a single trainable variable\r\ndef inside_network(x):\r\n\r\n    layer = Dense(1, activation='linear', use_bias=False, kernel_initializer=Constant(value=1.5))\r\n    y = layer(x)\r\n\r\n    dy = tf.gradients(y, [x])[0]\r\n    # for weight a, output should be [x, ax, a]\r\n    out = concatenate([x, y, dy], axis=-1)\r\n\r\n    return out\r\n\r\n\r\ndef outside_network():\r\n    x = Input((1))\r\n    y = 2 * x\r\n    y = y * 0.5\r\n    y = inside_network(y)\r\n\r\n    outside_network = Model(inputs=x, outputs=y, name='outside_network')\r\n    return outside_network\r\n\r\n\r\ndef get_first_weights(mod):\r\n    for layer in mod.layers:\r\n        w = layer.get_weights()\r\n        if len(w) > 0:\r\n            return w\r\n\r\n\r\nNdata = 1024\r\nnp.random.seed(0)\r\nxdata = np.random.rand(Ndata, 1)\r\nxdata[0:4, 0] = np.arange(0, 4)\r\na = 2.0\r\n\r\ndata_train_target = np.concatenate([xdata, a * xdata, a * np.ones((Ndata, 1))], axis=-1)\r\nprint('input :4', xdata[:4, :])\r\nprint('target :4', data_train_target[:4, :])\r\n\r\nx = Input((1))\r\nmodel1 = Model(x, inside_network(x), name='inside_network')\r\n\r\nmodel1.compile(optimizer=Adam(1e-2), loss='mae')  #\r\nprint('dense layer weights before training', get_first_weights(model1))\r\n\r\nmodel1.fit(xdata, data_train_target, verbose=1, epochs=2, shuffle=True)  # ,batch_size=bs\r\n\r\nprint('dense layer weights after training', get_first_weights(model1))\r\n\r\ndataout = model1.predict(xdata)\r\nprint('dataout', dataout[0:4])\r\nprint('target', data_train_target[0:4, :])\r\n\r\nmodel2 = outside_network()\r\n\r\nmodel2.compile(optimizer=Adam(1e-2), loss='mae')  #\r\n\r\nprint('dense layer weights before training', get_first_weights(model2))\r\n\r\nmodel2.fit(xdata, data_train_target, verbose=1, epochs=2, shuffle=True)\r\n\r\nprint('dense layer weights after training', get_first_weights(model2))\r\n\r\ndataout2 = model2.predict(xdata)\r\nprint('dataout2', dataout2[0:4])\r\nprint(data_train_target[:4, :])\r\n```"
        },
        {
            "Timestamp": "2022-11-24T15:20:35Z",
            "EntityIds": [
                2053858,
                81610181,
                17670772,
                81610181,
                17670772,
                81610181
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "OM4I8TGUIPF4"
            ],
            "Context": "@svobora I see, I did not know that distinction !\r\n\r\nSo how can I pre-train the inside network before making the outside (to continue training )? Do I have to wrap the inside network in a tf.Module or tf.Layer object  and then copy weights ?"
        },
        {
            "Timestamp": "2022-11-28T13:36:36Z",
            "EntityIds": [
                2053858,
                81610181,
                17670772,
                81610181,
                17670772,
                81610181
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "OM4I8TGUIPF4"
            ],
            "Context": "@fotlogo,\r\nI was able to reproduce the issue on tensorflow v2.10, whereas on v2.11 I was facing a different issue. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/6b56b0071731ecd93ba446786f77037b/untitled786.ipynb). Thank you!"
        },
        {
            "Timestamp": "2022-12-04T20:33:15Z",
            "EntityIds": [
                2053858,
                81610181,
                17670772,
                81610181,
                17670772,
                81610181
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "OM4I8TGUIPF4"
            ],
            "Context": "@tilakrayal Sorry for the late reply ! According to the changelog in https://github.com/tensorflow/tensorflow/releases 'old' optimisers on 2.11 are moved in tensorflow.keras.optimizers.legacy . so by changing the import as from tensorflow.keras.optimizers.legacy import Adam,SGD the exact same behaviour as in 2.10 is observed.\r\nupdated the gist [here ](https://colab.research.google.com/gist/fotlogo/34cf3a1fef8f70c454b2243ac7e14760/untitled786.ipynb)\r\n\r\n"
        },
        {
            "Timestamp": "2022-11-20T16:15:50Z",
            "EntityIds": [
                38817737,
                73069040,
                86464649,
                67798621,
                67798621,
                73069040
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "ILXL5IO200NC"
            ],
            "Context": "Android 12 TensorFlow ML operations are not supported by GPU delegate. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nsource\n\n### Tensorflow Version\n\ntf 2.9\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\nAndroid 12 (API 31)\n\n### Mobile device\n\nGoogle Pixel 4\n\n### Python version\n\n_No response_\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nTensorflow lite pose estimation Crashed when switched to GPU.\r\nIt says some TF operations are not supported by GPU delegate.\r\nInterestingly when the API is 30 (Android 11) the app runs fine when changing to GPU CPU or NNAPI. No matter what tf model, Movenet lightning or thunder, int 8 or float 16.\r\n\r\nI tried it on the TF lite example post estimation APP, changed the compile and target sdk to 31, it crashed with the same error.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nfun create(context: Context, device: Device, modelType: ModelType): MoveNet {\r\n            val options = Interpreter.Options()\r\n            var gpuDelegate: GpuDelegate? = null\r\n            options.setNumThreads(CPU_NUM_THREADS)\r\n            when (device) {\r\n                Device.CPU -> {\r\n                }\r\n                Device.GPU -> {\r\n                    gpuDelegate = GpuDelegate()\r\n                    options.addDelegate(gpuDelegate)\r\n                }\r\n                Device.NNAPI -> options.setUseNNAPI(true)\r\n            }\r\n            return MoveNet(\r\n                Interpreter(\r\n                    FileUtil.loadMappedFile(\r\n                        context,\r\n                        if (modelType == ModelType.Lightning) LIGHTNING_FILENAME\r\n                        else THUNDER_FILENAME\r\n                    ), options\r\n                ),\r\n                gpuDelegate\r\n            )\r\n        }\n```\n\n\n### Relevant log output\n\n```shell\njava.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: Following operations are not supported by GPU delegate:\r\n    ARG_MAX: Operation is not supported.\r\n    CAST: Not supported cast case\r\n    CONCATENATION: OP is supported, but tensor type isn't matched!\r\n    FLOOR_DIV: OP is supported, but tensor type isn't matched!\r\n    GATHER_ND: Operation is not supported.\r\n    MUL: OP is supported, but tensor type isn't matched!\r\n    PACK: OP is supported, but tensor type isn't matched!\r\n    RESHAPE: OP is supported, but tensor type isn't matched!\r\n    SUB: OP\n```\n</details>"
        },
        {
            "Timestamp": "2022-11-21T05:09:53Z",
            "EntityIds": [
                38817737,
                73069040,
                86464649,
                67798621,
                67798621,
                73069040
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ILXL5IO200NC"
            ],
            "Context": "This is using Interpreter API. I tried the Object dection demo which uses Task API and Baseoptions and such. It worked on the same device Pixel 4 Android 12. However I don't think Task API has pose estimation or movenet support.\r\nhttps://www.tensorflow.org/lite/inference_with_metadata/task_library/overview\r\n\r\n"
        },
        {
            "Timestamp": "2022-11-22T03:30:32Z",
            "EntityIds": [
                38817737,
                73069040,
                86464649,
                67798621,
                67798621,
                73069040
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ILXL5IO200NC"
            ],
            "Context": "Hi @8700nd !\r\nThanks for sharing your observations on android 12 w.r.to Movenet (lightning model) and GPU delegates.\r\n\r\n@sachinprasadhs !\r\nCould you look at this issue.\r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-25T10:36:34Z",
            "EntityIds": [
                38817737,
                73069040,
                86464649,
                67798621,
                67798621,
                73069040
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ILXL5IO200NC"
            ],
            "Context": "Hi, any update on this!"
        },
        {
            "Timestamp": "2022-11-26T08:06:44Z",
            "EntityIds": [
                38817737,
                73069040,
                86464649,
                67798621,
                67798621,
                73069040
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ILXL5IO200NC"
            ],
            "Context": "Hello all, I have found the solution to fix it. [https://issuetracker.google.com/issues/183419289](https://issuetracker.google.com/issues/183419289)\r\n\r\nAdd the following in AndroidManifest.\r\n```\r\n<uses-native-library\r\n  android:name=\"libOpenCL-pixel.so\"\r\n  android:required=\"false\"/>\r\n```\r\n\r\nLooks like it's because since Android 12, we need to explicitly state the non-NDK library  \r\n> Non-NDK native shared libraries that are provided by silicon vendors or device manufacturers are not accessible by default if the app is targeting Android 12 (API level 31) or higher. The libraries are accessible only when they are explicitly requested using the <uses-native-library> tag.\r\n[uses-native-library](https://developer.android.com/guide/topics/manifest/uses-native-library-element)\r\n\r\nI'm not sure if there is other smarter way to do it instead of manually list out all the native libraries for each manufacturer or silicon vendor.\r\n"
        },
        {
            "Timestamp": "2022-11-28T12:32:23Z",
            "EntityIds": [
                38817737,
                73069040,
                86464649,
                67798621,
                67798621,
                73069040
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ILXL5IO200NC"
            ],
            "Context": "hey @8700nd , you're a lifesaver!\r\n\r\n1. when you said **\"manually list out all the native libraries for each manufacturer or silicon vendor\"** \r\nWhat were you referring to? Do we just add the snippet attached by you in the AndroidManifest or do we change the \"pixel.so\" specifically for each manufacturer.\r\n\r\n2. What's the on device fps you're getting with movenet now!!"
        },
        {
            "Timestamp": "2022-11-28T13:09:37Z",
            "EntityIds": [
                38817737,
                73069040,
                86464649,
                67798621,
                67798621,
                73069040
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ILXL5IO200NC"
            ],
            "Context": "Hello @madhavarora2002, \r\n1. I think we might need to add them all to AndroidManifest. What I was saying is it's very hard to manually find out what customized libs each manufacturers use and make our app support them\r\n2. Currently I get with Pixel 4 Snapdragon 855\r\nlightning fp16 CPU: 25~ GPU: 30+\r\nthunder int8 CPU: 15~ GPU: 20~ NNAPI: 20~\r\n\r\n"
        },
        {
            "Timestamp": "2022-11-29T20:09:59Z",
            "EntityIds": [
                38817737,
                73069040,
                86464649,
                67798621,
                67798621,
                73069040
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ILXL5IO200NC"
            ],
            "Context": "@8700nd , Are you still looking for a solution or the below workaround is sufficient?\r\nIf you feel below changes in the code can be generic, could you please create a PR for the same. Thanks!\r\n\r\n> Hello all, I have found the solution to fix it. https://issuetracker.google.com/issues/183419289\r\n> \r\n> Add the following in AndroidManifest.\r\n> \r\n> ```\r\n> <uses-native-library\r\n>   android:name=\"libOpenCL-pixel.so\"\r\n>   android:required=\"false\"/>\r\n> ```\r\n> \r\n> Looks like it's because since Android 12, we need to explicitly state the non-NDK library\r\n> \r\n> > Non-NDK native shared libraries that are provided by silicon vendors or device manufacturers are not accessible by default if the app is targeting Android 12 (API level 31) or higher. The libraries are accessible only when they are explicitly requested using the  tag.\r\n> > [uses-native-library](https://developer.android.com/guide/topics/manifest/uses-native-library-element)\r\n> \r\n> I'm not sure if there is other smarter way to do it instead of manually list out all the native libraries for each manufacturer or silicon vendor.\r\n\r\n"
        },
        {
            "Timestamp": "2022-12-01T02:00:44Z",
            "EntityIds": [
                38817737,
                73069040,
                86464649,
                67798621,
                67798621,
                73069040
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ILXL5IO200NC"
            ],
            "Context": "@sachinprasadhs I am not sure if this is a generic walkaround. But it works on my specific device."
        },
        {
            "Timestamp": "2022-11-20T15:45:02Z",
            "EntityIds": [
                26105224,
                111861663,
                111861663,
                86464649
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "ZB9I9Z1P3T2F"
            ],
            "Context": "Tensorflow lite dynamic input. ### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows 11\r\n- TensorFlow installation (pip package or built from source):\r\npip 2.10\r\n\r\n\r\n### 2. Code\r\ninputs = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')\r\nmodel = tf.keras.Model(inputs, inputs)\r\n\r\ninput_image - [(None, None, None,  3)]\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\n\r\ninput_image - [1 1 1 3]"
        },
        {
            "Timestamp": "2022-11-21T17:58:55Z",
            "EntityIds": [
                26105224,
                111861663,
                111861663,
                86464649
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ZB9I9Z1P3T2F"
            ],
            "Context": "@sonfire186 \r\nCould you please elaborate on the issue reported here and provide a complete code snippet to reproduce the issue.\r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-22T11:11:11Z",
            "EntityIds": [
                26105224,
                111861663,
                111861663,
                86464649
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ZB9I9Z1P3T2F"
            ],
            "Context": "@tiruk007 \r\n```\r\ninputs = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')\r\nmodel = tf.keras.Model(inputs, inputs, name='light_level_detection')\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\n\r\nwith open('model.tflite', 'wb') as f:\r\n    f.write(tflite_model)\r\n\r\ninterpreter = tf.lite.Interpreter(model_path='model.tflite')\r\ninterpreter.allocate_tensors()\r\n\r\n# Print input shape and type\r\ninputs = interpreter.get_input_details()\r\nprint('{} input(s):'.format(len(inputs)))\r\nfor i in range(0, len(inputs)):\r\n    print('{} {}'.format(inputs[i]['shape'], inputs[i]['dtype']))\r\n\r\n# Print output shape and type\r\noutputs = interpreter.get_output_details()\r\nprint('\\n{} output(s):'.format(len(outputs)))\r\nfor i in range(0, len(outputs)):\r\n    print('{} {}'.format(outputs[i]['shape'], outputs[i]['dtype']))\r\n```\r\n\r\n\r\n\r\n```\r\n1 input(s):\r\n[1 1 1 3] <class 'numpy.float32'>\r\n\r\n1 output(s):\r\n[1 1 1 3] <class 'numpy.int32'>\r\n```"
        },
        {
            "Timestamp": "2022-11-24T04:15:12Z",
            "EntityIds": [
                26105224,
                111861663,
                111861663,
                86464649
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ZB9I9Z1P3T2F"
            ],
            "Context": "Hi @sonfire186 !\r\nThanks for bringing  the feature request on Dynamic input. We have already informed the concerned team about this earlier.\r\n\r\nCurrent workaround is give static shape using [model binding](https://www.tensorflow.org/lite/inference_with_metadata/codegen#mlbinding) before deploying in android.\r\n\r\n@sachinprasadhs !\r\nCould you look at this feature request.\r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-24T07:05:23Z",
            "EntityIds": [
                26105224,
                111861663,
                111861663,
                86464649
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "ZB9I9Z1P3T2F"
            ],
            "Context": "@mohantym \r\n\r\n`interpreter.resizeInput`\r\n\r\njava.lang.OutOfMemoryError: Failed to allocate a 144384016 byte allocation with 25165824 free bytes and 68MB until OOM, target footprint 356191760, growth limit 402653184\r\n\r\n\r\n"
        },
        {
            "Timestamp": "2022-11-20T13:16:10Z",
            "EntityIds": [
                17670772,
                81610181,
                81610181,
                81610181,
                56610014
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "S11H69JGWPS5"
            ],
            "Context": "Invalid argument in example. <details><summary>Click to expand!</summary> \r\n \r\n ### Issue Type\r\n\r\nBug\r\n\r\n### Source\r\n\r\nbinary\r\n\r\n### Tensorflow Version\r\n\r\n2.11\r\n\r\n### Custom Code\r\n\r\nNo\r\n\r\n### OS Platform and Distribution\r\n\r\nLinux Ubuntu 22.04.1\r\n\r\n### Mobile device\r\n\r\n_No response_\r\n\r\n### Python version\r\n\r\n3.10\r\n\r\n### Bazel version\r\n\r\n_No response_\r\n\r\n### GCC/Compiler version\r\n\r\n_No response_\r\n\r\n### CUDA/cuDNN version\r\n\r\n11.2\r\n\r\n### GPU model and memory\r\n\r\nRTX 3090 24GB\r\n\r\n### Current Behaviour?\r\n\r\n```shell\r\nThis example returns invalid argument message, but it still runs. I wonder if that is a warning or error.\r\n\r\nhttps://www.tensorflow.org/tutorials/images/classification\r\n```\r\n\r\n\r\n### Standalone code to reproduce the issue\r\n\r\nhttps://www.tensorflow.org/tutorials/images/classification\r\n\r\n\r\n\r\n### Relevant log output\r\n\r\n```shell\r\nlayout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_2/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\r\n```\r\n</details>"
        },
        {
            "Timestamp": "2022-11-21T11:19:43Z",
            "EntityIds": [
                17670772,
                81610181,
                81610181,
                81610181,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "S11H69JGWPS5"
            ],
            "Context": "@svobora,\r\nI tried to execute the given code in the latest stable version and was able to execute without the [error](https://colab.research.google.com/gist/tilakrayal/55eb4e612b0e4058064fb2f24e418f9f/classification.ipynb). The source code of the mentioned doc link also doesn't contain the error. So the document will get updated soon without the error for the future versions. Thank you!"
        },
        {
            "Timestamp": "2022-11-25T13:11:54Z",
            "EntityIds": [
                17670772,
                81610181,
                81610181,
                81610181,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "S11H69JGWPS5"
            ],
            "Context": "The same warning/error happens to my nets using Dropout in Ubuntu 22.04 with TF 2.11.0 when using GPU. Did not happen with 2.10.0. Cannot confirm on Windows since GPU support was dropped in latest version of TF. Right now it seems it does not affect performance.\r\n"
        },
        {
            "Timestamp": "2022-11-28T13:39:22Z",
            "EntityIds": [
                17670772,
                81610181,
                81610181,
                81610181,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "S11H69JGWPS5"
            ],
            "Context": "@svobora,\r\nAs mentioned the code was executed without any [issues](https://colab.research.google.com/gist/tilakrayal/55eb4e612b0e4058064fb2f24e418f9f/classification.ipynb) and the document will get updated soon without the error for the future tensorflow  versions. Thank you!"
        },
        {
            "Timestamp": "2022-12-05T14:16:19Z",
            "EntityIds": [
                17670772,
                81610181,
                81610181,
                81610181,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "S11H69JGWPS5"
            ],
            "Context": "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n"
        },
        {
            "Timestamp": "2022-11-20T03:29:04Z",
            "EntityIds": [
                22030060,
                86464649,
                95025816,
                86464649,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "MNPYJ3BVMXLS"
            ],
            "Context": "TF 2.11 Error: ModuleNotFoundError: No module named 'tensorflow.compat'. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nbinary\n\n### Tensorflow Version\n\n2.11\n\n### Custom Code\n\nNo\n\n### OS Platform and Distribution\n\nWindows 11\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n3.10.04\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nI tried training my model that used the functional API and got this error:\r\n\r\nModuleNotFoundError: No module named 'tensorflow.compat'\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nDon't have it.\n```\n\n\n### Relevant log output\n\n```shell\nfrom keras.layers import MaxPooling1D\r\n  File \"C:\\Development\\Python\\Python3104\\lib\\site-packages\\keras\\__init__.py\", line 21, in <module>\r\n    from keras import models\r\n  File \"C:\\Development\\Python\\Python3104\\lib\\site-packages\\keras\\models\\__init__.py\", line 18, in <module>\r\n    from keras.engine.functional import Functional\r\n  File \"C:\\Development\\Python\\Python3104\\lib\\site-packages\\keras\\engine\\functional.py\", line 24, in <module>\r\n    import tensorflow.compat.v2 as tf\r\nModuleNotFoundError: No module named 'tensorflow.compat'\n```\n</details>"
        },
        {
            "Timestamp": "2022-11-20T08:31:04Z",
            "EntityIds": [
                22030060,
                86464649,
                95025816,
                86464649,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "MNPYJ3BVMXLS"
            ],
            "Context": "@nectario If you scrolled down a bit more in the issues page, you would've found it... https://github.com/tensorflow/tensorflow/issues/58610"
        },
        {
            "Timestamp": "2022-11-21T04:36:11Z",
            "EntityIds": [
                22030060,
                86464649,
                95025816,
                86464649,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "MNPYJ3BVMXLS"
            ],
            "Context": "Hi @nectario !\r\ncan we consider this as duplicate to #58610.\r\nThank you! "
        },
        {
            "Timestamp": "2022-11-28T12:16:19Z",
            "EntityIds": [
                22030060,
                86464649,
                95025816,
                86464649,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "MNPYJ3BVMXLS"
            ],
            "Context": "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n"
        },
        {
            "Timestamp": "2022-12-05T13:16:23Z",
            "EntityIds": [
                22030060,
                86464649,
                95025816,
                86464649,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "MNPYJ3BVMXLS"
            ],
            "Context": "Closing as stale. Please reopen if you'd like to work on this further.\n"
        },
        {
            "Timestamp": "2022-12-05T13:16:27Z",
            "EntityIds": [
                22030060,
                86464649,
                95025816,
                86464649,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "MNPYJ3BVMXLS"
            ],
            "Context": "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58620\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58620\">No</a>\n"
        },
        {
            "Timestamp": "2022-11-19T16:34:26Z",
            "EntityIds": [
                53497039,
                84765720,
                111861663
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "5RZ94G7NXKUQ"
            ],
            "Context": "The experimental lcm function gives wrong result. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nsource\n\n### Tensorflow Version\n\n2.9.2\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\nLinux (Google Colab)\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n3.7.15\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nHi. The code below shows the lcm for 21 and 7 is output as 15 for TensorFlow while it should clearly be 21. NumPy and JAX give the correct result of 21. This is the case for int8 although the output value is certainly not high enough to be causing any overflows etc. The result in case of int16 or higher is accurate (21). However, if the values were 2100 and 70 the result would be inaccurate for int16 in tensorflow again as opposed to np and jax.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nat = tf.constant([21], dtype=tf.int8)\r\nbt = tf.constant([7], dtype=tf.int8)\r\n\r\nan = np.array([21], dtype=np.int8)\r\nbn = np.array([7], dtype=jnp.int8)\r\n\r\nprint(\"tensorflow: \", tf.experimental.numpy.lcm(at, bt))\r\nprint(\"numpy: \", np.lcm(an,bn))\n```\n\n\n### Relevant log output\n\n```shell\ntensorflow:  tf.Tensor([15], shape=(1,), dtype=int8)\r\nnumpy:  [21]\n```\n</details>"
        },
        {
            "Timestamp": "2022-11-21T17:17:53Z",
            "EntityIds": [
                53497039,
                84765720,
                111861663
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "5RZ94G7NXKUQ"
            ],
            "Context": "@sushreebarsa \r\nI was able to  reproduce the issue on Colab by using TF-nightly, TF v2.9.2 and TF v2.10.1. Please find the gist [here](https://colab.research.google.com/gist/tiruk007/f23b2dbd292720925b0d70dc3e72c718/58619.ipynb) for reference.\r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-19T16:28:39Z",
            "EntityIds": [
                2458806,
                81610181,
                81610181,
                116063290
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "US3MEELSX6I5"
            ],
            "Context": "Compiling libtensorflow for ios issues : can't fine Eigen/Core. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBuild/Install\n\n### Source\n\nsource\n\n### Tensorflow Version\n\ntf 2.10\n\n### Custom Code\n\nNo\n\n### OS Platform and Distribution\n\nMacOs ventura 13.0\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n_No response_\n\n### Bazel version\n\n5.3.2\n\n### GCC/Compiler version\n\nclang 14.0 (Xcode shipped)\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nHello !\r\n\r\nI am not able to build libtensorflow.so for ios.\r\nI just `./configure` and accepted all defaults.\r\n\r\nI can build for my mac:\r\n`bazel build -c opt //tensorflow:libtensorflow.so`\r\nbut cross compiling for ios\r\n`bazel build -c opt --config=ios //tensorflow:libtensorflow.so`\r\n\r\ngives me this error\r\n\r\n`\r\nERROR: /Users/SX/Documents/soundx-ai/vendor/tensorflow/tensorflow/cc/saved_model/BUILD:319:11: Compiling tensorflow/cc/saved_model/metrics.cc failed: (Aborted): wrapped_clang_pp failed: error executing command external/local_config_cc/wrapped_clang_pp '-D_FORTIFY_SOURCE=1' -fstack-protector -fcolor-diagnostics -Wall -Wthread-safety -Wself-assign -fno-omit-frame-pointer -g0 -O2 -DNDEBUG ... (remaining 32 arguments skipped)\r\nIn file included from tensorflow/cc/saved_model/metrics.cc:16:\r\nIn file included from ./tensorflow/cc/saved_model/metrics.h:25:\r\nIn file included from ./tensorflow/core/lib/monitoring/counter.h:19:\r\nIn file included from ./tensorflow/tsl/lib/monitoring/counter.h:85:\r\nIn file included from ./tensorflow/tsl/lib/monitoring/collection_registry.h:109:\r\nIn file included from ./tensorflow/tsl/lib/monitoring/collected_metrics.h:28:\r\nIn file included from ./tensorflow/tsl/lib/monitoring/metric_def.h:24:\r\nIn file included from ./tensorflow/tsl/lib/monitoring/types.h:22:\r\nIn file included from ./tensorflow/tsl/platform/types.h:21:\r\nIn file included from ./tensorflow/tsl/platform/bfloat16.h:20:\r\n./third_party/eigen3/Eigen/Core:1:10: fatal error: 'Eigen/Core' file not found\r\n#include \"Eigen/Core\"\r\n```\r\n\r\nI have a eigen3 lib installed with brew, in my `/opt/homebrew/Cellar/eigen/3.4.0_1/include/eigen3/Eigen/Core`, but I did not get how I could give this information to bazel. I'm not able to play with the path directly.\r\n\r\nAny clue to solve this problem ?\r\n\r\nThank you!\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nbazel build -c opt --config=ios //tensorflow:libtensorflow.so\n```\n\n\n### Relevant log output\n\n_No response_</details>"
        },
        {
            "Timestamp": "2022-11-19T16:52:10Z",
            "EntityIds": [
                2458806,
                81610181,
                81610181,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "US3MEELSX6I5"
            ],
            "Context": "_OK I was able to solve my problem myself. I had to manually call the bazel rule \"install_eigen_headers\" from third_party/eigen3\r\n\r\nIs it normal I have to call it myself ?_\r\n\r\n\r\nOK sorry in fact, the compilation order was changed but the error is here again :/ "
        },
        {
            "Timestamp": "2022-11-21T07:58:43Z",
            "EntityIds": [
                2458806,
                81610181,
                81610181,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "US3MEELSX6I5"
            ],
            "Context": "@simdax,\r\nCould you please try installing TensorFlow v2.10 with compiler `Clang from xcode 10.14` with `Bazel 5.1.1` as those are tested build configurations & please take a look at this official doc [link](https://www.tensorflow.org/install/source#cpu_2) for the reference and check if you are facing the same error. Thank you!\r\n"
        },
        {
            "Timestamp": "2022-11-21T21:20:34Z",
            "EntityIds": [
                2458806,
                81610181,
                81610181,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "US3MEELSX6I5"
            ],
            "Context": "I believe the link you point don't reference the version I'm trying to build, a.k.a ios, not macos. MacOs build fine :)\r\n"
        },
        {
            "Timestamp": "2022-11-21T21:27:32Z",
            "EntityIds": [
                2458806,
                81610181,
                81610181,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "US3MEELSX6I5"
            ],
            "Context": "I can be even more specific. One of the failing project is \r\nsaved_model:util\r\n\r\n`bazel build -c opt //tensorflow/cc/saved_model:util` works\r\n`bazel build -c opt //tensorflow/cc/saved_model:util --config=ios` don't works"
        },
        {
            "Timestamp": "2022-11-24T15:27:30Z",
            "EntityIds": [
                2458806,
                81610181,
                81610181,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "US3MEELSX6I5"
            ],
            "Context": "Hi @simdax ,\r\n\r\nCould you please confirm what option you have chosen while configuring `./configure` for below option.\r\n\r\n`Do you wish to build TensorFlow with iOS support? [y/N]:`\r\n\r\nIf you missed choosing `y`  then it might not be supporting IOS. Please cross check and try with `y` option for above configuration part and lets know if still facing issue.\r\n\r\nThankyou!"
        },
        {
            "Timestamp": "2022-11-24T15:40:37Z",
            "EntityIds": [
                2458806,
                81610181,
                81610181,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "US3MEELSX6I5"
            ],
            "Context": "Yes I can confirm that. One of the problem is linked to the \"if_mobile\" option in bazel. All the sources built with it failed.\r\nI think TF is assuming building for IOS need to be TFlite, which is not my case ?"
        },
        {
            "Timestamp": "2022-11-19T12:53:43Z",
            "EntityIds": [
                33950866,
                48215717,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "5R7NKMLGJPX4"
            ],
            "Context": "the priority of H2D. Question\uff1ahttps://github.com/tensorflow/tensorflow/issues/58616\r\nModify:\r\nWe distinguish FeaturesAsyncH2D and ComputeH2D, and raise the priority of ComputeH2D and lower the priority of FeaturesAsyncH2D.\r\nResult:\r\n<img width=\"1678\" alt=\"image\" src=\"https://user-images.githubusercontent.com/33950866/202851818-03031f51-a0df-4feb-a6b1-30203096a523.png\">\r\n\r\n**Due to busy work, if you find this feature useful, I will complete my PR later.**\r\n\r\n"
        },
        {
            "Timestamp": "2022-11-24T23:24:03Z",
            "EntityIds": [
                33950866,
                48215717,
                48215717
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "5R7NKMLGJPX4"
            ],
            "Context": "@zhaozheng09 Can you please resolve conflicts? Thank you!"
        },
        {
            "Timestamp": "2022-11-25T02:57:13Z",
            "EntityIds": [
                33950866,
                48215717,
                48215717
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "5R7NKMLGJPX4"
            ],
            "Context": "> @zhaozheng09 Can you please resolve conflicts? Thank you!\r\n\r\nDone,"
        },
        {
            "Timestamp": "2022-11-19T12:53:43Z",
            "EntityIds": [
                33950866,
                48215717,
                48215717
            ],
            "Symbol": "Pull Request",
            "Relational ID": [
                "5R7NKMLGJPX4"
            ],
            "Context": "the priority of H2D. Question\uff1ahttps://github.com/tensorflow/tensorflow/issues/58616\r\nModify:\r\nWe distinguish FeaturesAsyncH2D and ComputeH2D, and raise the priority of ComputeH2D and lower the priority of FeaturesAsyncH2D.\r\nResult:\r\n<img width=\"1678\" alt=\"image\" src=\"https://user-images.githubusercontent.com/33950866/202851818-03031f51-a0df-4feb-a6b1-30203096a523.png\">\r\n\r\n**Due to busy work, if you find this feature useful, I will complete my PR later.**\r\n\r\n"
        },
        {
            "Timestamp": "2022-11-19T12:36:22Z",
            "EntityIds": [
                33950866,
                86464649,
                86464649,
                86464649
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "279PXSN1H5SG"
            ],
            "Context": "ComputeH2D is more priority than FeaturesH2D. <details><summary>Click to expand!</summary> \r\n \r\n ### Issue Type\r\n\r\nPerformance\r\n\r\n### Source\r\n\r\nsource\r\n\r\n### Tensorflow Version\r\n\r\n2.8\r\n\r\n### Custom Code\r\n\r\nYes\r\n\r\n### OS Platform and Distribution\r\n\r\nLinux\r\n\r\n### Mobile device\r\n\r\nno\r\n\r\n### Python version\r\n\r\n2.7\r\n\r\n### Bazel version\r\n\r\nmaster\r\n\r\n### GCC/Compiler version\r\n\r\n10.2.0\r\n\r\n### CUDA/cuDNN version\r\n\r\nCUDA Version: 11.4\r\n\r\n### GPU model and memory\r\n\r\nyes\r\n\r\n### Current Behaviour?\r\n\r\n**BackGround 1**: CUDA only support once H2D in same time .\r\n**BackGround 2**: \r\n  1. FeaturesAsyncH2D: TrainingData H2D by `dataset.prefetch_to_device`\r\n  2. ComputeH2D: Some small H2D in Op. for example: DynamicPartitionOpGPU: CPU compute output size, and then transfer size to GPU.\r\n\r\n**BackGround 3**: ComputeH2D maybe block current compute, and FeaturesAsyncH2D is needed to next few steps, so ComputeH2D is more important than FeaturesAsyncH2D.\r\n\r\nWhen lots of features need AsyncH2D, they maybe block ComputeH2D, because TF don't distinguish the priority of ComputeH2D and FeaturesAsyncH2D. \r\nwe use nsys to recurrent this bug:\r\n<img width=\"1560\" alt=\"image\" src=\"https://user-images.githubusercontent.com/33950866/202851210-cb72e589-9dec-4a85-a35b-365b63ace052.png\">\r\n\r\n</details>"
        },
        {
            "Timestamp": "2022-11-21T03:46:41Z",
            "EntityIds": [
                33950866,
                86464649,
                86464649,
                86464649
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "279PXSN1H5SG"
            ],
            "Context": "Hi @zhaozheng09 !\r\n\r\nThanks for sharing your observations and the PR #58617 .\r\n\r\nBut I see Python 2.7 in above Template. ( Ignoring Cuda 11.4 and GCC 10.2 which are not included in Test config ( 9.3 , Cuda 11.2 and cudnn 8.1))\r\n\r\nJust curious to see the difference in performance  with Python 3.7 with above PR.\r\nWould it be possible to get a toy code snippet to replicate above issue.\r\n\r\nThank you!\r\n"
        },
        {
            "Timestamp": "2022-11-22T09:17:52Z",
            "EntityIds": [
                33950866,
                86464649,
                86464649,
                86464649
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "279PXSN1H5SG"
            ],
            "Context": "@zhaozheng09 !\r\nCould you resolve the conflict in above PR #58617 .\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-19T06:09:14Z",
            "EntityIds": [
                42224728,
                38085909,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "Y5KL250U4HWU"
            ],
            "Context": "ComputeH2D is more priority than FeaturesH2D. <details><summary>Click to expand!</summary> \r\n \r\n ### Issue Type\r\n\r\nPerformance\r\n\r\n### Source\r\n\r\nsource\r\n\r\n### Tensorflow Version\r\n\r\n2.8\r\n\r\n### Custom Code\r\n\r\nYes\r\n\r\n### OS Platform and Distribution\r\n\r\nLinux\r\n\r\n### Mobile device\r\n\r\nno\r\n\r\n### Python version\r\n\r\n2.7\r\n\r\n### Bazel version\r\n\r\nmaster\r\n\r\n### GCC/Compiler version\r\n\r\n10.2.0\r\n\r\n### CUDA/cuDNN version\r\n\r\nCUDA Version: 11.4\r\n\r\n### GPU model and memory\r\n\r\nyes\r\n\r\n### Current Behaviour?\r\n\r\n**BackGround 1**: CUDA only support once H2D in same time .\r\n**BackGround 2**: \r\n  1. FeaturesAsyncH2D: TrainingData H2D by `dataset.prefetch_to_device`\r\n  2. ComputeH2D: Some small H2D in Op. for example: DynamicPartitionOpGPU: CPU compute output size, and then transfer size to GPU.\r\n\r\n**BackGround 3**: ComputeH2D maybe block current compute, and FeaturesAsyncH2D is needed to next few steps, so ComputeH2D is more important than FeaturesAsyncH2D.\r\n\r\nWhen lots of features need AsyncH2D, they maybe block ComputeH2D, because TF don't distinguish the priority of ComputeH2D and FeaturesAsyncH2D. \r\nwe use nsys to recurrent this bug:\r\n<img width=\"1560\" alt=\"image\" src=\"https://user-images.githubusercontent.com/33950866/202851210-cb72e589-9dec-4a85-a35b-365b63ace052.png\">\r\n\r\n</details>"
        },
        {
            "Timestamp": "2022-11-19T06:09:14Z",
            "EntityIds": [
                42224728,
                38085909,
                48215717
            ],
            "Symbol": "Pull Request",
            "Relational ID": [
                "Y5KL250U4HWU"
            ],
            "Context": "the priority of H2D. Question\uff1ahttps://github.com/tensorflow/tensorflow/issues/58616\r\nModify:\r\nWe distinguish FeaturesAsyncH2D and ComputeH2D, and raise the priority of ComputeH2D and lower the priority of FeaturesAsyncH2D.\r\nResult:\r\n<img width=\"1678\" alt=\"image\" src=\"https://user-images.githubusercontent.com/33950866/202851818-03031f51-a0df-4feb-a6b1-30203096a523.png\">\r\n\r\n**Due to busy work, if you find this feature useful, I will complete my PR later.**\r\n\r\n"
        },
        {
            "Timestamp": "2022-11-18T16:08:12Z",
            "EntityIds": [
                59843233,
                111861663,
                111861663,
                111861663,
                111861663
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "TCOX4C3A8RHF"
            ],
            "Context": "Gradient return None. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nsource\n\n### Tensorflow Version\n\n2.9.1\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\nUbuntu\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n_No response_\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nI implement a model with a custom training loop and custom loss function. Loss function return a float value. But while calculate gradient tf.gradient(loss,model.trainable_weights), It gives None gradient.  I know the issue is way of calculate loss. I tried with custom mse loss. It works fine. I want to implement loss function like count_predition_0's+count_predition_1's/label_0's+label_1's. It's a binary classification problem. I set batch size is 100. So model return 100 batch output. I only consider few batch eg out of 100 batch i only consider or filter it out 40 based on input. Both label and prediction in same shape that is not issue here. That label and prediction pass to custom_loss function.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\ndef custom_loss(self,output,prediction):\r\n        \r\n     correct_count=tf.math.count_nonzero(tf.math.equal(tf.round(prediction),tf.cast(output,tf.float32)))\r\n        incorrect_count=prediction.shape[0]-correct_count\r\n\r\n        incorrect_label_count=tf.where(output==0.0).shape[0]\r\n        correct_label_count=tf.where(output==1.0).shape[0]\r\n            \r\n        return tf.math.divide(tf.math.add(correct_count,incorrect_count),output.shape[0])\n```\n\n\n### Relevant log output\n\n```shell\nValueError: No gradients provided for any variable: (['my_model/object/embeddings:0', 'my_model/dense/kernel:0', 'my_model/dense/bias:0', 'my_model/dense_1/kernel:0', 'my_model/dense_1/bias:0', 'my_model/dense_2/kernel:0', 'my_model/dense_2/bias:0', 'my_model/dense_3/kernel:0', 'my_model/dense_3/bias:0', 'my_model/dense_4/kernel:0', 'my_model/dense_4/bias:0', 'my_model/dense_5/kernel:0', 'my_model/dense_5/bias:0', 'my_model/dense_6/kernel:0', 'my_model/dense_6/bias:0', 'my_model/dense_7/kernel:0', 'my_model/dense_7/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'my_model/object/embeddings:0' shape=(263, 100) dtype=float32, numpy=\n```\n</details>"
        },
        {
            "Timestamp": "2022-11-21T16:41:24Z",
            "EntityIds": [
                59843233,
                111861663,
                111861663,
                111861663,
                111861663
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "TCOX4C3A8RHF"
            ],
            "Context": "@joshuajennysibbu \r\nCould you please provide a complete code snippet to reproduce the issue reported here.\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-23T08:04:02Z",
            "EntityIds": [
                59843233,
                111861663,
                111861663,
                111861663,
                111861663
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "TCOX4C3A8RHF"
            ],
            "Context": "This is my trainer class\r\n\r\n`import tensorflow as tf\r\nimport numpy as np\r\n\r\n      class Trainer():\r\n          def __init__(self,loss,correct_pred,incorrect_pred,correct_label,incorrect_label):  \r\n              lr_scheduler=lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.01,decay_steps=100,decay_rate=0.1)\r\n              self.loss=tf.keras.losses.MeanSquaredError()\r\n              self.optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\r\n              self.correct_pred,self.incorrect_pred,self.correct_label,self.incorrect_label=correct_pred,incorrect_pred,correct_label,incorrect_label\r\n              self.loss_metric=loss\r\n              \r\n    def train_step(self,model,log_,object_,user_id,time,output,label_):\r\n        \r\n        with tf.GradientTape() as tape:\r\n            predictions = model(log_,object_,user_id, training=True)\r\n            prediction=tf.gather(predictions, output)\r\n            # loss = self.loss(label_,prediction)\r\n            loss=self.custom_loss(label_,prediction)\r\n            self.loss_metric(loss)\r\n            \r\n\r\n        gradients = tape.gradient(loss, model.trainable_variables)\r\n        self.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n\r\n        return output,predictions\r\n    \r\n        \r\n    def custom_loss(self,output,prediction):\r\n        correct_count=tf.math.count_nonzero(tf.math.equal(tf.round(prediction),tf.cast(output,tf.float32)))\r\n        incorrect_count=prediction.shape[0]-correct_count\r\n\r\n        incorrect_label_count=tf.math.reduce_sum(tf.where(output==0.0))\r\n        correct_label_count=tf.math.reduce_sum(tf.where(output==1.0))\r\n            \r\n        return tf.math.divide(tf.math.add(correct_count,incorrect_count),tf.math.add(correct_label_count,incorrect_label_count))\r\n`\r\n"
        },
        {
            "Timestamp": "2022-11-23T17:01:08Z",
            "EntityIds": [
                59843233,
                111861663,
                111861663,
                111861663,
                111861663
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "TCOX4C3A8RHF"
            ],
            "Context": "@joshuajennysibbu \r\nI was able to execute the given code on Colab using TF v2.11 without any error.  Could you please provide the code with all dependencies to replicate the issue and find the gist [here](https://colab.research.google.com/gist/tiruk007/f69f6d2145ce0dfebdd69436b9450b67/untitled29.ipynb) for reference.\r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-24T08:38:45Z",
            "EntityIds": [
                59843233,
                111861663,
                111861663,
                111861663,
                111861663
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "TCOX4C3A8RHF"
            ],
            "Context": "I update [gist](https://colab.research.google.com/gist/tiruk007/f69f6d2145ce0dfebdd69436b9450b67/untitled29.ipynb) same custom loss with tensorflow expert [sample](https://www.tensorflow.org/tutorials/quickstart/advanced) code. Can you able to see changes.. If not My notebook [link](https://colab.research.google.com/gist/joshuajennysibbu/822ddee4d0f587e475c3927ac8df9c55/untitled29.ipynb)"
        },
        {
            "Timestamp": "2022-11-28T06:11:11Z",
            "EntityIds": [
                59843233,
                111861663,
                111861663,
                111861663,
                111861663
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "TCOX4C3A8RHF"
            ],
            "Context": "@sushreebarsa \r\nI was able to reproduce the issue on Colab using TF v2.11 and TF-nightly. Please find the gist [here](https://colab.research.google.com/gist/tiruk007/808cd34d2bc25a035a5a3e35ab66e234/58614.ipynb) for reference.\r\n\r\nThank you !"
        },
        {
            "Timestamp": "2022-11-18T15:42:56Z",
            "EntityIds": [
                14215174,
                73069040,
                86464649
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "G67NMA8B81X6"
            ],
            "Context": "Tensorflow Lite C API works much slower than C++ API. ### Issue Type\r\n\r\nPerformance\r\n\r\n### Source\r\n\r\nsource\r\n\r\n### Tensorflow Version\r\n\r\ntflite v2.4.0\r\n\r\n### Custom Code\r\n\r\nYes\r\n\r\n### OS Platform and Distribution\r\n\r\nUbuntu 18.04.6 LTS\r\n\r\n### Mobile device\r\n\r\n_No response_\r\n\r\n### Python version\r\n\r\n_No response_\r\n\r\n### Bazel version\r\n\r\nCMake was used\r\n\r\n### GCC/Compiler version\r\n\r\ngcc 7.5.0\r\n\r\n### CUDA/cuDNN version\r\n\r\n_No response_\r\n\r\n### GPU model and memory\r\n\r\n_No response_\r\n\r\n### Current Behaviour?\r\n\r\n```shell\r\nI built TFLite v2.4.0 static library and used in our project using C++ API \r\n\r\n(we are using it cross-platform Ubuntu/Android/iOS). It shows inference time 5-10 ms on Ubuntu 18. \r\n\r\nWe decided to switch to C API (iOS xcframework is available on C). But I see that on \r\n\r\nC API inference time becomes 45-50 ms. I tried to test using TFLite v2.10.0 C API \r\n\r\nand it shows 180-200 ms. The model tested in Ubuntu is a small OCR model \r\n\r\nwith size smaller than 200 KB.\r\n```\r\n\r\n\r\n### Standalone code to reproduce the issue\r\n\r\n```shell\r\nI can't upload the whole files, so here is snippets:\r\n\r\nclass TextRecognizer {\r\n    ...\r\n    virtual TfLiteModel* getModel() = 0;\r\n    TfLiteInterpreterOptions* options;\r\n    TfLiteInterpreter* interpreter;\r\n};\r\n```\r\n\r\nCpp file:\r\n```\r\nvdoc::TextLinePrediction vdoc::TextRecognizer::predict(const cv::Mat &srcImage) {\r\n    ...\r\n    options = TfLiteInterpreterOptionsCreate();\r\n    interpreter = TfLiteInterpreterCreate(getModel(), options);\r\n    TfLiteInterpreterAllocateTensors(interpreter);\r\n    ...\r\n    TfLiteTensor *input_tensor = TfLiteInterpreterGetInputTensor(interpreter, 0);\r\n    TfLiteTensorCopyFromBuffer(input_tensor, convertedImage.data,\r\n                                   convertedImage.total() * convertedImage.elemSize());\r\n    TfLiteInterpreterInvoke(interpreter);\r\n    const TfLiteTensor *output_tensor = TfLiteInterpreterGetOutputTensor(interpreter, 0);\r\n    float *output = output_tensor->data.f;\r\n    ...\r\n}\r\n```\r\n\r\n\r\n### Relevant log output\r\n\r\n```shell\r\nOutput is measured time of each TFLite method call:\r\nTime taken to init interpreter: 0.00191s\r\nTime taken to allocate tensors: 0.00060s\r\nTime taken to copy buffer data: 0.00031s\r\nTime taken to Invoke inference: 0.05476s\r\n\r\nAs I mentioned before on C++ API inference time is about 10 times faster 0.005s.\r\n```\r\n"
        },
        {
            "Timestamp": "2022-11-21T08:56:58Z",
            "EntityIds": [
                14215174,
                73069040,
                86464649
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "G67NMA8B81X6"
            ],
            "Context": "@kkuatov !\r\nThanks for sharing your results on C and C++ inference with respect to your OCR model.\r\n\r\n@sachinprasadhs !\r\nCould you look at this issue.\r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-18T15:07:02Z",
            "EntityIds": [
                15980055,
                86464649,
                86464649,
                56610014,
                19637339,
                19637339
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "IMSIHDLVXNX1"
            ],
            "Context": "Wrong barplot x-labels in https://www.tensorflow.org/tutorials/audio/simple_audio. I think that in the notebook https://www.tensorflow.org/tutorials/audio/simple_audio this line:\r\n\r\n`plt.bar(commands, tf.nn.softmax(prediction[0]))`\r\n\r\nshould be replaced with:\r\n\r\n`x_labels = ['down', 'go', 'left', 'no', 'right', 'stop', 'up', 'yes']`\r\n`plt.bar(x_labels, tf.nn.softmax(prediction[0]))`\r\n\r\nAs a result, the graph will correctly show the probabilities for all classes. \r\n\r\n"
        },
        {
            "Timestamp": "2022-11-18T17:12:24Z",
            "EntityIds": [
                15980055,
                86464649,
                86464649,
                56610014,
                19637339,
                19637339
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "IMSIHDLVXNX1"
            ],
            "Context": "Line: \r\n`plt.bar(np.sort(commands), tf.nn.softmax(prediction[0]))`\r\ninstead of:\r\n`plt.bar(commands, tf.nn.softmax(prediction[0]))`\r\nwill work too."
        },
        {
            "Timestamp": "2022-11-21T04:11:58Z",
            "EntityIds": [
                15980055,
                86464649,
                86464649,
                56610014,
                19637339,
                19637339
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "IMSIHDLVXNX1"
            ],
            "Context": "Hi @JacekPardyak !\r\nThanks for sharing your observation on this bug. \r\n\r\nIt is correct that probabilities for others is not visible in above output ( looked like a image rendering issue initially) \r\nUpon above fact, I investigated on the sequence shared by you, the present command and the one mentioned in confusion matrix. They are showing same results in output.\r\n\r\nSo I think It would be good to change the documentation  with sequence mentioned in [dataset](https://www.tensorflow.org/tutorials/audio/simple_audio#import_the_mini_speech_commands_dataset) mentions below sequence  and  hear from you on this PR [#2152](https://github.com/tensorflow/docs/pull/2152).\r\n```\r\nx_labels = ['no', 'yes', 'down', 'go', 'left', 'up', 'right', 'stop']\r\nplt.bar(x_labels, tf.nn.softmax(prediction[0]))\r\n```\r\nRef :\r\n1. [output in webpage](https://user-images.githubusercontent.com/86464649/202963204-5e9c047b-da2d-4393-8de4-76ead5bcd0e7.png)\r\n\r\n2. [output in gist](https://user-images.githubusercontent.com/86464649/202963500-c2a4aa08-db2e-4e66-8772-51a5c45eedb8.png)\r\n\r\n3. [test_gist]( https://colab.sandbox.google.com/gist/mohantym/d1a0a3bff923c8d948ac46b577490e40/simple_audio.ipynb#scrollTo=zRxauKMdhofU)\r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-28T07:16:19Z",
            "EntityIds": [
                15980055,
                86464649,
                86464649,
                56610014,
                19637339,
                19637339
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "IMSIHDLVXNX1"
            ],
            "Context": "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n"
        },
        {
            "Timestamp": "2022-11-30T22:33:50Z",
            "EntityIds": [
                15980055,
                86464649,
                86464649,
                56610014,
                19637339,
                19637339
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "IMSIHDLVXNX1"
            ],
            "Context": "@JacekPardyak On it"
        },
        {
            "Timestamp": "2022-11-30T23:44:34Z",
            "EntityIds": [
                15980055,
                86464649,
                86464649,
                56610014,
                19637339,
                19637339
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "IMSIHDLVXNX1"
            ],
            "Context": "PR https://github.com/tensorflow/docs/pull/2152 approved "
        },
        {
            "Timestamp": "2022-11-18T13:38:41Z",
            "EntityIds": [
                67419721,
                111861663,
                105795148,
                111861663,
                56610014
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "DS9S6Q7ERTW3"
            ],
            "Context": "Tensorflow Lite 2.11.0-rc2 CMake build system broken. <details><summary>Click to expand!</summary> \r\n \r\n ### Issue Type\r\n\r\nBuild/Install\r\n\r\n### Source\r\n\r\nsource\r\n\r\n### Tensorflow Version\r\n\r\n2.11.0-rc2\r\n\r\n### Custom Code\r\n\r\nNo\r\n\r\n### OS Platform and Distribution\r\n\r\nAndroid\r\n\r\n### Mobile device\r\n\r\nN/A\r\n\r\n### Python version\r\n\r\n3.9\r\n\r\n### Bazel version\r\n\r\nN/A\r\n\r\n### GCC/Compiler version\r\n\r\nAndroid NDK 24\r\n\r\n### CUDA/cuDNN version\r\n\r\nN/A\r\n\r\n### GPU model and memory\r\n\r\nN/A\r\n\r\n### Current Behaviour?\r\n\r\nUnable to cross compile TFLite 2.11.0-rc2 for Android, using CMake.\r\nI understand that v2.11.0 is still a release candidate. But I want to bring this issue to your attention. We rely heavily on TFLite (and the CMake workflow) in our production and we are looking forward to upgrading to v2.11.0, once it is officially released, to take advantage of fixes to long standing bugs and issues.\r\n\r\nHere is the command I used to build:\r\n\r\n```shell\r\nmkdir tflite.build.android && cd tflite.build.android\r\n\r\ncmake -G \"Unix Makefiles\" -DCMAKE_SYSTEM_NAME=Android -DANDROID_ABI=arm64-v8a -DANDROID_STL=c++_shared -DANDROID_NATIVE_API_LEVEL=27 -DCMAKE_VERBOSE_MAKEFILE=ON -DCMAKE_TOOLCHAIN_FILE=$HOME/Android/Sdk/ndk/24.0.8215888/build/cmake/android.toolchain.cmake -DTFLITE_ENABLE_XNNPACK=ON -DTFLITE_ENABLE_GPU=ON -DTFLITE_ENABLE_NNAPI=ON -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=OFF ../tensorflow/tensorflow/lite\r\n\r\nmake -j4\r\n```\r\n, and I get the following error:\r\n```\r\n 28%] Linking CXX executable flatc\r\ncd /home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build && /usr/local/bin/cmake -E cmake_link_script CMakeFiles/flatc.dir/link.txt --verbose=1\r\n/home/myname/Android/Sdk/ndk/24.0.8215888/toolchains/llvm/prebuilt/linux-x86_64/bin/clang++ --target=aarch64-none-linux-android27 --sysroot=/home/myname/Android/Sdk/ndk/24.0.8215888/toolchains/llvm/prebuilt/linux-x86_64/sysroot -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security -fexceptions -frtti -stdlib=libc++ -O3 -DNDEBUG -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--fatal-warnings -Qunused-arguments -Wl,--no-undefined  -Wl,--gc-sections CMakeFiles/flatc.dir/src/idl_parser.cpp.o CMakeFiles/flatc.dir/src/idl_gen_text.cpp.o CMakeFiles/flatc.dir/src/reflection.cpp.o CMakeFiles/flatc.dir/src/util.cpp.o CMakeFiles/flatc.dir/src/idl_gen_cpp.cpp.o CMakeFiles/flatc.dir/src/idl_gen_csharp.cpp.o CMakeFiles/flatc.dir/src/idl_gen_dart.cpp.o CMakeFiles/flatc.dir/src/idl_gen_kotlin.cpp.o CMakeFiles/flatc.dir/src/idl_gen_go.cpp.o CMakeFiles/flatc.dir/src/idl_gen_java.cpp.o CMakeFiles/flatc.dir/src/idl_gen_ts.cpp.o CMakeFiles/flatc.dir/src/idl_gen_php.cpp.o CMakeFiles/flatc.dir/src/idl_gen_python.cpp.o CMakeFiles/flatc.dir/src/idl_gen_lobster.cpp.o CMakeFiles/flatc.dir/src/idl_gen_lua.cpp.o CMakeFiles/flatc.dir/src/idl_gen_rust.cpp.o CMakeFiles/flatc.dir/src/idl_gen_fbs.cpp.o CMakeFiles/flatc.dir/src/idl_gen_grpc.cpp.o CMakeFiles/flatc.dir/src/idl_gen_json_schema.cpp.o CMakeFiles/flatc.dir/src/idl_gen_swift.cpp.o CMakeFiles/flatc.dir/src/flatc.cpp.o CMakeFiles/flatc.dir/src/flatc_main.cpp.o CMakeFiles/flatc.dir/src/bfbs_gen_lua.cpp.o CMakeFiles/flatc.dir/src/code_generators.cpp.o CMakeFiles/flatc.dir/grpc/src/compiler/cpp_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/go_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/java_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/python_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/swift_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/ts_generator.cc.o -o flatc   -latomic -lm \r\nRunning scripts/generate_code.py...\r\ncd /home/myname/myworkingdir/tflite.build.android/flatbuffers && /usr/bin/python3.9 scripts/generate_code.py --flatc /home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc --skip-gen-reflection\r\nTraceback (most recent call last):\r\n  File \"/home/myname/myworkingdir/tflite.build.android/flatbuffers/scripts/generate_code.py\", line 148, in <module>\r\n    flatc(\r\n  File \"/home/myname/myworkingdir/tflite.build.android/flatbuffers/scripts/generate_code.py\", line 82, in flatc\r\n    result = subprocess.run(cmd, cwd=str(cwd), check=True)\r\n  File \"/usr/lib/python3.9/subprocess.py\", line 505, in run\r\n    with Popen(*popenargs, **kwargs) as process:\r\n  File \"/usr/lib/python3.9/subprocess.py\", line 951, in __init__\r\n    self._execute_child(args, executable, preexec_fn, close_fds,\r\n  File \"/usr/lib/python3.9/subprocess.py\", line 1821, in _execute_child\r\n    raise child_exception_type(errno_num, err_msg, err_filename)\r\nOSError: [Errno 8] Exec format error: '/home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc'\r\nmake[2]: *** [_deps/flatbuffers-build/CMakeFiles/flatc.dir/build.make:566: _deps/flatbuffers-build/flatc] Error 1\r\nmake[2]: *** Deleting file '_deps/flatbuffers-build/flatc'\r\nmake[2]: Leaving directory '/home/myname/myworkingdir/tflite.build.android'\r\nmake[1]: *** [CMakeFiles/Makefile2:4720: _deps/flatbuffers-build/CMakeFiles/flatc.dir/all] Error 2\r\nmake[1]: Leaving directory '/home/myname/myworkingdir/tflite.build.android'\r\nmake: *** [Makefile:139: all] Error 2\r\n```\r\n\r\nThe problem seems to be that Python tries to invoke the `flatbuffers/scripts/generate_code.py` script, which attempts to run `/home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc`, which does not exist. \r\n\r\nTFLite v2.10.1 builds fine, but as far as I can tell, for v2.10.1m there is no attempt to invoke `generate_code.py` or `_deps/flatbuffers-build/flatc`\r\n\r\n### Standalone code to reproduce the issue\r\n\r\n```shell\r\nmkdir tflite.build.android && cd tflite.build.android\r\n\r\ncmake -G \"Unix Makefiles\" -DCMAKE_SYSTEM_NAME=Android -DANDROID_ABI=arm64-v8a -DANDROID_STL=c++_shared -DANDROID_NATIVE_API_LEVEL=27 -DCMAKE_VERBOSE_MAKEFILE=ON -DCMAKE_TOOLCHAIN_FILE=$HOME/Android/Sdk/ndk/24.0.8215888/build/cmake/android.toolchain.cmake -DTFLITE_ENABLE_XNNPACK=ON -DTFLITE_ENABLE_GPU=ON -DTFLITE_ENABLE_NNAPI=ON -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=OFF ../tensorflow/tensorflow/lite\r\n\r\nmake -j4\r\n```\r\n\r\n### Relevant log output\r\n\r\n```shell\r\n28%] Linking CXX executable flatc\r\ncd /home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build && /usr/local/bin/cmake -E cmake_link_script CMakeFiles/flatc.dir/link.txt --verbose=1\r\n/home/myname/Android/Sdk/ndk/24.0.8215888/toolchains/llvm/prebuilt/linux-x86_64/bin/clang++ --target=aarch64-none-linux-android27 --sysroot=/home/myname/Android/Sdk/ndk/24.0.8215888/toolchains/llvm/prebuilt/linux-x86_64/sysroot -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security -fexceptions -frtti -stdlib=libc++ -O3 -DNDEBUG -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--fatal-warnings -Qunused-arguments -Wl,--no-undefined  -Wl,--gc-sections CMakeFiles/flatc.dir/src/idl_parser.cpp.o CMakeFiles/flatc.dir/src/idl_gen_text.cpp.o CMakeFiles/flatc.dir/src/reflection.cpp.o CMakeFiles/flatc.dir/src/util.cpp.o CMakeFiles/flatc.dir/src/idl_gen_cpp.cpp.o CMakeFiles/flatc.dir/src/idl_gen_csharp.cpp.o CMakeFiles/flatc.dir/src/idl_gen_dart.cpp.o CMakeFiles/flatc.dir/src/idl_gen_kotlin.cpp.o CMakeFiles/flatc.dir/src/idl_gen_go.cpp.o CMakeFiles/flatc.dir/src/idl_gen_java.cpp.o CMakeFiles/flatc.dir/src/idl_gen_ts.cpp.o CMakeFiles/flatc.dir/src/idl_gen_php.cpp.o CMakeFiles/flatc.dir/src/idl_gen_python.cpp.o CMakeFiles/flatc.dir/src/idl_gen_lobster.cpp.o CMakeFiles/flatc.dir/src/idl_gen_lua.cpp.o CMakeFiles/flatc.dir/src/idl_gen_rust.cpp.o CMakeFiles/flatc.dir/src/idl_gen_fbs.cpp.o CMakeFiles/flatc.dir/src/idl_gen_grpc.cpp.o CMakeFiles/flatc.dir/src/idl_gen_json_schema.cpp.o CMakeFiles/flatc.dir/src/idl_gen_swift.cpp.o CMakeFiles/flatc.dir/src/flatc.cpp.o CMakeFiles/flatc.dir/src/flatc_main.cpp.o CMakeFiles/flatc.dir/src/bfbs_gen_lua.cpp.o CMakeFiles/flatc.dir/src/code_generators.cpp.o CMakeFiles/flatc.dir/grpc/src/compiler/cpp_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/go_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/java_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/python_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/swift_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/ts_generator.cc.o -o flatc   -latomic -lm \r\nRunning scripts/generate_code.py...\r\ncd /home/myname/myworkingdir/tflite.build.android/flatbuffers && /usr/bin/python3.9 scripts/generate_code.py --flatc /home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc --skip-gen-reflection\r\nTraceback (most recent call last):\r\n  File \"/home/myname/myworkingdir/tflite.build.android/flatbuffers/scripts/generate_code.py\", line 148, in <module>\r\n    flatc(\r\n  File \"/home/myname/myworkingdir/tflite.build.android/flatbuffers/scripts/generate_code.py\", line 82, in flatc\r\n    result = subprocess.run(cmd, cwd=str(cwd), check=True)\r\n  File \"/usr/lib/python3.9/subprocess.py\", line 505, in run\r\n    with Popen(*popenargs, **kwargs) as process:\r\n  File \"/usr/lib/python3.9/subprocess.py\", line 951, in __init__\r\n    self._execute_child(args, executable, preexec_fn, close_fds,\r\n  File \"/usr/lib/python3.9/subprocess.py\", line 1821, in _execute_child\r\n    raise child_exception_type(errno_num, err_msg, err_filename)\r\nOSError: [Errno 8] Exec format error: '/home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc'\r\nmake[2]: *** [_deps/flatbuffers-build/CMakeFiles/flatc.dir/build.make:566: _deps/flatbuffers-build/flatc] Error 1\r\nmake[2]: *** Deleting file '_deps/flatbuffers-build/flatc'\r\nmake[2]: Leaving directory '/home/myname/myworkingdir/tflite.build.android'\r\nmake[1]: *** [CMakeFiles/Makefile2:4720: _deps/flatbuffers-build/CMakeFiles/flatc.dir/all] Error 2\r\nmake[1]: Leaving directory '/home/myname/myworkingdir/tflite.build.android'\r\nmake: *** [Makefile:139: all] Error 2\r\n```\r\n</details>"
        },
        {
            "Timestamp": "2022-11-19T12:29:34Z",
            "EntityIds": [
                67419721,
                111861663,
                105795148,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "DS9S6Q7ERTW3"
            ],
            "Context": "hey i am a beginner in this community can i help you solve this issue\r\n "
        },
        {
            "Timestamp": "2022-11-21T16:34:51Z",
            "EntityIds": [
                67419721,
                111861663,
                105795148,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "DS9S6Q7ERTW3"
            ],
            "Context": "@Aryanryn09 \r\nCould you please refer to the [Cross compilation TensorFlow Lite with CMake](https://www.tensorflow.org/lite/guide/build_cmake_arm) and [Build TensorFlow Lite with CMake](https://www.tensorflow.org/lite/guide/build_cmake) and let us know if it helps.\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-21T18:40:39Z",
            "EntityIds": [
                67419721,
                111861663,
                105795148,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "DS9S6Q7ERTW3"
            ],
            "Context": "@tiruk007, Tensorflow Lite v 2.11.0 was just released, but I get the same build error. I will close this ticket and file a new one for V2.11.0. I tried https://www.tensorflow.org/lite/guide/build_cmake but it doesn't help. Please see the new ticket (https://github.com/tensorflow/tensorflow/issues/58636) for more details."
        },
        {
            "Timestamp": "2022-11-21T18:40:41Z",
            "EntityIds": [
                67419721,
                111861663,
                105795148,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "DS9S6Q7ERTW3"
            ],
            "Context": "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58611\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58611\">No</a>\n"
        },
        {
            "Timestamp": "2022-11-18T12:10:40Z",
            "EntityIds": [
                95025816,
                116063290,
                116063290,
                116063290,
                116063290,
                56610014
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "0TI45CUO1JX3"
            ],
            "Context": "from keras.models import load_model raises no module named tensorflow.compat error. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nSupport\n\n### Source\n\nbinary\n\n### Tensorflow Version\n\n2.11\n\n### Custom Code\n\nNo\n\n### OS Platform and Distribution\n\nWindoes 11\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n3.7.9\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nWhen doing  keras.models import load_model, An error saying no module named tensorflow.compat appears\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nJust open python 3.7 and type  keras.models import load_model\n```\n\n\n### Relevant log output\n\n```shell\nTraceback (most recent call last):\r\n  File \"c:/Users/Noah Ryu/Coding/AI/Teachable Machine/Guesser3.py\", line 1, in <module>\r\n    from keras.models import load_model # TensorFlow is needed for Keras to work\r\n  File \"C:\\Users\\Noah Ryu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\__init__.py\", line 21, in <module>\r\n    from keras import models\r\n  File \"C:\\Users\\Noah Ryu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\models\\__init__.py\", line 18, in <module>  \r\n    from keras.engine.functional import Functional\r\n  File \"C:\\Users\\Noah Ryu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\functional.py\", line 24, in <module>\r\n    import tensorflow.compat.v2 as tf\r\nModuleNotFoundError: No module named 'tensorflow.compat'\n```\n</details>"
        },
        {
            "Timestamp": "2022-11-18T13:19:21Z",
            "EntityIds": [
                95025816,
                116063290,
                116063290,
                116063290,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "0TI45CUO1JX3"
            ],
            "Context": "Hi @sryu1 ,\r\n\r\nInstead of `keras.models import load_model`, Please use `from tensorflow.keras.models import load_model` ."
        },
        {
            "Timestamp": "2022-11-18T22:35:53Z",
            "EntityIds": [
                95025816,
                116063290,
                116063290,
                116063290,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "0TI45CUO1JX3"
            ],
            "Context": "I've already tried it previously and it didn't work \r\n```\r\nTraceback (most recent call last):\r\n  File \"c:/Users/Noah Ryu/Coding/AI/Teachable Machine/Guesser.py\", line 1, in <module>\r\n    from tensorflow.keras.models import load_model\r\nModuleNotFoundError: No module named 'tensorflow.keras'\r\n```"
        },
        {
            "Timestamp": "2022-11-19T01:20:52Z",
            "EntityIds": [
                95025816,
                116063290,
                116063290,
                116063290,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "0TI45CUO1JX3"
            ],
            "Context": "Also, I noticed the tf 2.10 tag, for tensorflow 2.10,  `import keras.models import load_model` works but not for 2.11"
        },
        {
            "Timestamp": "2022-11-19T04:10:50Z",
            "EntityIds": [
                95025816,
                116063290,
                116063290,
                116063290,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "0TI45CUO1JX3"
            ],
            "Context": "Hi @sryu1 ,\r\nSorry i didn't noticed your OS earllier. Please refer the note from Documentation.\r\n\r\n`Caution: TensorFlow 2.10 was the last TensorFlow release that supported GPU on native-Windows. Starting with TensorFlow 2.11, you will need to install [TensorFlow in WSL2](https://tensorflow.org/install/pip#windows-wsl2), or install tensorflow-cpu and, optionally, try the [TensorFlow-DirectML-Plugin](https://github.com/microsoft/tensorflow-directml-plugin#tensorflow-directml-plugin-)`\r\n\r\nPlease refer the attached [link](https://www.tensorflow.org/install/pip) for more details."
        },
        {
            "Timestamp": "2022-11-19T05:06:31Z",
            "EntityIds": [
                95025816,
                116063290,
                116063290,
                116063290,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "0TI45CUO1JX3"
            ],
            "Context": "Ah, ok. Well, if I'm using tensorflow-cpu, it should work, right? It seems like it doesn't though, it gives back the same error..."
        },
        {
            "Timestamp": "2022-11-19T11:28:38Z",
            "EntityIds": [
                95025816,
                116063290,
                116063290,
                116063290,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "0TI45CUO1JX3"
            ],
            "Context": "@sryu1,\r\n\r\nCould you please check whether the instructions mentioned in documentation followed correctly?Please refer link [here](https://www.tensorflow.org/install/pip#step-by-step_instructions).Please ignore step5 which is for GPU setup.Please cross check again and confirm us if still problem persists.\r\n\r\nThankyou!"
        },
        {
            "Timestamp": "2022-11-19T12:10:16Z",
            "EntityIds": [
                95025816,
                116063290,
                116063290,
                116063290,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "0TI45CUO1JX3"
            ],
            "Context": "Yes, using a conda environment worked... Is there any way to use windows native and tensorflow-cpu though? Or is that the only option for tf 2.11?"
        },
        {
            "Timestamp": "2022-11-19T12:22:50Z",
            "EntityIds": [
                95025816,
                116063290,
                116063290,
                116063290,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "0TI45CUO1JX3"
            ],
            "Context": "Wait, nevermind, using tensorflow-cpu works with windows native now, I tried uninstalling everything related to tensorflow (tensorflow-cpu, tensorflow-intel, keras, etc.) with pip then installed tensorflow-cpu. :)"
        },
        {
            "Timestamp": "2022-11-19T12:24:24Z",
            "EntityIds": [
                95025816,
                116063290,
                116063290,
                116063290,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "0TI45CUO1JX3"
            ],
            "Context": "So, in conclusion:\r\n`from keras.models import load_model` does not work with native windows and tensorflow 2.11\r\nIt works with tensorflow-cpu OR tensorflow 2.11 with a conda environment or other sorts of similar."
        },
        {
            "Timestamp": "2022-11-20T08:32:50Z",
            "EntityIds": [
                95025816,
                116063290,
                116063290,
                116063290,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "0TI45CUO1JX3"
            ],
            "Context": "That's it, thank you so much! I'll open this issue up again if I have any question regarding this..."
        },
        {
            "Timestamp": "2022-11-20T08:32:54Z",
            "EntityIds": [
                95025816,
                116063290,
                116063290,
                116063290,
                116063290,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "0TI45CUO1JX3"
            ],
            "Context": "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58610\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58610\">No</a>\n"
        },
        {
            "Timestamp": "2022-11-18T08:48:08Z",
            "EntityIds": [
                87115287,
                73069040,
                86464649
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "CBR4OKEQNQ7X"
            ],
            "Context": "gpu metal  lack  \u201dinference_context_generated.h\u201c. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nsource\n\n### Tensorflow Version\n\n2.10 or 2.11\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\nios\n\n### Mobile device\n\niphone\n\n### Python version\n\n3.7\n\n### Bazel version\n\nno \n\n### GCC/Compiler version\n\nno\n\n### CUDA/cuDNN version\n\nno\n\n### GPU model and memory\n\n111\n\n### Current Behaviour?\n\n```shell\nA bug happened!\r\n#include \"tensorflow/lite/delegates/gpu/metal/inference_context_generated.h\"\r\nBut I can not find the inference_context_generated.h.WHy?\r\nThanks\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\n111\n```\n\n\n### Relevant log output\n\n_No response_</details>"
        },
        {
            "Timestamp": "2022-11-19T01:33:38Z",
            "EntityIds": [
                87115287,
                73069040,
                86464649
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "CBR4OKEQNQ7X"
            ],
            "Context": "Hi @chenliang110 !\r\nThanks for reporting it.\r\n\r\n@sachinprasadhs !\r\nCould you look at this bug.\r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-18T00:23:19Z",
            "EntityIds": [
                12981474,
                144114,
                6878204,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "KO47FNKPB5BF"
            ],
            "Context": "[NVIDIA TF] Enable BF16 L2Loss. GPU support for bfloat16 L2Loss op."
        },
        {
            "Timestamp": "2022-11-18T00:23:19Z",
            "EntityIds": [
                12981474,
                144114,
                6878204,
                48215717
            ],
            "Symbol": "Pull Request",
            "Relational ID": [
                "KO47FNKPB5BF"
            ],
            "Context": "[NVIDIA TF] Enable BF16 L2Loss. GPU support for bfloat16 L2Loss op."
        },
        {
            "Timestamp": "2022-11-18T09:05:26Z",
            "Entity Ids": [
                null
            ],
            "Symbol": "Pull Request Merged",
            "Relational IDs": [
                "KO47FNKPB5BF"
            ],
            "Context": "[NVIDIA TF] Enable BF16 L2Loss. GPU support for bfloat16 L2Loss op."
        },
        {
            "Timestamp": "2022-11-17T16:31:00Z",
            "EntityIds": [
                38138022,
                111861663,
                111861663,
                111861663,
                111861663,
                56610014
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "2K0UI2XD4FSW"
            ],
            "Context": "Tflite GPU Delegate error for FULLY_CONNECTED. ### 1. System information\r\n\r\n- OS Platform and Distribution: Ubuntu 20.4\r\n- TensorFlow installation: pip package\r\n- TensorFlow library: 2.10\r\n\r\n\r\n### 3. Failure after conversion\r\nIf the conversion is successful, but the generated model is wrong, then state what is wrong:\r\n\r\nModel is successfully converted. However, during benchmark with GPU delegate (1. using latest benchmark binary: https://www.tensorflow.org/lite/performance/measurement#native_benchmark_binary 2. using older benchmark binary), following error appears: \r\n1. ERROR: TfLiteGpuDelegate Init: Unrecognized Write selector\r\n2. ERROR: TfLiteGpuDelegate Init: FULLY_CONNECTED: Amount of input data should match weights width\r\n\r\nWhat is more interesting, if i convert the model using tensorflow 2.3.4, everything works as expected - i can run the benchmark without any problems. \r\nIt seems that starting from tf 2.4, some bug was introduced... \r\n\r\n"
        },
        {
            "Timestamp": "2022-11-17T17:15:09Z",
            "EntityIds": [
                38138022,
                111861663,
                111861663,
                111861663,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "2K0UI2XD4FSW"
            ],
            "Context": "i can share the tflite model with this problem, if needed "
        },
        {
            "Timestamp": "2022-11-21T02:37:45Z",
            "EntityIds": [
                38138022,
                111861663,
                111861663,
                111861663,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "2K0UI2XD4FSW"
            ],
            "Context": "@macsmy \r\nSorry for the late reply, Could you please share the tflite model to reproduce the issue ?\r\n\r\nThank you!\r\n\r\n\r\n\r\n"
        },
        {
            "Timestamp": "2022-11-22T12:08:00Z",
            "EntityIds": [
                38138022,
                111861663,
                111861663,
                111861663,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "2K0UI2XD4FSW"
            ],
            "Context": "@tiruk007 \r\n[tmp.zip](https://github.com/tensorflow/tensorflow/files/10067209/tmp.zip)\r\n"
        },
        {
            "Timestamp": "2022-11-22T12:09:00Z",
            "EntityIds": [
                38138022,
                111861663,
                111861663,
                111861663,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "2K0UI2XD4FSW"
            ],
            "Context": "without GPU delegates, inference is okay "
        },
        {
            "Timestamp": "2022-11-23T10:12:40Z",
            "EntityIds": [
                38138022,
                111861663,
                111861663,
                111861663,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "2K0UI2XD4FSW"
            ],
            "Context": "@macsmy \r\nCould you please refer to the similar [issue_1](https://github.com/tensorflow/tensorflow/issues/57180) & [issue_2](https://github.com/tensorflow/tensorflow/issues/34525) and let us know if it helps.\r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-23T23:39:21Z",
            "EntityIds": [
                38138022,
                111861663,
                111861663,
                111861663,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "2K0UI2XD4FSW"
            ],
            "Context": "thanks, it resolves the issue, i can convert and run the model using tf 2.10. however, surprisingly, when im using gelu as activation, most of the OPs fallback to CPU. other activations, such as swish, work fine. isnt gelu supported on the GPU? "
        },
        {
            "Timestamp": "2022-11-24T09:01:19Z",
            "EntityIds": [
                38138022,
                111861663,
                111861663,
                111861663,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "2K0UI2XD4FSW"
            ],
            "Context": "@macsmy \r\nCan you please refer to [Supported Select TensorFlow operators](https://www.tensorflow.org/lite/guide/op_select_allowlist) and close the issue if it resolved.\r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-12-01T09:16:19Z",
            "EntityIds": [
                38138022,
                111861663,
                111861663,
                111861663,
                111861663,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "2K0UI2XD4FSW"
            ],
            "Context": "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n"
        },
        {
            "Timestamp": "2022-11-17T10:17:39Z",
            "EntityIds": [
                61427290,
                116063290,
                116063290,
                116063290,
                116063290
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "8DTABFPT2NCJ"
            ],
            "Context": "TensorFlow Dataset.from_generator leaks memory for randomly generated samples (correlated with 'cuda_malloc_async'). <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nbinary\n\n### Tensorflow Version\n\n2.10, 2.9 tested as well\n\n### Custom Code\n\nNo\n\n### OS Platform and Distribution\n\nUbuntu Linux 22.04 and Google Colab tested\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n3.9\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n11.8\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nWhen dataset is generated via `Dataset.from_generator`, samples that have already been used are not removed from GPU memory (or at least this is what I presume), leading to an increased use of VRAM and finally an OOM error as the training proceeds.\r\n\r\nThis is an important bug, since very often (as in this case) someone might use `from_generator` to perform augmentation etc, and It can be easily seen by examining the `GPU_mem_usage`, that the memory usage indeed grows. For some reason, Colab allocates memory straight away to ~8 GB, so the growth is only noticeable after around 300-500 epochs. The problem is way worse when training on real, larger datasets.\r\n\r\nFor a simple summary, just view the graphs on the end of the notebook.\r\n\r\n\r\nNotice (in the notebook), that even though total memory taken on the GPU grows, TensorFlow \"thinks\" it is consuming basically constant amount of memory, which points into the direction of a memory leak.\r\n\r\n\r\nAlso, it takes around 900 epochs to fill almost the whole memory (16 GB in case of Colab). Epochs consist of 1024 images of shape (64, 64, 3), float32 dtype, giving 1024*3*64*64*900*4 bytes allocated in total, which is around 45 GB, so I presume not all memory is leaked, OR leaking data is not the cause of the problem.\r\n\r\nNotice, however, that MobileNetV3 (which I have used in this example) is roughly 18MB in size, and 18MB*900 epochs is basically the aforementioned 16 GB. This could possibly mean that the model's state is leaked somehow, but I have yet to test this hypothesis (for example by using a larger model and checking when the leak happens, i.e. if `num_epochs_until_crash*model_size==gpu_vram_capacity`).\r\n\r\n\r\nAlso, I have tested multiple scenarios locally, and this seems NOT to happen without the `os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'` set, however I have no relevant logs to prove it, since when the flag is absent, whole GPU memory is allocated, and I have no means of monitoring it relevantly, since it doesn't change. I have, however, performed 4 tests and none resulted in OOM error after 1500 epochs, while locally they would usually throw OOM after 400 epochs (RTX 3060Ti).\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nI have provided a minimal example on google colab, can be viewed here:\r\nhttps://colab.research.google.com/drive/1-ANVp8KF9irKvqdR390QNlop-pPhGMrU?usp=sharing\r\nI think the example is self-explanatory.\n```\n\n\n### Relevant log output\n\n_No response_</details>"
        },
        {
            "Timestamp": "2022-11-21T08:10:55Z",
            "EntityIds": [
                61427290,
                116063290,
                116063290,
                116063290,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "8DTABFPT2NCJ"
            ],
            "Context": "I could able to replicate the issue in google colab but colab stopped at epoch 858 due to longer training time taken.But still the Expected behaviour captured in logs.Please find attached gist [here](https://colab.research.google.com/gist/SuryanarayanaY/f69d51ac0fd2c3b7a53833ac8b06a736/58606.ipynb#scrollTo=LWN099X70JnO)."
        },
        {
            "Timestamp": "2022-11-21T16:18:31Z",
            "EntityIds": [
                61427290,
                116063290,
                116063290,
                116063290,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "8DTABFPT2NCJ"
            ],
            "Context": "Hi @Szustarol ,\r\n\r\nBy default, TensorFlow maps nearly all of the GPU memory of all GPUs (subject to [CUDA_VISIBLE_DEVICES](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars)) visible to the process.Hence i tried to create logical device to check actual memory used by the TF.\r\n\r\nFrom the documentation of `get_memory_info` [API](https://www.tensorflow.org/api_docs/python/tf/config/experimental/get_memory_info)  the dict specifies only the current and peak memory that TensorFlow is actually using, not the memory that TensorFlow has allocated on the GPU. \r\n\r\nHence i used `tf.config.experimental.get_memory_info('GPU:0')['current']` to track current Memory being used by TF process where as the nvidia memory you derived for variable `smi_ret` might be the cumulative Memory being used to store the Model configs,checkpoints,logs etc which will keep growing with no of epochs.Please refer to attached [gist](https://colab.research.google.com/gist/SuryanarayanaY/721a9909505d33494741fb19be7f7c99/58606-r1.ipynb#scrollTo=P1wqtKQehp8C) for my case. In your case since you have not limited Memory growth and also used `'peak' `memory to track hence TF allocates all the Memory on GPU and  `smi_ret` memory value also started increasing only after 856 epochs.I hope this make some sense even though it is not an elegant solution.\r\n\r\nPlease also refer to some comments from other developers for similar issues [comment1](https://github.com/tensorflow/tensorflow/issues/36465#issuecomment-1072994037), [comment2](https://github.com/tensorflow/tensorflow/issues/36465#issuecomment-1073040685) which might be useful for understanding this case.\r\n"
        },
        {
            "Timestamp": "2022-11-21T21:19:54Z",
            "EntityIds": [
                61427290,
                116063290,
                116063290,
                116063290,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "8DTABFPT2NCJ"
            ],
            "Context": "Hello @SuryanarayanaY,\r\n I did measure the amount of \"current\" memory used but I am not sure if this is really the problem here, so I chose to monitor the peak value which should better indicate, that TensorFlow really thinks it ever allocated *less* memory than it actually did. What I find wrong is the fact that as the training proceeds, the cumulative memory allocated on the GPU grows by over 8 GB and finally causes an OOM error after about 800 epochs, which shouldn't happen, and does not happen when the `cuda_malloc_async` flag is not set (as far as my tests show).\r\n\r\nI might be wrong but this, for me, is a memory leak when the platform in some circumstances (setting a flag) causes OOM.\r\nWhat I am trying to say is:\r\n- either the memory is not cleared when it should be cleared automatically (like previous samples from dataset generator are not released),\r\n- or for some reason cuda_malloc_async allocates extra data on the GPU memory which causes the VRAM usage to grow as the training progresses.\r\n\r\n\r\nTo further illustrate the problem I provide yet another colab notebook: \r\nhttps://colab.research.google.com/drive/1R1w3HVb3JIqNftF_FsnBT6OwvWsYwNmW?usp=sharing\r\nThe *only* difference between this notebook and the previous one, is that the `cuda_malloc_async` flag is NOT set. And now you can see, that the GPU memory taken never exceeds ~8.5 GB, even though training continues for 1500 epochs, while you have been able to confirm, that around 900 epochs is enough to crash the malloc_async version."
        },
        {
            "Timestamp": "2022-11-29T13:28:36Z",
            "EntityIds": [
                61427290,
                116063290,
                116063290,
                116063290,
                116063290
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "8DTABFPT2NCJ"
            ],
            "Context": "@sachinprasadhs could you please look into the issue?"
        },
        {
            "Timestamp": "2022-11-17T08:54:58Z",
            "EntityIds": [
                86464649,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "10FW3I0CWJXR"
            ],
            "Context": "Fixed some typos in embedding_ops.py. Fixed some typos in embedding_ops.py."
        },
        {
            "Timestamp": "2022-11-17T08:54:58Z",
            "EntityIds": [
                86464649,
                48215717
            ],
            "Symbol": "Pull Request",
            "Relational ID": [
                "10FW3I0CWJXR"
            ],
            "Context": "Fixed some typos in embedding_ops.py. Fixed some typos in embedding_ops.py."
        },
        {
            "Timestamp": "2022-11-16T18:19:09Z",
            "EntityIds": [
                20158647,
                86464649,
                86464649,
                86464649
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "GVFU8UWYZ2NU"
            ],
            "Context": "TF2.11 Release Estimate?. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nOthers\n\n### Source\n\nsource\n\n### Tensorflow Version\n\nTF2.11\n\n### Custom Code\n\nNo\n\n### OS Platform and Distribution\n\n_No response_\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n_No response_\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nNoticed that there has been activity on the TF2.11 branch for release, and wanted to inquire if there was an ETA on this particular release, or a timeline on when we should expect another RC for TF2.11?\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nN/A\n```\n\n\n### Relevant log output\n\n_No response_</details>"
        },
        {
            "Timestamp": "2022-11-17T04:06:13Z",
            "EntityIds": [
                20158647,
                86464649,
                86464649,
                86464649
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "GVFU8UWYZ2NU"
            ],
            "Context": "Hi @ohadkatz !\r\n\r\nThat is a good question actually. \r\nCould you post it on TF forum too. \r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-21T08:44:20Z",
            "EntityIds": [
                20158647,
                86464649,
                86464649,
                86464649
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "GVFU8UWYZ2NU"
            ],
            "Context": "@ohadkatz !\r\n2.11  stable version has been released now. Check the release notes from [here](https://github.com/tensorflow/tensorflow/releases).\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-16T18:11:12Z",
            "EntityIds": [
                25738889,
                111861663,
                111861663,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "BI72L473OPJ1"
            ],
            "Context": "TFLite benchmark tool - example to use input_layer_value_files. Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: No\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**: Source\r\n-   **TensorFlow version (use command below)**: \r\n-   **Python version**:\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nI am trying to use the Android TFLite benchmark tool to run inference time analysis for my TFLite model. Going through the [repo](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark), I am interested in passing custom inputs to the benchmark tool. I am specifically looking for how to use input_layer_value_files flag. Could you provide an example of a sample file? Thanks!\r\n\r\n### Source code / logs\r\n-\r\n"
        },
        {
            "Timestamp": "2022-11-17T10:55:25Z",
            "EntityIds": [
                25738889,
                111861663,
                111861663,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "BI72L473OPJ1"
            ],
            "Context": "@AbinayaKumar25 \r\nCould you please refer to the [Benchmark tools](https://www.tensorflow.org/lite/performance/measurement) and let us know if it helps.\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-24T11:02:31Z",
            "EntityIds": [
                25738889,
                111861663,
                111861663,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "BI72L473OPJ1"
            ],
            "Context": "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n"
        },
        {
            "Timestamp": "2022-12-01T11:16:22Z",
            "EntityIds": [
                25738889,
                111861663,
                111861663,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "BI72L473OPJ1"
            ],
            "Context": "Closing as stale. Please reopen if you'd like to work on this further.\n"
        },
        {
            "Timestamp": "2022-12-01T11:16:26Z",
            "EntityIds": [
                25738889,
                111861663,
                111861663,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "BI72L473OPJ1"
            ],
            "Context": "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58603\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58603\">No</a>\n"
        },
        {
            "Timestamp": "2022-11-16T15:23:07Z",
            "EntityIds": [
                8885699,
                116063290,
                116063290,
                116063290,
                1107341,
                1107341,
                56610014,
                323199,
                66660475,
                10442001,
                56610014
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "H5XALHSZRKXI"
            ],
            "Context": "Tensorflow 2.10 cannot be installed using `poetry` on linux aarch64. <details><summary>Click to expand!</summary> \r\n \r\n ### Issue Type\r\n\r\nBuild/Install\r\n\r\n### Source\r\n\r\nbinary\r\n\r\n### Tensorflow Version\r\n\r\n2.10.0\r\n\r\n### Custom Code\r\n\r\nNo\r\n\r\n### OS Platform and Distribution\r\n\r\nlinux aarch64\r\n\r\n### Mobile device\r\n\r\n_No response_\r\n\r\n### Python version\r\n\r\n3.8\r\n\r\n### Bazel version\r\n\r\n_No response_\r\n\r\n### GCC/Compiler version\r\n\r\n_No response_\r\n\r\n### CUDA/cuDNN version\r\n\r\n_No response_\r\n\r\n### GPU model and memory\r\n\r\n_No response_\r\n\r\n### Current Behaviour?\r\n\r\nPoetry parses the endpoint at `https://pypi.org/pypi/tensorflow/2.10.0/json` to get dependency metadata. The endpoint returns:\r\n```shell\r\n[\r\n  \"absl-py (>=1.0.0)\",\r\n  \"astunparse (>=1.6.0)\",\r\n  \"flatbuffers (>=2.0)\",\r\n  \"gast (<=0.4.0,>=0.2.1)\",\r\n  \"google-pasta (>=0.1.1)\",\r\n  \"h5py (>=2.9.0)\",\r\n  \"keras-preprocessing (>=1.1.1)\",\r\n  \"libclang (>=13.0.0)\",\r\n  \"numpy (>=1.20)\",\r\n  \"opt-einsum (>=2.3.2)\",\r\n  \"packaging\",\r\n  \"protobuf (<3.20,>=3.9.2)\",\r\n  \"setuptools\",\r\n  \"six (>=1.12.0)\",\r\n  \"termcolor (>=1.1.0)\",\r\n  \"typing-extensions (>=3.6.6)\",\r\n  \"wrapt (>=1.11.0)\",\r\n  \"tensorflow-io-gcs-filesystem (>=0.23.1)\",\r\n  \"grpcio (<2.0,>=1.24.3)\",\r\n  \"tensorboard (<2.11,>=2.10)\",\r\n  \"tensorflow-estimator (<2.11,>=2.10.0)\",\r\n  \"keras (<2.11,>=2.10.0)\"\r\n]\r\n```\r\n\r\nHowever, the linux aarch64 wheel has different dependencies, namely `tensorflow-cpu-aws`. Since the dependency metadata is split across wheels, package managers like `poetry` are unable to resolve them correctly. \r\n\r\n**The solution is to have a unified list of dependencies across wheels, with PEP508 environment markers to specify platform-specific dependencies.**\r\n\r\n### Standalone code to reproduce the issue\r\n\r\n```shell\r\npoetry add tensorflow@2.10.0\r\npoetry shell\r\npython -c \"import tensorflow\"\r\n```\r\n\r\n\r\n### Relevant log output\r\n\r\n```shell\r\n(app-py3.8) root@53e9f35d6529:/app# python -c \"import tensorflow\"\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'tensorflow'\r\n```\r\n</details>"
        },
        {
            "Timestamp": "2022-11-17T12:52:52Z",
            "EntityIds": [
                8885699,
                116063290,
                116063290,
                116063290,
                1107341,
                1107341,
                56610014,
                323199,
                66660475,
                10442001,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "H5XALHSZRKXI"
            ],
            "Context": "Hi @ColinVDH ,\r\n\r\nCould you please refer similar issues attached here and see whether they are helpful to you.Please refer [TF-48939](https://github.com/tensorflow/tensorflow/issues/48939), [56921](https://github.com/tensorflow/tensorflow/issues/56921#issuecomment-1259797988), [SO](https://stackoverflow.com/questions/70356867/solverproblemerror-on-install-tensorfow-with-poetry) and [python_poetry](https://github.com/python-poetry/poetry/issues/1330) here and let us know if it helps?\r\n\r\nThankyou!"
        },
        {
            "Timestamp": "2022-11-22T17:53:36Z",
            "EntityIds": [
                8885699,
                116063290,
                116063290,
                116063290,
                1107341,
                1107341,
                56610014,
                323199,
                66660475,
                10442001,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "H5XALHSZRKXI"
            ],
            "Context": "@SuryanarayanaY The issue can be worked around by adding the following to the `pyproject.toml`:\r\n```\r\ntensorflow = \"2.10.0\"\r\ntensorflow-cpu-aws = {\"version\" = \"2.10.0\", markers = \"platform_system == 'Linux' and (platform_machine == 'arm64' or platform_machine == 'aarch64')\"}\r\n```\r\n\r\nHowever, this is a workaround. Ideally the correct dependencies should be listed in https://pypi.org/pypi/tensorflow/json in the `requires_dist` section of `info`. Namely, `tensorflow-cpu-aws` should be correctly listed as a dependency in the linux aarch64 environment."
        },
        {
            "Timestamp": "2022-11-23T12:38:38Z",
            "EntityIds": [
                8885699,
                116063290,
                116063290,
                116063290,
                1107341,
                1107341,
                56610014,
                323199,
                66660475,
                10442001,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "H5XALHSZRKXI"
            ],
            "Context": "Hi @ColinVDH,\r\n\r\nGlad that you find a workaround.I will also escalate your suggestion in above [comment](https://github.com/tensorflow/tensorflow/issues/58602#issuecomment-1324045059) to Development team for their review and see what can be done. \r\n\r\nSince your issue got resolved would you like to close the issue ?\r\n"
        },
        {
            "Timestamp": "2022-11-24T15:58:56Z",
            "EntityIds": [
                8885699,
                116063290,
                116063290,
                116063290,
                1107341,
                1107341,
                56610014,
                323199,
                66660475,
                10442001,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "H5XALHSZRKXI"
            ],
            "Context": "Hey @SuryanarayanaY, we noticed that the released arm packages for tensorflow 2.10 and 2.11 are broken, or rather empty, which leads to the described problem of not being able to import tensorflow. You can see this on the [pypi downloadable files page for tf 2.10.1](https://pypi.org/project/tensorflow/2.10.1/#files). You see that all the aarch64 packages have a size of only 1.9 kb"
        },
        {
            "Timestamp": "2022-11-24T16:24:12Z",
            "EntityIds": [
                8885699,
                116063290,
                116063290,
                116063290,
                1107341,
                1107341,
                56610014,
                323199,
                66660475,
                10442001,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "H5XALHSZRKXI"
            ],
            "Context": "It seems that tensorflow-cpu-aws then contains the actual tensorflow code for arm which is odd since probably not all arm machines are on aws"
        },
        {
            "Timestamp": "2022-12-01T17:16:19Z",
            "EntityIds": [
                8885699,
                116063290,
                116063290,
                116063290,
                1107341,
                1107341,
                56610014,
                323199,
                66660475,
                10442001,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "H5XALHSZRKXI"
            ],
            "Context": "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n"
        },
        {
            "Timestamp": "2022-12-01T17:23:30Z",
            "EntityIds": [
                8885699,
                116063290,
                116063290,
                116063290,
                1107341,
                1107341,
                56610014,
                323199,
                66660475,
                10442001,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "H5XALHSZRKXI"
            ],
            "Context": "CC @nitins17 @learning-to-play @rishikasinha-tf "
        },
        {
            "Timestamp": "2022-12-02T00:35:17Z",
            "EntityIds": [
                8885699,
                116063290,
                116063290,
                116063290,
                1107341,
                1107341,
                56610014,
                323199,
                66660475,
                10442001,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "H5XALHSZRKXI"
            ],
            "Context": "Hi @elfringham @mseth10 Could you please take a look?"
        },
        {
            "Timestamp": "2022-12-02T16:25:10Z",
            "EntityIds": [
                8885699,
                116063290,
                116063290,
                116063290,
                1107341,
                1107341,
                56610014,
                323199,
                66660475,
                10442001,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "H5XALHSZRKXI"
            ],
            "Context": "@twerkmeister The released ARM64 packages are neither broken nor empty. They are simple redirects to where the full installs can be found which is why they are so small. You may run 'pip install tensorflow' on AARCH64 and it will install the desired package.\r\ntensorflow-cpu-aws is so named because it is built using AWS resources, the name is not meant to imply that it is only suitable for running on AWS instances."
        },
        {
            "Timestamp": "2022-12-06T00:23:27Z",
            "EntityIds": [
                8885699,
                116063290,
                116063290,
                116063290,
                1107341,
                1107341,
                56610014,
                323199,
                66660475,
                10442001,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "H5XALHSZRKXI"
            ],
            "Context": "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58602\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58602\">No</a>\n"
        },
        {
            "Timestamp": "2022-11-16T14:16:37Z",
            "EntityIds": [
                78156688,
                48215717,
                5112267
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "PK5584502BLX"
            ],
            "Context": "Fix the endianness issue in v1 frozen graphs in python:lite_test on BE machines. This PR is to add big-endian support to TensorFlow v1 frozen graphs.\r\n \r\nThe `byte_swap_tensor` related code in `tensorflow/python/saved_model/utils_impl.py` has been refactored and function `swap_tensor_in_frozen_graph()` was added to deal with the LE/BE conversion in TensorFlow v1 frozen graphs. This function is invoked in frozen graph read/write process so that TensorFlow v1 frozen graphs would be stored with LE format in files and converted to BE format after being loaded into memory on BE machines.\r\n \r\nThis code change also extended the covered code paths for byte-swapping in read/write process of TensorFlow v2 saved models.\r\n \r\nThis PR could fix `//tensorflow/lite/python:lite_test` on s390x (BE machines) and will not cause any regressions on LE/BE platforms.\r\n\r\nFixes issue https://github.com/tensorflow/tensorflow/issues/57215 .\r\n\r\nSigned-off-by: Kun-Lu <kun.lu@ibm.com>"
        },
        {
            "Timestamp": "2022-11-21T16:10:38Z",
            "EntityIds": [
                78156688,
                48215717,
                5112267
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "PK5584502BLX"
            ],
            "Context": "Hi @alankelly ,\r\n\r\nCould you please review this PR when you have some time? Thank you very much!"
        },
        {
            "Timestamp": "2022-11-29T13:20:46Z",
            "EntityIds": [
                78156688,
                48215717,
                5112267
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "PK5584502BLX"
            ],
            "Context": "Hi @alankelly ,\r\n\r\nHope all is well. \r\n\r\nCould you please have a look at this PR? Thank you!"
        },
        {
            "Timestamp": "2022-11-29T14:33:25Z",
            "EntityIds": [
                78156688,
                48215717,
                5112267
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "PK5584502BLX"
            ],
            "Context": "@terryheo Can you PTAL at this? This is really not my domain. Thanks1"
        },
        {
            "Timestamp": "2022-12-02T19:48:49Z",
            "EntityIds": [
                78156688,
                48215717,
                5112267
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "PK5584502BLX"
            ],
            "Context": "Hi @terryheo ,\r\n\r\nCould you please review this PR when you have some time? Thank you very much!"
        },
        {
            "Timestamp": "2022-11-16T14:16:37Z",
            "EntityIds": [
                78156688,
                48215717,
                5112267
            ],
            "Symbol": "Pull Request",
            "Relational ID": [
                "PK5584502BLX"
            ],
            "Context": "Fix the endianness issue in v1 frozen graphs in python:lite_test on BE machines. This PR is to add big-endian support to TensorFlow v1 frozen graphs.\r\n \r\nThe `byte_swap_tensor` related code in `tensorflow/python/saved_model/utils_impl.py` has been refactored and function `swap_tensor_in_frozen_graph()` was added to deal with the LE/BE conversion in TensorFlow v1 frozen graphs. This function is invoked in frozen graph read/write process so that TensorFlow v1 frozen graphs would be stored with LE format in files and converted to BE format after being loaded into memory on BE machines.\r\n \r\nThis code change also extended the covered code paths for byte-swapping in read/write process of TensorFlow v2 saved models.\r\n \r\nThis PR could fix `//tensorflow/lite/python:lite_test` on s390x (BE machines) and will not cause any regressions on LE/BE platforms.\r\n\r\nFixes issue https://github.com/tensorflow/tensorflow/issues/57215 .\r\n\r\nSigned-off-by: Kun-Lu <kun.lu@ibm.com>"
        },
        {
            "Timestamp": "2022-11-16T13:54:48Z",
            "EntityIds": [
                60800749,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "0LB9QQP0LKI6"
            ],
            "Context": "Move plugin rule to the XLA directory. Moves the dependency of `//tensorflow/compiler/xla/pjrt:pjrt_plugin_device_client` from `//tensorflow/compiler/plugin` to `//tensorflow/compiler/xla/pjrt/plugin`.\r\n\r\nThe old plugin folder is retained to avoid breaking anyone using that rule for unrelated reasons, but it no longer connects to the xla_client.\r\n\r\n@joker-eph @skye @penpornk "
        },
        {
            "Timestamp": "2022-11-16T13:59:01Z",
            "EntityIds": [
                60800749,
                48215717
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "0LB9QQP0LKI6"
            ],
            "Context": "For additional context see this thread https://github.com/tensorflow/tensorflow/pull/57193#discussion_r1022240126"
        },
        {
            "Timestamp": "2022-11-16T13:54:48Z",
            "EntityIds": [
                60800749,
                48215717
            ],
            "Symbol": "Pull Request",
            "Relational ID": [
                "0LB9QQP0LKI6"
            ],
            "Context": "Move plugin rule to the XLA directory. Moves the dependency of `//tensorflow/compiler/xla/pjrt:pjrt_plugin_device_client` from `//tensorflow/compiler/plugin` to `//tensorflow/compiler/xla/pjrt/plugin`.\r\n\r\nThe old plugin folder is retained to avoid breaking anyone using that rule for unrelated reasons, but it no longer connects to the xla_client.\r\n\r\n@joker-eph @skye @penpornk "
        },
        {
            "Timestamp": "2022-11-16T21:23:13Z",
            "Entity Ids": [
                null
            ],
            "Symbol": "Pull Request Merged",
            "Relational IDs": [
                "0LB9QQP0LKI6"
            ],
            "Context": "Move plugin rule to the XLA directory. Moves the dependency of `//tensorflow/compiler/xla/pjrt:pjrt_plugin_device_client` from `//tensorflow/compiler/plugin` to `//tensorflow/compiler/xla/pjrt/plugin`.\r\n\r\nThe old plugin folder is retained to avoid breaking anyone using that rule for unrelated reasons, but it no longer connects to the xla_client.\r\n\r\n@joker-eph @skye @penpornk "
        },
        {
            "Timestamp": "2022-11-16T09:33:42Z",
            "EntityIds": [
                9656425,
                73069040,
                86464649,
                86464649,
                73069040,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "PBRHLASU71BF"
            ],
            "Context": "there is no operator to calculate the matrix's inverse using tflite. tf.raw_ops.MatrixInverse and tf.linalg.svd is not supported in tflite \r\nBatchMatrixInverse is not available in GraphDef version 1205.\r\n\r\nHence\uff0c how to calculate the matrix's inverse using tflite?\r\n\r\nI need some Op to calculate the  matrix's inverse\r\n\r\n\r\nbest wishes\r\n\r\n\r\n\r\n\r\n"
        },
        {
            "Timestamp": "2022-11-16T13:09:29Z",
            "EntityIds": [
                9656425,
                73069040,
                86464649,
                86464649,
                73069040,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "PBRHLASU71BF"
            ],
            "Context": "Hi @ZYX-MLer !\r\nI can see BatchMatrixInverse in [select ops ](https://www.tensorflow.org/lite/guide/op_select_allowlist)allow list . You can include them in lite model by following [select ops](https://www.tensorflow.org/lite/guide/ops_select) syntax.\r\n```\r\nconverter.target_spec.supported_ops = [\r\n  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\r\n  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\r\n]\r\n\r\n```\r\nYou can also check in [custom Ops documentation ](https://www.tensorflow.org/lite/guide/ops_custom)for registering a custom op which might address your requirement.\r\n\r\n@sachinprasadhs ! \r\nCould you look at this issue.\r\n\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-16T13:43:21Z",
            "EntityIds": [
                9656425,
                73069040,
                86464649,
                86464649,
                73069040,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "PBRHLASU71BF"
            ],
            "Context": "> Hi @ZYX-MLer ! I can see BatchMatrixInverse in [select ops ](https://www.tensorflow.org/lite/guide/op_select_allowlist)allow list . You can include them in lite model through [select ops](https://www.tensorflow.org/lite/guide/ops_select) syntax.\r\n> \r\n> ```\r\n> converter.target_spec.supported_ops = [\r\n>   tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\r\n>   tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\r\n> ]\r\n> ```\r\n> \r\n> You can also check in [custom Ops documentation ](https://www.tensorflow.org/lite/guide/ops_custom)for registering a custom op which might address your requirement.\r\n> \r\n> @sachinprasadhs ! Could you look at this issue.\r\n> \r\n> Thank you!\r\n\r\nthank you for your replay,\r\n\r\nmy tf is 2.10, my system is MacOS Monterey, and my code is as follows:\r\n\r\n`Ma_t = tf.linalg.matrix_transpose(Ma)`\r\n`Ma_i = tf.raw_ops.MatrixInverse(input=tf.matmul(Ma_t, Ma))`\r\n`Ma_i = tf.matmul(Ma, Ma_i)`\r\n\r\nthen  I got the following error.\r\n\r\n\"tensorflow.lite.python.convert_phase.ConverterError: <unknown>:0: error: loc(callsite(callsite(fused[\"MatrixInverse:\", \"MatrixInverse@__inference_call_78\"] at fused[\"PartitionedCall:\", \"PartitionedCall@__inference_signature_wrapper_102\"]) at fused[\"PartitionedCall:\", \"PartitionedCall\"])): 'tf.MatrixInverse' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(fused[\"PartitionedCall:\", \"PartitionedCall\"]): called from\r\n<unknown>:0: note: loc(callsite(callsite(fused[\"MatrixInverse:\", \"MatrixInverse@__inference_call_78\"] at fused[\"PartitionedCall:\", \"PartitionedCall@__inference_signature_wrapper_102\"]) at fused[\"PartitionedCall:\", \"PartitionedCall\"])): Error code: ERROR_NEEDS_FLEX_OPS\r\n<unknown>:0: error: failed while converting: 'call': \r\nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \r\nTF Select ops: MatrixInverse\r\nDetails:\r\n\ttf.MatrixInverse(tensor<3x3xf32>) -> (tensor<3x3xf32>) : {adjoint = false, device = \"\"}\r\n\"\r\n\r\nbest wishes"
        },
        {
            "Timestamp": "2022-11-16T16:06:20Z",
            "EntityIds": [
                9656425,
                73069040,
                86464649,
                86464649,
                73069040,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "PBRHLASU71BF"
            ],
            "Context": "@ZYX-MLer !\r\nYou got the Select ops error as expected. Just add these two code snippet before conversion.\r\n```\r\n#load the model using load from saved_model or concrete_function, see [TF lite converter.](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter) doc.\r\n.......\r\n#add select ops syntax\r\n......\r\nconverter.target_spec.supported_ops = [\r\n  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\r\n  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\r\n]\r\ntflite_model = converter.convert()\r\n\r\n```\r\nThank you!"
        },
        {
            "Timestamp": "2022-11-17T11:21:21Z",
            "EntityIds": [
                9656425,
                73069040,
                86464649,
                86464649,
                73069040,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "PBRHLASU71BF"
            ],
            "Context": "> @ZYX-MLer ! You got the Select ops error as expected. Just add these two code snippet before conversion.\r\n> \r\n> ```\r\n> #load the model using load from saved_model or concrete_function, see [TF lite converter.](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter) doc.\r\n> .......\r\n> #add select ops syntax\r\n> ......\r\n> converter.target_spec.supported_ops = [\r\n>   tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\r\n>   tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\r\n> ]\r\n> tflite_model = converter.convert()\r\n> ```\r\n> \r\n> Thank you!\r\n\r\nThank you for your replay, I covert the model successfully, after adding the tf.lite.OpsSet.SELECT_TF_OPS. \r\n\r\nwhat the different between the TensorFlow lite ops and TensorFlow ops? \r\n\r\nDose it only increase the size of aar?\r\n\r\nBy the way, is there some best practice on deploying algorithm on dsp or npu? the ops supported by the nnapi is so limited. I need some matrix ops such as multiplication and inverse.\r\n\r\n\r\n\r\nBest wishes\r\n"
        },
        {
            "Timestamp": "2022-11-17T20:56:37Z",
            "EntityIds": [
                9656425,
                73069040,
                86464649,
                86464649,
                73069040,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "PBRHLASU71BF"
            ],
            "Context": "Tensorflow Lite operators are TFLite builtin operators, TFLite builtin ops are usually recommended because it is simple to optimize and also it will be lesser in size.\r\n![image](https://user-images.githubusercontent.com/73069040/202538112-5ea7ef96-9209-421e-96a6-f27ec3395fe0.png)\r\n\r\nYou can refer to the document [here](https://www.tensorflow.org/lite/guide/ops_compatibility) for complete details. \r\n\r\nThe list of supported `builtinops` for different data types can be found [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema_generated.h#L909).\r\nTeam is working on including more OP under builtin ops, till then you can make use of Select OP. \r\n\r\nFor example usage and more details on delegates, refer the document [here](https://www.tensorflow.org/lite/android/delegates/hexagon).\r\n"
        },
        {
            "Timestamp": "2022-11-24T21:02:31Z",
            "EntityIds": [
                9656425,
                73069040,
                86464649,
                86464649,
                73069040,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "PBRHLASU71BF"
            ],
            "Context": "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n"
        },
        {
            "Timestamp": "2022-12-01T21:16:20Z",
            "EntityIds": [
                9656425,
                73069040,
                86464649,
                86464649,
                73069040,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "PBRHLASU71BF"
            ],
            "Context": "Closing as stale. Please reopen if you'd like to work on this further.\n"
        },
        {
            "Timestamp": "2022-12-01T21:16:23Z",
            "EntityIds": [
                9656425,
                73069040,
                86464649,
                86464649,
                73069040,
                56610014,
                56610014,
                56610014
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "PBRHLASU71BF"
            ],
            "Context": "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58599\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/58599\">No</a>\n"
        },
        {
            "Timestamp": "2022-11-16T01:16:16Z",
            "EntityIds": [
                106367904
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "V0RLSHESJW19"
            ],
            "Context": "Broken tests is causing release builds failures - TF 2.11.0. # TODO(b/259319686) : Disable the test"
        },
        {
            "Timestamp": "2022-11-16T01:16:16Z",
            "EntityIds": [
                106367904
            ],
            "Symbol": "Pull Request",
            "Relational ID": [
                "V0RLSHESJW19"
            ],
            "Context": "Broken tests is causing release builds failures - TF 2.11.0. # TODO(b/259319686) : Disable the test"
        },
        {
            "Timestamp": "2022-11-16T01:17:12Z",
            "Entity Ids": [
                null
            ],
            "Symbol": "Pull Request Merged",
            "Relational IDs": [
                "V0RLSHESJW19"
            ],
            "Context": "Broken tests is causing release builds failures - TF 2.11.0. # TODO(b/259319686) : Disable the test"
        },
        {
            "Timestamp": "2022-11-16T01:02:38Z",
            "EntityIds": [
                3444368,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "IZ009J46U53D"
            ],
            "Context": "Support writing non conversion report to more filesystems. This PR allows tf trt non conversion report to save in all filesystems supported by tensorflow. This is especially useful when user has a use case to convert a remotely saved model.\r\n\r\nRegarding unit test: I didn't find corresponding unit test for this function in `segment_test.cc`. For this kind of functionality maybe an integration test is more suitable? Please let me know and I could work on that."
        },
        {
            "Timestamp": "2022-11-22T22:32:14Z",
            "EntityIds": [
                3444368,
                48215717
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "IZ009J46U53D"
            ],
            "Context": "@bixia1 gentle ping. Could I get a review for this PR? Thanks!"
        },
        {
            "Timestamp": "2022-12-01T20:06:00Z",
            "EntityIds": [
                3444368,
                48215717
            ],
            "Symbol": "Issue Comment",
            "Relational ID": [
                "IZ009J46U53D"
            ],
            "Context": "@gbaned @bixia1 Hi there! I would like to get a review on this PR. Thanks!"
        },
        {
            "Timestamp": "2022-11-16T01:02:38Z",
            "EntityIds": [
                3444368,
                48215717
            ],
            "Symbol": "Pull Request",
            "Relational ID": [
                "IZ009J46U53D"
            ],
            "Context": "Support writing non conversion report to more filesystems. This PR allows tf trt non conversion report to save in all filesystems supported by tensorflow. This is especially useful when user has a use case to convert a remotely saved model.\r\n\r\nRegarding unit test: I didn't find corresponding unit test for this function in `segment_test.cc`. For this kind of functionality maybe an integration test is more suitable? Please let me know and I could work on that."
        }
    ]
}