{
    "Data Name": "Github Data for Tensorflow",
    "Creation Date": "2015-11-07T01:19:20Z",
    "Data Range Start": "2015-11-09T14:21:11Z",
    "Data Range End": "2022-09-01T22:12:06Z",
    "Version Information": 1.0,
    "Provenance Information": "Utlizes data/gh_Issues.json, data/gh_Pulls.json and dynamic requests to the Github API",
    "Predicted Symbols": [
        "tbd"
    ],
    "Prediction Period": "tbd",
    "Entities": [
        {
            "Id": 106367904,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T22:12:06Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-05-27T05:25:55Z",
                    "Valid To": "2022-08-23T21:44:45Z"
                }
            ]
        },
        {
            "Id": 106367904,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T21:35:23Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-09-01T21:35:23Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-05-27T05:25:55Z",
                    "Valid To": "2022-08-23T21:44:45Z"
                }
            ]
        },
        {
            "Id": 739632,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T19:56:01Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2011-04-19T17:52:26Z",
                    "Valid To": "2021-08-09T01:05:34Z"
                }
            ]
        },
        {
            "Id": 323199,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T18:33:36Z",
                    "Valid To": "2022-09-01T18:34:47Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-09-01T18:33:36Z",
                    "Valid To": "2022-09-01T18:34:47Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2010-07-05T11:26:31Z",
                    "Valid To": "2022-10-29T18:11:58Z"
                }
            ]
        },
        {
            "Id": 86808158,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T18:33:04Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-09-01T18:33:04Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-07-01T22:48:26Z",
                    "Valid To": "2022-06-23T19:01:42Z"
                }
            ]
        },
        {
            "Id": 10923599,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T18:31:25Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-09-01T18:31:25Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2015-02-09T13:35:29Z",
                    "Valid To": "2022-10-24T22:25:44Z"
                }
            ]
        },
        {
            "Id": 323199,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T18:16:28Z",
                    "Valid To": "2022-09-01T18:22:43Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-09-01T18:16:28Z",
                    "Valid To": "2022-09-01T18:22:43Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2010-07-05T11:26:31Z",
                    "Valid To": "2022-10-29T18:11:58Z"
                }
            ]
        },
        {
            "Id": 80416898,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T18:07:46Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-09-01T18:07:46Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-03-10T17:27:05Z",
                    "Valid To": "2022-10-13T23:36:44Z"
                }
            ]
        },
        {
            "Id": 86808158,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T18:04:58Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-09-01T18:04:58Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-07-01T22:48:26Z",
                    "Valid To": "2022-06-23T19:01:42Z"
                }
            ]
        },
        {
            "Id": 323199,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T18:04:34Z",
                    "Valid To": "2022-09-01T18:04:52Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-09-01T18:04:34Z",
                    "Valid To": "2022-09-01T18:04:52Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2010-07-05T11:26:31Z",
                    "Valid To": "2022-10-29T18:11:58Z"
                }
            ]
        },
        {
            "Id": 32910461,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T16:53:07Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-09-01T16:53:07Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2017-10-18T18:10:59Z",
                    "Valid To": "2022-10-24T15:49:29Z"
                }
            ]
        },
        {
            "Id": 10442001,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T14:40:00Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-09-01T14:40:00Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2015-01-07T23:05:07Z",
                    "Valid To": "2022-10-28T10:21:55Z"
                }
            ]
        },
        {
            "Id": 107059430,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T14:20:31Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-06-07T15:08:29Z",
                    "Valid To": "2022-10-08T10:19:15Z"
                }
            ]
        },
        {
            "Id": 10442001,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T14:14:23Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-09-01T14:14:23Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2015-01-07T23:05:07Z",
                    "Valid To": "2022-10-28T10:21:55Z"
                }
            ]
        },
        {
            "Id": 13285808,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T12:40:38Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-09-01T12:40:38Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2015-07-11T07:54:07Z",
                    "Valid To": "2022-10-24T18:25:10Z"
                }
            ]
        },
        {
            "Id": 27568333,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T12:26:25Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2017-04-15T16:01:50Z",
                    "Valid To": "2022-11-01T17:02:45Z"
                }
            ]
        },
        {
            "Id": 50069574,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T09:42:05Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2019-04-28T07:41:22Z",
                    "Valid To": "2022-10-24T09:11:55Z"
                }
            ]
        },
        {
            "Id": 67035463,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T09:31:52Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2020-06-17T02:43:34Z",
                    "Valid To": "2022-08-13T06:00:54Z"
                }
            ]
        },
        {
            "Id": 75348594,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T09:14:20Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2020-12-02T02:50:11Z",
                    "Valid To": "2022-07-12T16:47:22Z"
                }
            ]
        },
        {
            "Id": 71369657,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T05:59:50Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2020-09-16T06:08:09Z",
                    "Valid To": "2022-08-16T04:37:11Z"
                }
            ]
        },
        {
            "Id": 108649012,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T05:49:49Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-07-04T05:10:06Z",
                    "Valid To": "2022-10-24T16:40:17Z"
                }
            ]
        },
        {
            "Id": 86464649,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T05:19:53Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-09-01T05:19:53Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-06-25T07:31:47Z",
                    "Valid To": "2022-11-02T05:30:26Z"
                }
            ]
        },
        {
            "Id": 106367904,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T02:53:28Z",
                    "Valid To": "2022-09-01T03:08:18Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-09-01T02:53:28Z",
                    "Valid To": "2022-09-01T03:08:18Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-05-27T05:25:55Z",
                    "Valid To": "2022-08-23T21:44:45Z"
                }
            ]
        },
        {
            "Id": 106367904,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T02:34:50Z",
                    "Valid To": "2022-09-01T02:36:37Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-09-01T02:34:50Z",
                    "Valid To": "2022-09-01T02:36:37Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-05-27T05:25:55Z",
                    "Valid To": "2022-08-23T21:44:45Z"
                }
            ]
        },
        {
            "Id": 7644676,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T00:46:08Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2014-05-20T12:44:03Z",
                    "Valid To": "2022-11-02T11:18:32Z"
                }
            ]
        },
        {
            "Id": 241317,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-09-01T00:18:05Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2010-04-11T01:28:24Z",
                    "Valid To": "2022-06-22T00:07:14Z"
                }
            ]
        },
        {
            "Id": 16668746,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T22:04:15Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2016-01-12T15:09:28Z",
                    "Valid To": "2022-11-03T12:35:47Z"
                }
            ]
        },
        {
            "Id": 323199,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T21:27:11Z",
                    "Valid To": "2022-08-31T21:28:45Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-31T21:27:11Z",
                    "Valid To": "2022-08-31T21:28:45Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2010-07-05T11:26:31Z",
                    "Valid To": "2022-10-29T18:11:58Z"
                }
            ]
        },
        {
            "Id": 323199,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T21:19:52Z",
                    "Valid To": "2022-08-31T21:20:33Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-31T21:19:52Z",
                    "Valid To": "2022-08-31T21:20:33Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2010-07-05T11:26:31Z",
                    "Valid To": "2022-10-29T18:11:58Z"
                }
            ]
        },
        {
            "Id": 323199,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T21:19:41Z",
                    "Valid To": "2022-08-31T21:20:37Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-31T21:19:41Z",
                    "Valid To": "2022-08-31T21:20:37Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-31T21:19:41Z",
                    "Valid To": "2022-08-31T21:20:37Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2010-07-05T11:26:31Z",
                    "Valid To": "2022-10-29T18:11:58Z"
                }
            ]
        },
        {
            "Id": 10923599,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T20:59:10Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-31T20:59:10Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2015-02-09T13:35:29Z",
                    "Valid To": "2022-10-24T22:25:44Z"
                }
            ]
        },
        {
            "Id": 80416898,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T20:54:04Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-31T20:54:04Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-03-10T17:27:05Z",
                    "Valid To": "2022-10-13T23:36:44Z"
                }
            ]
        },
        {
            "Id": 77295044,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T20:42:53Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2021-01-11T18:19:44Z",
                    "Valid To": "2022-08-11T17:12:12Z"
                }
            ]
        },
        {
            "Id": 77295044,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T20:31:54Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2021-01-11T18:19:44Z",
                    "Valid To": "2022-08-11T17:12:12Z"
                }
            ]
        },
        {
            "Id": 42785357,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T19:27:31Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-31T19:27:31Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Average Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2018-08-28T20:12:58Z",
                    "Valid To": "2022-10-14T22:24:41Z"
                }
            ]
        },
        {
            "Id": 6932348,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T19:05:55Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-31T19:05:55Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-31T19:05:55Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2014-03-12T17:10:12Z",
                    "Valid To": "2022-10-30T23:39:34Z"
                }
            ]
        },
        {
            "Id": 577149,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T18:04:59Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Average Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2011-01-21T20:22:16Z",
                    "Valid To": "2022-10-25T02:50:04Z"
                }
            ]
        },
        {
            "Id": 106367904,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T15:53:10Z",
                    "Valid To": "2022-08-31T15:54:06Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-31T15:53:10Z",
                    "Valid To": "2022-08-31T15:54:06Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-05-27T05:25:55Z",
                    "Valid To": "2022-08-23T21:44:45Z"
                }
            ]
        },
        {
            "Id": 50210727,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T15:50:17Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2019-05-02T16:05:33Z",
                    "Valid To": "2022-08-23T19:15:48Z"
                }
            ]
        },
        {
            "Id": 106367904,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T15:42:06Z",
                    "Valid To": "2022-08-31T15:43:12Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-31T15:42:06Z",
                    "Valid To": "2022-08-31T15:43:12Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-05-27T05:25:55Z",
                    "Valid To": "2022-08-23T21:44:45Z"
                }
            ]
        },
        {
            "Id": 45400368,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T15:09:27Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2018-11-27T17:22:14Z",
                    "Valid To": "2022-10-16T17:06:58Z"
                }
            ]
        },
        {
            "Id": 20746434,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T12:56:52Z",
                    "Valid To": "2022-09-01T14:16:28Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2016-07-30T22:28:35Z",
                    "Valid To": "2022-10-24T11:42:16Z"
                }
            ]
        },
        {
            "Id": 58871163,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T11:38:19Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": null,
                    "Valid To": null
                }
            ]
        },
        {
            "Id": 33950866,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T11:03:40Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2017-11-24T07:15:21Z",
                    "Valid To": "2022-04-06T01:58:36Z"
                }
            ]
        },
        {
            "Id": 45327670,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T07:40:44Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2018-11-25T08:05:34Z",
                    "Valid To": "2022-09-28T13:22:31Z"
                }
            ]
        },
        {
            "Id": 22957388,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T06:53:00Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2016-10-20T11:07:36Z",
                    "Valid To": "2022-10-26T08:03:35Z"
                }
            ]
        },
        {
            "Id": 2286292,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T05:33:30Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2012-09-05T17:15:42Z",
                    "Valid To": "2022-09-26T18:22:44Z"
                }
            ]
        },
        {
            "Id": 16867443,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T04:15:15Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-31T04:15:15Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Heavy Committer",
                    "Valid From": "2016-01-24T18:33:32Z",
                    "Valid To": "2022-10-18T11:22:15Z"
                }
            ]
        },
        {
            "Id": 106367904,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T00:25:24Z",
                    "Valid To": "2022-08-31T15:26:53Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-31T00:25:24Z",
                    "Valid To": "2022-08-31T15:26:53Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-05-27T05:25:55Z",
                    "Valid To": "2022-08-23T21:44:45Z"
                }
            ]
        },
        {
            "Id": 106367904,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-31T00:07:31Z",
                    "Valid To": "2022-08-31T00:17:05Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-31T00:07:31Z",
                    "Valid To": "2022-08-31T00:17:05Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-05-27T05:25:55Z",
                    "Valid To": "2022-08-23T21:44:45Z"
                }
            ]
        },
        {
            "Id": 106367904,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T23:44:42Z",
                    "Valid To": "2022-08-30T23:51:46Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-30T23:44:42Z",
                    "Valid To": "2022-08-30T23:51:46Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-05-27T05:25:55Z",
                    "Valid To": "2022-08-23T21:44:45Z"
                }
            ]
        },
        {
            "Id": 106367904,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T23:07:37Z",
                    "Valid To": "2022-08-30T23:08:10Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-30T23:07:37Z",
                    "Valid To": "2022-08-30T23:08:10Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-05-27T05:25:55Z",
                    "Valid To": "2022-08-23T21:44:45Z"
                }
            ]
        },
        {
            "Id": 106367904,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T22:26:22Z",
                    "Valid To": "2022-08-30T23:17:18Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-30T22:26:22Z",
                    "Valid To": "2022-08-30T23:17:18Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-05-27T05:25:55Z",
                    "Valid To": "2022-08-23T21:44:45Z"
                }
            ]
        },
        {
            "Id": 106367904,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T21:27:46Z",
                    "Valid To": "2022-08-30T21:58:11Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-30T21:27:46Z",
                    "Valid To": "2022-08-30T21:58:11Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2022-05-27T05:25:55Z",
                    "Valid To": "2022-08-23T21:44:45Z"
                }
            ]
        },
        {
            "Id": 16359713,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T20:45:31Z",
                    "Valid To": "2022-08-30T20:45:57Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-30T20:45:31Z",
                    "Valid To": "2022-08-30T20:45:57Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2015-12-19T07:46:44Z",
                    "Valid To": "2021-05-19T20:35:46Z"
                }
            ]
        },
        {
            "Id": 41713505,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T20:33:41Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2018-07-26T02:31:12Z",
                    "Valid To": "2022-06-29T15:42:18Z"
                }
            ]
        },
        {
            "Id": 16359713,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T20:09:00Z",
                    "Valid To": "2022-08-30T20:09:27Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-30T20:09:00Z",
                    "Valid To": "2022-08-30T20:09:27Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2015-12-19T07:46:44Z",
                    "Valid To": "2021-05-19T20:35:46Z"
                }
            ]
        },
        {
            "Id": 16359713,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T18:29:31Z",
                    "Valid To": "2022-08-30T18:32:49Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-30T18:29:31Z",
                    "Valid To": "2022-08-30T18:32:49Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "More Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2015-12-19T07:46:44Z",
                    "Valid To": "2021-05-19T20:35:46Z"
                }
            ]
        },
        {
            "Id": 86808158,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T17:25:54Z",
                    "Valid To": "2022-09-01T14:54:29Z"
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-30T17:25:54Z",
                    "Valid To": "2022-09-01T14:54:29Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-07-01T22:48:26Z",
                    "Valid To": "2022-06-23T19:01:42Z"
                }
            ]
        },
        {
            "Id": 11022453,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T16:19:53Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2015-02-16T01:00:05Z",
                    "Valid To": "2022-08-18T16:54:54Z"
                }
            ]
        },
        {
            "Id": 108412181,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T16:13:05Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-06-29T13:39:00Z",
                    "Valid To": "2022-08-21T13:48:40Z"
                }
            ]
        },
        {
            "Id": 108412181,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T15:49:47Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": null,
                    "Valid From": "2022-06-29T13:39:00Z",
                    "Valid To": "2022-08-21T13:48:40Z"
                }
            ]
        },
        {
            "Id": 84091837,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T15:45:54Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2021-05-12T16:09:31Z",
                    "Valid To": "2022-05-04T02:57:50Z"
                }
            ]
        },
        {
            "Id": 18442791,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T14:15:23Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2016-04-13T13:12:06Z",
                    "Valid To": "2022-10-05T18:23:57Z"
                }
            ]
        },
        {
            "Id": 45662732,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T14:14:50Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2018-12-06T14:11:01Z",
                    "Valid To": "2022-10-27T12:59:47Z"
                }
            ]
        },
        {
            "Id": 19678,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T14:11:01Z",
                    "Valid To": null
                },
                {
                    "Contribution Type": "Pull Requestor",
                    "Valid From": "2022-08-30T14:11:01Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2008-08-05T20:11:27Z",
                    "Valid To": "2022-10-30T21:46:22Z"
                }
            ]
        },
        {
            "Id": 45327670,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T14:04:55Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2018-11-25T08:05:34Z",
                    "Valid To": "2022-09-28T13:22:31Z"
                }
            ]
        },
        {
            "Id": 37875281,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T13:55:40Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2018-03-28T14:57:56Z",
                    "Valid To": "2022-11-03T06:56:17Z"
                }
            ]
        },
        {
            "Id": 45327670,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T13:54:54Z",
                    "Valid To": "2022-08-30T13:58:29Z"
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2018-11-25T08:05:34Z",
                    "Valid To": "2022-09-28T13:22:31Z"
                }
            ]
        },
        {
            "Id": 45327670,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T12:42:08Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2018-11-25T08:05:34Z",
                    "Valid To": "2022-09-28T13:22:31Z"
                }
            ]
        },
        {
            "Id": 45327670,
            "Symbols": [
                {
                    "Contribution Type": "Issue Creator",
                    "Valid From": "2022-08-30T12:18:29Z",
                    "Valid To": null
                }
            ],
            "Properties": [
                {
                    "Follower type": "Less Followers",
                    "Committer Type": "Light Committer",
                    "Valid From": "2018-11-25T08:05:34Z",
                    "Valid To": "2022-09-28T13:22:31Z"
                }
            ]
        }
    ],
    "Data": [
        {
            "Timestamp": "2022-09-01T22:12:06Z",
            "EntityIds": [
                106367904
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "HNIFIDL0NOVV"
            ],
            "Context": "Fix the build r2.7. Disabling the test 'slice_op_test'"
        },
        {
            "Timestamp": "2022-09-01T21:35:23Z",
            "EntityIds": [
                106367904
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "XJ4CIH1I4QHL"
            ],
            "Context": "Fix the build r2.7. Disabling the test pad_op_test, scan_ops_test, split_op_test"
        },
        {
            "Timestamp": "2022-09-01T21:35:23Z",
            "Entity Ids": [
                106367904,
                323199
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "XJ4CIH1I4QHL",
                "XK0C79QJM9WF"
            ],
            "Context": "Fix the build r2.7. Disabling the test pad_op_test, scan_ops_test, split_op_test"
        },
        {
            "Timestamp": "2022-09-01T19:56:01Z",
            "EntityIds": [
                739632,
                84765720
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "XB87XMA4T0PS"
            ],
            "Context": "Load a model from a memory buffer using Tensorflow 2.x C api. Hi, \r\nI was wondering if there is a way to load 2.x model from memory buffer like GraphDef in v1\r\n\r\nThanks\r\n"
        },
        {
            "Timestamp": "2022-09-01T18:33:36Z",
            "EntityIds": [
                323199
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "00QHT3KUJ812"
            ],
            "Context": "Fix conflict resolution error. Signed-off-by: Mihai Maruseac <mihaimaruseac@google.com>"
        },
        {
            "Timestamp": "2022-09-01T18:33:36Z",
            "Entity Ids": [
                323199
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "00QHT3KUJ812",
                "0F2BNF6842CQ"
            ],
            "Context": "Fix conflict resolution error. Signed-off-by: Mihai Maruseac <mihaimaruseac@google.com>"
        },
        {
            "Timestamp": "2022-09-01T18:33:04Z",
            "EntityIds": [
                86808158,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "0JUJN5XR0W76"
            ],
            "Context": "[TFTRT] Additional ConvertPool validation. Add additional validation for TRT failure cases for `ConvertPool` and `ConvertPool3D`, so that failing nodes will not be converted."
        },
        {
            "Timestamp": "2022-09-01T18:33:04Z",
            "Entity Ids": [
                86808158,
                48215717,
                35820639
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "0JUJN5XR0W76",
                "Z0XXLSP82Z2Z"
            ],
            "Context": "[TFTRT] Additional ConvertPool validation. Add additional validation for TRT failure cases for `ConvertPool` and `ConvertPool3D`, so that failing nodes will not be converted."
        },
        {
            "Timestamp": "2022-09-01T18:31:25Z",
            "EntityIds": [
                10923599,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "X650RZ31RMSX"
            ],
            "Context": "[TF-TRT] CUDA Lazy Loading Warning Filtered. Add an extra substring to filter CUDA Lazy Loading Warning Messages in TRT 8.5"
        },
        {
            "Timestamp": "2022-09-01T18:31:25Z",
            "Entity Ids": [
                10923599,
                48215717,
                35820639
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "X650RZ31RMSX",
                "1RZNGZKKWY9V"
            ],
            "Context": "[TF-TRT] CUDA Lazy Loading Warning Filtered. Add an extra substring to filter CUDA Lazy Loading Warning Messages in TRT 8.5"
        },
        {
            "Timestamp": "2022-09-01T18:16:28Z",
            "EntityIds": [
                323199
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "IPT4A7IVDDY2"
            ],
            "Context": "Fix build on r2.8. This is caused by bad merge conflict resolution, duplicate lines with old and new API were left in the code.\r\n\r\nSigned-off-by: Mihai Maruseac <mihaimaruseac@google.com>"
        },
        {
            "Timestamp": "2022-09-01T18:16:28Z",
            "Entity Ids": [
                323199
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "IPT4A7IVDDY2",
                "O8OUFI6EEYYQ"
            ],
            "Context": "Fix build on r2.8. This is caused by bad merge conflict resolution, duplicate lines with old and new API were left in the code.\r\n\r\nSigned-off-by: Mihai Maruseac <mihaimaruseac@google.com>"
        },
        {
            "Timestamp": "2022-09-01T18:07:46Z",
            "EntityIds": [
                80416898,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "E415XYMCSIMZ"
            ],
            "Context": "[TF-TRT]: Revert default dynamic shape strategy to Range. Revert \"Make default dynamic shape profile strategy to implicit batch compatible\"\r\n\r\nCurrently, the ImplicitBatchModeCompatible strategy creates profiles with the\r\nassumption that the first dim is always the batch dim. This does not necessarily\r\nhold for TRTEngineOps deeper in the graph, therefore we cannot simply override\r\ndim 0 for all the min values. We have a case where this leads to inconsistent\r\nprofiles and engine creation failure in certain BERT networks.\r\n\r\nThe Range profile strategy does not have this issue, so revert to using\r\nRange as the default.\r\n\r\nThis reverts commit 0737efbe374b2bc89134f153d54a45af6811592a.\r\n\r\ncc: @tfeher @bixia1 @DEKHTIARJonathan "
        },
        {
            "Timestamp": "2022-09-01T18:07:46Z",
            "Entity Ids": [
                80416898,
                48215717
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "E415XYMCSIMZ",
                "15R0FZHAPVGW"
            ],
            "Context": "[TF-TRT]: Revert default dynamic shape strategy to Range. Revert \"Make default dynamic shape profile strategy to implicit batch compatible\"\r\n\r\nCurrently, the ImplicitBatchModeCompatible strategy creates profiles with the\r\nassumption that the first dim is always the batch dim. This does not necessarily\r\nhold for TRTEngineOps deeper in the graph, therefore we cannot simply override\r\ndim 0 for all the min values. We have a case where this leads to inconsistent\r\nprofiles and engine creation failure in certain BERT networks.\r\n\r\nThe Range profile strategy does not have this issue, so revert to using\r\nRange as the default.\r\n\r\nThis reverts commit 0737efbe374b2bc89134f153d54a45af6811592a.\r\n\r\ncc: @tfeher @bixia1 @DEKHTIARJonathan "
        },
        {
            "Timestamp": "2022-09-01T18:04:58Z",
            "EntityIds": [
                86808158,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "JG9G739RJXS5"
            ],
            "Context": "[TFTRT] Check supported precisions before build. Checks the platform's supported precisions prior to building each engine. If the selected precision mode is not supported, terminate the program with a detailed message.\r\n\r\ncc: @DEKHTIARJonathan @meena-at-work"
        },
        {
            "Timestamp": "2022-09-01T18:04:58Z",
            "Entity Ids": [
                86808158,
                48215717,
                35820639
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "JG9G739RJXS5",
                "KON939NN3FIS"
            ],
            "Context": "[TFTRT] Check supported precisions before build. Checks the platform's supported precisions prior to building each engine. If the selected precision mode is not supported, terminate the program with a detailed message.\r\n\r\ncc: @DEKHTIARJonathan @meena-at-work"
        },
        {
            "Timestamp": "2022-09-01T18:04:34Z",
            "EntityIds": [
                323199
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "2Y37STLVMRXM"
            ],
            "Context": "Pin protobuf.. See https://github.com/tensorflow/tensorflow/releases/tag/v2.9.1\r\n\r\nSigned-off-by: Mihai Maruseac <mihaimaruseac@google.com>"
        },
        {
            "Timestamp": "2022-09-01T18:04:34Z",
            "Entity Ids": [
                323199
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "2Y37STLVMRXM",
                "RI42GRFSPX7D"
            ],
            "Context": "Pin protobuf.. See https://github.com/tensorflow/tensorflow/releases/tag/v2.9.1\r\n\r\nSigned-off-by: Mihai Maruseac <mihaimaruseac@google.com>"
        },
        {
            "Timestamp": "2022-09-01T16:53:07Z",
            "EntityIds": [
                32910461,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "XVOLX5IAC6EU"
            ],
            "Context": "Refactoring of the CombinedNMS converter.. Combining two pairs of converters and test procedures:\r\n```\r\nStatus ConvertCombinedNMS(const OpConverterParams* params)\r\nTEST_P(OpConverter_FP32_Test, ConvertCombinedNMS)\r\n```\r\nwhich were written, respectively, for\r\n```\r\n#if IS_TRT_VERSION_GE(8, 2, 1, 6) || defined(TF_TRT_USE_EFFICIENT_NMS_PLUGIN)\r\n....\r\n#elif IS_TRT_VERSION_GE(7, 1, 3, 0)\r\n```\r\nThe new code is almost 200 lines shorter, easier to maintain and to rewrite via  `OpConverterBase`.\r\n"
        },
        {
            "Timestamp": "2022-09-01T16:53:07Z",
            "Entity Ids": [
                32910461,
                48215717,
                35820639
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "XVOLX5IAC6EU",
                "SFIH2FLT0CC5"
            ],
            "Context": "Refactoring of the CombinedNMS converter.. Combining two pairs of converters and test procedures:\r\n```\r\nStatus ConvertCombinedNMS(const OpConverterParams* params)\r\nTEST_P(OpConverter_FP32_Test, ConvertCombinedNMS)\r\n```\r\nwhich were written, respectively, for\r\n```\r\n#if IS_TRT_VERSION_GE(8, 2, 1, 6) || defined(TF_TRT_USE_EFFICIENT_NMS_PLUGIN)\r\n....\r\n#elif IS_TRT_VERSION_GE(7, 1, 3, 0)\r\n```\r\nThe new code is almost 200 lines shorter, easier to maintain and to rewrite via  `OpConverterBase`.\r\n"
        },
        {
            "Timestamp": "2022-09-01T14:40:00Z",
            "EntityIds": [
                10442001,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "FYVU5PR5UZI4"
            ],
            "Context": "Prevent actions from running in forks. Forks of the main repo do not have the resources or\r\ncredentials for running the Actions, so bail when\r\nthat is attempted"
        },
        {
            "Timestamp": "2022-09-01T14:40:00Z",
            "Entity Ids": [
                10442001,
                48215717
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "FYVU5PR5UZI4",
                "SX8XKFJZQWEU"
            ],
            "Context": "Prevent actions from running in forks. Forks of the main repo do not have the resources or\r\ncredentials for running the Actions, so bail when\r\nthat is attempted"
        },
        {
            "Timestamp": "2022-09-01T14:20:31Z",
            "EntityIds": [
                107059430,
                81610181
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "0F87M8TV0HF5"
            ],
            "Context": "Unncessary semicolons in tutorials terminate statements, possible documentation improvement. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nDocumentation Bug\n\n### Source\n\nsource\n\n### Tensorflow Version\n\n2.9.1\n\n### Custom Code\n\nNo\n\n### OS Platform and Distribution\n\n_No response_\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n_No response_\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nThe documentation found at `https://www.tensorflow.org/guide/basics` under heading 'Training loops' as well as additional documentation on that tutorial/guide page have unnecessary semicolons (`;`) at end of statements, not necessary for Python syntactically. \r\n\r\nFor example, `plt.legend();` under 'Training loops' heading throws warning errors in certain IDEs with AI-assisted code review such as VSCode because of the superfluous `;`.\r\n\r\nI kindly recommend discontinuation of unnecessary semicolons and revision of this page to remove all that are not needed per proper syntax or convention. Kindly let me know if any more information is needed. Thank you for consideration.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nimport tensorflow as tf\r\nimport matplotlib\r\nfrom matplotlib import pyplot as plt\r\nmatplotlib.rcParams['figure-figsize'] = [9, 6]\r\n\r\nx = tf.linspace(-2, 2, 201)\r\nx = tf.cast(x, tf.float32)\r\n\r\ndef f(x):\r\n  y = x**2 + 2*x - 5\r\n  return y\r\n\r\ny = f(x) + tf.random.normal(shape=[201])\r\n\r\nplt.plot(x.numpy(), y.numpy(), '.', label='Data')\r\nplt.plot(x, f(x), label='Ground truth')\r\nplt.legend();\r\n\r\n_excerpted from: https://www.tensorflow.org/guide/basics_\n```\n\n\n### Relevant log output\n\n```shell\nn/a\n```\n</details>"
        },
        {
            "Timestamp": "2022-09-01T14:14:23Z",
            "EntityIds": [
                10442001,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "CXZKDAXAAEBL"
            ],
            "Context": "Fix compilation and linking of compiler/xla/runtime:custom_call_test. Failure was\r\n`ERROR: /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/compiler/xla/runtime/BUILD:45:11: Compiling tensorflow/compiler/xla/runtime/async_runtime.cc failed: undeclared inclusion(s) in rule '//tensorflow/compiler/xla/runtime:async_runtime':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/compiler/xla/runtime/async_runtime.cc':\r\n  'external/com_google_absl/absl/status/status.h'\r\n  'external/com_google_absl/absl/status/internal/status_internal.h'\r\nTarget //tensorflow/compiler/xla/runtime:custom_call_test failed to build\r\n`\r\nAfter fixing that it failed with\r\n`ERROR: /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/compiler/xla/runtime/BUILD:102:11: Linking tensorflow/compiler/xla/runtime/custom_call_test failed: (Exit 1): gcc failed: error executing command \r\n  (cd /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/local/lib64:/usr/local/lib \\\r\n    PATH=/home/builder/.cache/bazelisk/downloads/bazelbuild/bazel-5.3.0-linux-arm64/bin:/home/builder/1/tensorflow_build/venv_py38/bin:/home/builder/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/home/builder/1/tensorflow_build/venv_py38/bin/python3 \\\r\n    PYTHON_LIB_PATH=/home/builder/1/tensorflow_build/venv_py38/lib/python3.8/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n  /usr/local/bin/gcc @bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/runtime/custom_call_test-2.params)\r\n# Configuration: 6a157ea5430c4f8c0216a3c013aa8930b2449e788f4e52217225891817f5290a\r\n# Execution platform: @local_execution_config_platform//:platform\r\nbazel-out/aarch64-opt/bin/_solib_aarch64/libtensorflow_Scompiler_Sxla_Smlir_Stransforms_Sruntime_Slibjit_Ucompiler.so: error: undefined reference to 'LLVMInitializeAArch64AsmParser'\r\nbazel-out/aarch64-opt/bin/_solib_aarch64/libtensorflow_Scompiler_Sxla_Smlir_Stransforms_Sruntime_Slibjit_Ucompiler.so: error: undefined reference to 'LLVMInitializeAArch64AsmPrinter'\r\nbazel-out/aarch64-opt/bin/_solib_aarch64/libtensorflow_Scompiler_Sxla_Smlir_Stransforms_Sruntime_Slibjit_Ucompiler.so: error: undefined reference to 'LLVMInitializeAArch64TargetMC'\r\nbazel-out/aarch64-opt/bin/_solib_aarch64/libtensorflow_Scompiler_Sxla_Smlir_Stransforms_Sruntime_Slibjit_Ucompiler.so: error: undefined reference to 'LLVMInitializeAArch64Target'\r\nbazel-out/aarch64-opt/bin/_solib_aarch64/libtensorflow_Scompiler_Sxla_Smlir_Stransforms_Sruntime_Slibjit_Ucompiler.so: error: undefined reference to 'LLVMInitializeAArch64TargetInfo'\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/compiler/xla/runtime:custom_call_test failed to build\r\n`"
        },
        {
            "Timestamp": "2022-09-01T14:14:23Z",
            "Entity Ids": [
                10442001,
                48215717,
                1835471
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "CXZKDAXAAEBL",
                "SOPN39FSZQMX"
            ],
            "Context": "Fix compilation and linking of compiler/xla/runtime:custom_call_test. Failure was\r\n`ERROR: /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/compiler/xla/runtime/BUILD:45:11: Compiling tensorflow/compiler/xla/runtime/async_runtime.cc failed: undeclared inclusion(s) in rule '//tensorflow/compiler/xla/runtime:async_runtime':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/compiler/xla/runtime/async_runtime.cc':\r\n  'external/com_google_absl/absl/status/status.h'\r\n  'external/com_google_absl/absl/status/internal/status_internal.h'\r\nTarget //tensorflow/compiler/xla/runtime:custom_call_test failed to build\r\n`\r\nAfter fixing that it failed with\r\n`ERROR: /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/compiler/xla/runtime/BUILD:102:11: Linking tensorflow/compiler/xla/runtime/custom_call_test failed: (Exit 1): gcc failed: error executing command \r\n  (cd /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/local/lib64:/usr/local/lib \\\r\n    PATH=/home/builder/.cache/bazelisk/downloads/bazelbuild/bazel-5.3.0-linux-arm64/bin:/home/builder/1/tensorflow_build/venv_py38/bin:/home/builder/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/home/builder/1/tensorflow_build/venv_py38/bin/python3 \\\r\n    PYTHON_LIB_PATH=/home/builder/1/tensorflow_build/venv_py38/lib/python3.8/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n  /usr/local/bin/gcc @bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/runtime/custom_call_test-2.params)\r\n# Configuration: 6a157ea5430c4f8c0216a3c013aa8930b2449e788f4e52217225891817f5290a\r\n# Execution platform: @local_execution_config_platform//:platform\r\nbazel-out/aarch64-opt/bin/_solib_aarch64/libtensorflow_Scompiler_Sxla_Smlir_Stransforms_Sruntime_Slibjit_Ucompiler.so: error: undefined reference to 'LLVMInitializeAArch64AsmParser'\r\nbazel-out/aarch64-opt/bin/_solib_aarch64/libtensorflow_Scompiler_Sxla_Smlir_Stransforms_Sruntime_Slibjit_Ucompiler.so: error: undefined reference to 'LLVMInitializeAArch64AsmPrinter'\r\nbazel-out/aarch64-opt/bin/_solib_aarch64/libtensorflow_Scompiler_Sxla_Smlir_Stransforms_Sruntime_Slibjit_Ucompiler.so: error: undefined reference to 'LLVMInitializeAArch64TargetMC'\r\nbazel-out/aarch64-opt/bin/_solib_aarch64/libtensorflow_Scompiler_Sxla_Smlir_Stransforms_Sruntime_Slibjit_Ucompiler.so: error: undefined reference to 'LLVMInitializeAArch64Target'\r\nbazel-out/aarch64-opt/bin/_solib_aarch64/libtensorflow_Scompiler_Sxla_Smlir_Stransforms_Sruntime_Slibjit_Ucompiler.so: error: undefined reference to 'LLVMInitializeAArch64TargetInfo'\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/compiler/xla/runtime:custom_call_test failed to build\r\n`"
        },
        {
            "Timestamp": "2022-09-01T12:40:38Z",
            "EntityIds": [
                13285808,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "BQZ0939DQU26"
            ],
            "Context": "Update Embedded Linux toolchains to GCC 11.3.1. This PR upgrades the [Embedded Linux toolchains](https://github.com/tensorflow/tensorflow/blob/4cfeb0e3eb6027f95a3be624041c7331dee98911/.bazelrc#L81-L84) from the discontinued ARM GCC 8.3 toolchain to the latest [GCC 11.3.1 based release](https://developer.arm.com/downloads/-/arm-gnu-toolchain-downloads).\r\n\r\nThis PR fixes #57364 which would be great to back-port to the 2.10 release candidates as well.\r\n\r\n/cc @sachinprasadhs @arfaian"
        },
        {
            "Timestamp": "2022-09-01T12:40:38Z",
            "Entity Ids": [
                13285808,
                48215717,
                1106365
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "BQZ0939DQU26",
                "R3A1YBJ3X3ST"
            ],
            "Context": "Update Embedded Linux toolchains to GCC 11.3.1. This PR upgrades the [Embedded Linux toolchains](https://github.com/tensorflow/tensorflow/blob/4cfeb0e3eb6027f95a3be624041c7331dee98911/.bazelrc#L81-L84) from the discontinued ARM GCC 8.3 toolchain to the latest [GCC 11.3.1 based release](https://developer.arm.com/downloads/-/arm-gnu-toolchain-downloads).\r\n\r\nThis PR fixes #57364 which would be great to back-port to the 2.10 release candidates as well.\r\n\r\n/cc @sachinprasadhs @arfaian"
        },
        {
            "Timestamp": "2022-09-01T12:26:25Z",
            "EntityIds": [
                27568333,
                86464649
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "2TLLEPC0PW9G"
            ],
            "Context": "Can't build project with included TensorFlow Lite in Play Services (vision task). Gradle version: 7.3.3\r\nFull code: https://github.com/vladd11/ar-shop/\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nI include TensorFlow Lite in Play Services dependency:\r\n\r\n```\r\ndependencies {\r\n    ...\r\n    implementation 'org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03'\r\n}\r\n```\r\n\r\nWhen syncing, Gradle gives me these warnings:\r\n```\r\nFailed to resolve: org.tensorflow:tensorflow-lite-api:0.0.0-nightly-20220719.054020-244\r\nFailed to resolve: org.tensorflow:tensorflow-lite-support-api:0.0.0-nightly-20220719.045912-252\r\nFailed to resolve: org.tensorflow:tensorflow-lite-task-base:0.0.0-nightly-20220719.045922-401\r\n```\r\n\r\nWhen I build project, I have this error:\r\n```\r\nExecuting tasks: [:app:assembleDebug] in project /home/vladislav/AndroidStudioProjects/ARshop\r\n\r\n> Task :app:preBuild UP-TO-DATE\r\n> Task :app:preDebugBuild UP-TO-DATE\r\n> Task :app:mergeDebugNativeDebugMetadata NO-SOURCE\r\n> Task :app:compileDebugAidl NO-SOURCE\r\n> Task :app:compileDebugRenderscript NO-SOURCE\r\n> Task :app:generateDebugBuildConfig UP-TO-DATE\r\n> Task :app:generateSafeArgsDebug UP-TO-DATE\r\n> Task :app:checkDebugAarMetadata FAILED\r\n> Task :app:generateDebugResValues UP-TO-DATE\r\n> Task :app:generateDebugResources UP-TO-DATE\r\n> Task :app:mergeDebugResources FAILED\r\n> Task :app:packageDebugResources UP-TO-DATE\r\n> Task :app:parseDebugLocalResources UP-TO-DATE\r\n> Task :app:createDebugCompatibleScreenManifests UP-TO-DATE\r\n> Task :app:extractDeepLinksDebug UP-TO-DATE\r\n> Task :app:processDebugMainManifest FAILED\r\n> Task :app:javaPreCompileDebug UP-TO-DATE\r\n> Task :app:mergeDebugShaders UP-TO-DATE\r\n> Task :app:compileDebugShaders NO-SOURCE\r\n> Task :app:generateDebugAssets UP-TO-DATE\r\n> Task :app:mergeDebugAssets FAILED\r\n> Task :app:processDebugJavaRes NO-SOURCE\r\n> Task :app:checkDebugDuplicateClasses FAILED\r\n> Task :app:desugarDebugFileDependencies FAILED\r\n> Task :app:extractNativeLibraries\r\n> Task :app:configureCMakeDebug[arm64-v8a]\r\n> Task :app:buildCMakeDebug[arm64-v8a]\r\n> Task :app:configureCMakeDebug[armeabi-v7a]\r\n> Task :app:buildCMakeDebug[armeabi-v7a]\r\n> Task :app:configureCMakeDebug[x86]\r\n> Task :app:buildCMakeDebug[x86]\r\n> Task :app:externalNativeBuildDebug\r\n> Task :app:mergeDebugJniLibFolders UP-TO-DATE\r\n> Task :app:mergeDebugNativeLibs FAILED\r\n> Task :app:validateSigningDebug UP-TO-DATE\r\n> Task :app:writeDebugAppMetadata UP-TO-DATE\r\n> Task :app:writeDebugSigningConfigVersions UP-TO-DATE\r\n\r\nFAILURE: Build completed with 7 failures.\r\n\r\n1: Task failed with an exception.\r\n-----------\r\n* What went wrong:\r\nExecution failed for task ':app:checkDebugAarMetadata'.\r\n> Could not resolve all files for configuration ':app:debugRuntimeClasspath'.\r\n   > Could not find org.tensorflow:tensorflow-lite-api:0.0.0-nightly-20220719.054020-244.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-api-0.0.0-nightly-20220719.054020-244.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-api-0.0.0-nightly-20220719.054020-244.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03 > com.google.android.gms:play-services-tflite-support:16.0.0-beta03 > com.google.android.gms:play-services-tflite-java:16.0.0-beta03\r\n   > Could not find org.tensorflow:tensorflow-lite-support-api:0.0.0-nightly-20220719.045912-252.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-support-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-support-api-0.0.0-nightly-20220719.045912-252.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-support-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-support-api-0.0.0-nightly-20220719.045912-252.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03 > com.google.android.gms:play-services-tflite-support:16.0.0-beta03\r\n   > Could not find org.tensorflow:tensorflow-lite-task-base:0.0.0-nightly-20220719.045922-401.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-task-base/0.0.0-nightly-SNAPSHOT/tensorflow-lite-task-base-0.0.0-nightly-20220719.045922-401.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-task-base/0.0.0-nightly-SNAPSHOT/tensorflow-lite-task-base-0.0.0-nightly-20220719.045922-401.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n\r\n* Try:\r\n> Run with --stacktrace option to get the stack trace.\r\n> Run with --info or --debug option to get more log output.\r\n> Run with --scan to get full insights.\r\n==============================================================================\r\n\r\n2: Task failed with an exception.\r\n-----------\r\n* What went wrong:\r\nExecution failed for task ':app:mergeDebugResources'.\r\n> Could not resolve all files for configuration ':app:debugRuntimeClasspath'.\r\n   > Could not find org.tensorflow:tensorflow-lite-api:0.0.0-nightly-20220719.054020-244.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-api-0.0.0-nightly-20220719.054020-244.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-api-0.0.0-nightly-20220719.054020-244.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03 > com.google.android.gms:play-services-tflite-support:16.0.0-beta03 > com.google.android.gms:play-services-tflite-java:16.0.0-beta03\r\n   > Could not find org.tensorflow:tensorflow-lite-support-api:0.0.0-nightly-20220719.045912-252.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-support-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-support-api-0.0.0-nightly-20220719.045912-252.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-support-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-support-api-0.0.0-nightly-20220719.045912-252.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03 > com.google.android.gms:play-services-tflite-support:16.0.0-beta03\r\n   > Could not find org.tensorflow:tensorflow-lite-task-base:0.0.0-nightly-20220719.045922-401.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-task-base/0.0.0-nightly-SNAPSHOT/tensorflow-lite-task-base-0.0.0-nightly-20220719.045922-401.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-task-base/0.0.0-nightly-SNAPSHOT/tensorflow-lite-task-base-0.0.0-nightly-20220719.045922-401.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n\r\n* Try:\r\n> Run with --stacktrace option to get the stack trace.\r\n> Run with --info or --debug option to get more log output.\r\n> Run with --scan to get full insights.\r\n==============================================================================\r\n\r\n3: Task failed with an exception.\r\n-----------\r\n* What went wrong:\r\nExecution failed for task ':app:processDebugMainManifest'.\r\n> Could not resolve all files for configuration ':app:debugRuntimeClasspath'.\r\n   > Could not find org.tensorflow:tensorflow-lite-api:0.0.0-nightly-20220719.054020-244.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-api-0.0.0-nightly-20220719.054020-244.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-api-0.0.0-nightly-20220719.054020-244.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03 > com.google.android.gms:play-services-tflite-support:16.0.0-beta03 > com.google.android.gms:play-services-tflite-java:16.0.0-beta03\r\n   > Could not find org.tensorflow:tensorflow-lite-support-api:0.0.0-nightly-20220719.045912-252.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-support-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-support-api-0.0.0-nightly-20220719.045912-252.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-support-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-support-api-0.0.0-nightly-20220719.045912-252.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03 > com.google.android.gms:play-services-tflite-support:16.0.0-beta03\r\n   > Could not find org.tensorflow:tensorflow-lite-task-base:0.0.0-nightly-20220719.045922-401.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-task-base/0.0.0-nightly-SNAPSHOT/tensorflow-lite-task-base-0.0.0-nightly-20220719.045922-401.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-task-base/0.0.0-nightly-SNAPSHOT/tensorflow-lite-task-base-0.0.0-nightly-20220719.045922-401.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n\r\n* Try:\r\n> Run with --stacktrace option to get the stack trace.\r\n> Run with --info or --debug option to get more log output.\r\n> Run with --scan to get full insights.\r\n==============================================================================\r\n\r\n4: Task failed with an exception.\r\n-----------\r\n* What went wrong:\r\nExecution failed for task ':app:mergeDebugAssets'.\r\n> Could not resolve all files for configuration ':app:debugRuntimeClasspath'.\r\n   > Could not find org.tensorflow:tensorflow-lite-api:0.0.0-nightly-20220719.054020-244.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-api-0.0.0-nightly-20220719.054020-244.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-api-0.0.0-nightly-20220719.054020-244.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03 > com.google.android.gms:play-services-tflite-support:16.0.0-beta03 > com.google.android.gms:play-services-tflite-java:16.0.0-beta03\r\n   > Could not find org.tensorflow:tensorflow-lite-support-api:0.0.0-nightly-20220719.045912-252.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-support-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-support-api-0.0.0-nightly-20220719.045912-252.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-support-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-support-api-0.0.0-nightly-20220719.045912-252.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03 > com.google.android.gms:play-services-tflite-support:16.0.0-beta03\r\n   > Could not find org.tensorflow:tensorflow-lite-task-base:0.0.0-nightly-20220719.045922-401.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-task-base/0.0.0-nightly-SNAPSHOT/tensorflow-lite-task-base-0.0.0-nightly-20220719.045922-401.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-task-base/0.0.0-nightly-SNAPSHOT/tensorflow-lite-task-base-0.0.0-nightly-20220719.045922-401.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n\r\n* Try:\r\n> Run with --stacktrace option to get the stack trace.\r\n> Run with --info or --debug option to get more log output.\r\n> Run with --scan to get full insights.\r\n==============================================================================\r\n\r\n5: Task failed with an exception.\r\n-----------\r\n* What went wrong:\r\nExecution failed for task ':app:checkDebugDuplicateClasses'.\r\n> Could not resolve all files for configuration ':app:debugRuntimeClasspath'.\r\n   > Could not find org.tensorflow:tensorflow-lite-api:0.0.0-nightly-20220719.054020-244.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-api-0.0.0-nightly-20220719.054020-244.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-api-0.0.0-nightly-20220719.054020-244.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03 > com.google.android.gms:play-services-tflite-support:16.0.0-beta03 > com.google.android.gms:play-services-tflite-java:16.0.0-beta03\r\n   > Could not find org.tensorflow:tensorflow-lite-support-api:0.0.0-nightly-20220719.045912-252.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-support-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-support-api-0.0.0-nightly-20220719.045912-252.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-support-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-support-api-0.0.0-nightly-20220719.045912-252.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03 > com.google.android.gms:play-services-tflite-support:16.0.0-beta03\r\n   > Could not find org.tensorflow:tensorflow-lite-task-base:0.0.0-nightly-20220719.045922-401.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-task-base/0.0.0-nightly-SNAPSHOT/tensorflow-lite-task-base-0.0.0-nightly-20220719.045922-401.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-task-base/0.0.0-nightly-SNAPSHOT/tensorflow-lite-task-base-0.0.0-nightly-20220719.045922-401.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n\r\n* Try:\r\n> Run with --stacktrace option to get the stack trace.\r\n> Run with --info or --debug option to get more log output.\r\n> Run with --scan to get full insights.\r\n==============================================================================\r\n\r\n6: Task failed with an exception.\r\n-----------\r\n* What went wrong:\r\nExecution failed for task ':app:desugarDebugFileDependencies'.\r\n> Could not resolve all files for configuration ':app:debugRuntimeClasspath'.\r\n   > Could not find org.tensorflow:tensorflow-lite-api:0.0.0-nightly-20220719.054020-244.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-api-0.0.0-nightly-20220719.054020-244.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-api-0.0.0-nightly-20220719.054020-244.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03 > com.google.android.gms:play-services-tflite-support:16.0.0-beta03 > com.google.android.gms:play-services-tflite-java:16.0.0-beta03\r\n   > Could not find org.tensorflow:tensorflow-lite-support-api:0.0.0-nightly-20220719.045912-252.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-support-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-support-api-0.0.0-nightly-20220719.045912-252.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-support-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-support-api-0.0.0-nightly-20220719.045912-252.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03 > com.google.android.gms:play-services-tflite-support:16.0.0-beta03\r\n   > Could not find org.tensorflow:tensorflow-lite-task-base:0.0.0-nightly-20220719.045922-401.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-task-base/0.0.0-nightly-SNAPSHOT/tensorflow-lite-task-base-0.0.0-nightly-20220719.045922-401.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-task-base/0.0.0-nightly-SNAPSHOT/tensorflow-lite-task-base-0.0.0-nightly-20220719.045922-401.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n\r\n* Try:\r\n> Run with --stacktrace option to get the stack trace.\r\n> Run with --info or --debug option to get more log output.\r\n> Run with --scan to get full insights.\r\n==============================================================================\r\n\r\n7: Task failed with an exception.\r\n-----------\r\n* What went wrong:\r\nExecution failed for task ':app:mergeDebugNativeLibs'.\r\n> Could not resolve all files for configuration ':app:debugRuntimeClasspath'.\r\n   > Could not find org.tensorflow:tensorflow-lite-api:0.0.0-nightly-20220719.054020-244.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-api-0.0.0-nightly-20220719.054020-244.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-api-0.0.0-nightly-20220719.054020-244.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03 > com.google.android.gms:play-services-tflite-support:16.0.0-beta03 > com.google.android.gms:play-services-tflite-java:16.0.0-beta03\r\n   > Could not find org.tensorflow:tensorflow-lite-support-api:0.0.0-nightly-20220719.045912-252.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-support-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-support-api-0.0.0-nightly-20220719.045912-252.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-support-api/0.0.0-nightly-SNAPSHOT/tensorflow-lite-support-api-0.0.0-nightly-20220719.045912-252.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03 > com.google.android.gms:play-services-tflite-support:16.0.0-beta03\r\n   > Could not find org.tensorflow:tensorflow-lite-task-base:0.0.0-nightly-20220719.045922-401.\r\n     Searched in the following locations:\r\n       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-task-base/0.0.0-nightly-SNAPSHOT/tensorflow-lite-task-base-0.0.0-nightly-20220719.045922-401.pom\r\n       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-task-base/0.0.0-nightly-SNAPSHOT/tensorflow-lite-task-base-0.0.0-nightly-20220719.045922-401.pom\r\n     Required by:\r\n         project :app > org.tensorflow:tensorflow-lite-task-vision-play-services:0.4.2-beta03\r\n\r\n* Try:\r\n> Run with --stacktrace option to get the stack trace.\r\n> Run with --info or --debug option to get more log output.\r\n> Run with --scan to get full insights.\r\n==============================================================================\r\n\r\n* Get more help at https://help.gradle.org\r\n\r\nBUILD FAILED in 6s\r\n28 actionable tasks: 15 executed, 13 up-to-date\r\n```"
        },
        {
            "Timestamp": "2022-09-01T09:42:05Z",
            "EntityIds": [
                50069574,
                84765720
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "BOORL3OORR2M"
            ],
            "Context": "Tensorflow customized embedding not work on GPU. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nbinary\n\n### Tensorflow Version\n\nv2.3.0-rc2-23-gb36436b087 2.3.0\n\n### Custom Code\n\nNo\n\n### OS Platform and Distribution\n\nUbuntu 17.04\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n3.7\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n10.1 / 7.6.5\n\n### GPU model and memory\n\nTesla-V100 32G\n\n### Current Behaviour?\n\n```shell\nI made a tensorflow model like following:\r\n\r\nclass EnhancedEmbedding(tf.keras.layers.Embedding):\r\n    def __init__(self, input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None, **kwargs):\r\n        super().__init__(input_dim, output_dim, embeddings_initializer, embeddings_regularizer, activity_regularizer, embeddings_constraint, mask_zero, input_length, **kwargs)\r\n        self.five=tf.constant(0.5)\r\n        self.zero=tf.constant(0)\r\n    \r\n    def embedding(self,inputs):\r\n        return super().call(inputs)\r\n    \r\n    def map_2(self,tokens):\r\n        identifier=self.embedding(tokens[0])\r\n        cur_word=self.embedding(tokens[2])\r\n        return tf.cond(tf.equal(tf.shape(tokens[0]),self.zero),\r\n                lambda: tf.squeeze(cur_word),\r\n                lambda: tf.squeeze(tf.reduce_mean(identifier)*self.five+cur_word*self.five))\r\n\r\n\r\n    def map_1(self,inputs):\r\n        return tf.map_fn(fn=lambda x :self.map_2(x),elems=inputs,dtype=tf.float32)\r\n\r\n    def call(self, inputs):\r\n        final_embeddings=tf.map_fn(fn=lambda x:self.map_1(x),elems=inputs,dtype=tf.float32)\r\n\r\n        return final_embeddings\r\n```\r\n```\r\nclass EnhancedModel(Model):\r\n    def __init__(self,  embedding_dim, hidden_dim, vocab_size, label_size,seq_len, pretrained_weight):\r\n        super().__init__()\r\n        self.hidden_dim = hidden_dim\r\n        self.vocab_size = vocab_size\r\n        self.embedding_dim = embedding_dim\r\n        self.label_size = label_size\r\n        self.activation = tf.keras.activations.tanh\r\n        self.num_layers = 1\r\n\r\n        self.embedding=EnhancedEmbedding(vocab_size,embedding_dim,embeddings_initializer=keras.initializers.Constant(pretrained_weight))\r\n        self.encoder = Bidirectional(LSTM(hidden_dim, return_sequences=True,input_shape=(seq_len,embedding_dim)))\r\n        self.pool=MaxPool1D(hidden_dim*2)\r\n        self.decoder = Dense(self.label_size)\r\n\r\n    def call(self, inputs):\r\n        embeddings = self.embedding(inputs)\r\n        embeddings=tf.reshape(embeddings,[-1,400,32])\r\n        lstm_out = self.encoder(embeddings)\r\n        lstm_out = tf.transpose(lstm_out, perm=[0,2,1])\r\n        pool_out=self.pool(lstm_out)\r\n        out = tf.squeeze(pool_out,[1])\r\n        out = self.decoder(out)\r\n        return out\r\n```\r\nActually it is a model that cited from others. I only changed the embedding layer and the input.\r\nthe input is a RaggedTensor with shape(batch_size,400,3,None), and i use ``` and ```map_2``` function in ```EnhancedEmbedding``` to general final embedding for the following layers. Everything works fine except that the model is not work with GPU. I looked the GPU utilization using ```nvidia-smi``` and the result is about 5%. But CPU-Util is about 100%.\r\n\r\nGPU can be used in the virtual env:\r\n```\r\n>>>tf.test.is_gpu_available()\r\n>>>True\r\n```\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nthe training code is here but it cannot be reproduced since the pretrained vectors, the training data are too large.\r\n\r\nhttps://colab.research.google.com/drive/1qdo629GsnIdgbFpqTbIrwOaIHCsfwyJr?usp=sharing\n```\n\n\n### Relevant log output\n\n_No response_</details>"
        },
        {
            "Timestamp": "2022-09-01T09:31:52Z",
            "EntityIds": [
                67035463,
                81610181
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "9KZVCLT4JKA1"
            ],
            "Context": "Memory allocation. Hi sorry for bothering. I am just wondering when using multiple streams for model inference. Will the cached memory blocks been shared by different streams? Or they are not shared like in pytorch?\r\n"
        },
        {
            "Timestamp": "2022-09-01T09:14:20Z",
            "EntityIds": [
                75348594,
                84765720
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "3EBU6Y84KT7S"
            ],
            "Context": "the edtion of TensorRT for TF-TRT. <img width=\"936\" alt=\"image\" src=\"https://user-images.githubusercontent.com/75348594/187877984-f321d97a-92a1-4953-a0fa-703626c106a4.png\">\r\nOn the website, I can know the edtion of cuda and cudnn, but how can I know the edtion of TensorRT?"
        },
        {
            "Timestamp": "2022-09-01T05:59:50Z",
            "EntityIds": [
                71369657,
                73069040
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "V20JLGVM8LGA"
            ],
            "Context": "Pose estimation line mismatch. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nsource\n\n### Tensorflow Version\n\n pod 'TensorFlowLiteSwift', '~> 0.0.1-nightly', :subspecs => ['CoreML', 'Metal']\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\nMacOS\n\n### Mobile device\n\niPhone X\n\n### Python version\n\n_No response_\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nWhen I am performing some exercise pose estimation model lines display cross.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nWhen I am performing Squat sometimes lines display cross.\n```\n\n\n### Relevant log output\n\n_No response_</details>"
        },
        {
            "Timestamp": "2022-09-01T05:49:49Z",
            "EntityIds": [
                108649012,
                81610181
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "R0L3TLYR2WD1"
            ],
            "Context": "tf.linalg.solve produces incorrect output when compiled using XLA. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nbinary\n\n### Tensorflow Version\n\n2.9.1\n\n### Custom Code\n\nNo\n\n### OS Platform and Distribution\n\nLinux Ubuntu 20.04.4 LTS\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n3.8.10\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\ntf.linalg.solve when compiled with XLA produces different (incorrect) output when compared to a standalone TF execution.\r\n\r\nIn the sample code below, the solveEquation function solves for Ax = B and returns Ax. This function is run with and without XLA enabled. Both executions produce very different outputs!\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndata_type = tf.float32\r\n\r\ndef solveEquation(A, B):\r\n\r\n    ATA = tf.matmul(A, A, transpose_a=True)\r\n    ATB = tf.matmul(A, B, transpose_a=True)\r\n\r\n    output = tf.linalg.solve(ATA, ATB)\r\n\r\n    return (tf.matmul(A, output))\r\n\r\nP = 2\r\nQ = 3\r\nR = 5\r\n\r\nnp.random.seed(0)\r\nmat1 = tf.constant(np.random.random((P, Q)), dtype=data_type)\r\nmat2 = tf.constant(np.random.random((P, R)), dtype=data_type)\r\n\r\noutput_standard = solveEquation(mat1, mat2)\r\n\r\ntf_func_xla = tf.function(func=solveEquation, \r\n                          input_signature=[tf.TensorSpec(shape=(P,Q),dtype=data_type),\r\n                                           tf.TensorSpec(shape=(P,R),dtype=data_type)], \r\n                          jit_compile=True)\r\noutput_xla = tf_func_xla(mat1, mat2)\r\n\r\ntf.print(output_standard)\r\ntf.print(output_xla)\n```\n\n\n### Relevant log output\n\n```shell\n# output with XLA disabled\r\n[[0.43758738 0.891772866 0.963661969 0.383441627 0.791725397]\r\n [0.528894722 0.568044662 0.92559737 0.0710358918 0.0871287584]]\r\n\r\n# output with XLA enabled\r\n[[0.274795085 0.876262307 0.82626003 0.345206 0.581315041]\r\n [0.3589876 0.553595543 0.778286219 0.0325973332 -0.126585901]]\n```\n</details>"
        },
        {
            "Timestamp": "2022-09-01T05:19:53Z",
            "EntityIds": [
                86464649,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "NNV8KJIUA4U2"
            ],
            "Context": "Updated Documentation on CoreML delegate. Updated Documentation on CoreML delegate as mentioned in #57565"
        },
        {
            "Timestamp": "2022-09-01T05:19:53Z",
            "Entity Ids": [
                86464649,
                48215717,
                2908505
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "NNV8KJIUA4U2",
                "EKSZBSFR7SJB"
            ],
            "Context": "Updated Documentation on CoreML delegate. Updated Documentation on CoreML delegate as mentioned in #57565"
        },
        {
            "Timestamp": "2022-09-01T02:53:28Z",
            "EntityIds": [
                106367904
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "F8TC6AODITXQ"
            ],
            "Context": "Fix the build. Fix the build"
        },
        {
            "Timestamp": "2022-09-01T02:53:28Z",
            "Entity Ids": [
                106367904,
                323199
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "F8TC6AODITXQ",
                "KKCJSMDJ7BJM"
            ],
            "Context": "Fix the build. Fix the build"
        },
        {
            "Timestamp": "2022-09-01T02:34:50Z",
            "EntityIds": [
                106367904
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "Z9NIHLJXT0SC"
            ],
            "Context": "Fix the build. Fix the build"
        },
        {
            "Timestamp": "2022-09-01T02:34:50Z",
            "Entity Ids": [
                106367904,
                323199
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "Z9NIHLJXT0SC",
                "Q30V9T0BU5JR"
            ],
            "Context": "Fix the build. Fix the build"
        },
        {
            "Timestamp": "2022-09-01T00:46:08Z",
            "EntityIds": [
                7644676,
                84765720
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "PZK65EB1YANT"
            ],
            "Context": "Make tf.image.resize gradient computation compatible with XLA compilation.  ### Issue Type\r\n\r\nFeature Request\r\n\r\n### Source\r\n\r\nbinary\r\n\r\n### Tensorflow Version\r\n\r\ntf 2.11.0-dev20220831\r\n\r\n### Custom Code\r\n\r\nNo\r\n\r\n### Current Behaviour?\r\n\r\nCurrently, XLA compilation does not work for gradient computation of `tf.image.resize`, for example for the default method `ResizeMethod.BILINEAR`:\r\n\r\n> ResizeBilinearGrad with align_corners=False or half_pixel_centers=True is not yet implemented\r\n\r\nSupport for forward pass has recently been added: https://github.com/tensorflow/tensorflow/issues/46447\r\n\r\nThis makes it impossible to XLA compile models for training that use resizing, such as RetinaNet.\r\n\r\n\r\n### Standalone code to reproduce the issue\r\n\r\n[Colab to reproduce error](https://colab.research.google.com/drive/1eevpjtJYqQ7Mkg7PujJu_I5UOfL1PnWX?usp=sharing)\r\n"
        },
        {
            "Timestamp": "2022-09-01T00:18:05Z",
            "EntityIds": [
                241317,
                84765720
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "XP4E1YHZ0JMD"
            ],
            "Context": "Cannot deserialize keras model using __add__. <details><summary>Click to expand!</summary> \r\n \r\n ### Issue Type\r\n\r\nBug\r\n\r\n### Source\r\n\r\nsource\r\n\r\n### Tensorflow Version\r\n\r\nv2.9.1-0-gd8ce9f9c301 2.9.1\r\n\r\n### Custom Code\r\n\r\nNo\r\n\r\n### OS Platform and Distribution\r\n\r\nUbuntu 20.04\r\n\r\n### Mobile device\r\n\r\n_No response_\r\n\r\n### Python version\r\n\r\n3.9.13\r\n\r\n### Bazel version\r\n\r\n5.0.0\r\n\r\n### GCC/Compiler version\r\n\r\nGCC 9.2\r\n\r\n### CUDA/cuDNN version\r\n\r\n11.7/8.4.1.50\r\n\r\n### GPU model and memory\r\n\r\nA100-SXM4-40GB\r\n\r\n### Current Behaviour?\r\n\r\nWhen calling `tf.keras.models.load_model(\"/tmp/my_model\")` I get\r\n\r\n```\r\nFile \"/mnt/disks/data/src/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 1078, in op_dispatch_handler\r\n    result = api_dispatcher.Dispatch(args, kwargs)\r\nTypeError: Missing required positional argument\r\n```\r\n\r\nI expected the model to load successfully. I trained my model for 2 days and now I can't load it.\r\n\r\n\r\n### Standalone code to reproduce the issue\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Dense, Layer\r\n\r\nclass MyLayer(Layer):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.dense = Dense(512)\r\n    def __call__(self, X):\r\n        short = X\r\n        X = self.dense(X)\r\n        X = short + X\r\n        return X\r\n\r\n\r\ndef main():\r\n    model = tf.keras.Sequential([MyLayer()])\r\n    model.build([None, 512])\r\n    model.save(\"/tmp/my_model\")\r\n\r\n    tf.keras.models.load_model(\"/tmp/my_model\")\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\n\r\n### Relevant log output\r\n\r\n```shell\r\napi_dispatcher.Dispatch=<bound method PyCapsule.Dispatch of <Dispatch(_add_dispatch): >, args=(<tf.Tensor 'Placeholder:0' shape=(None, 512) dtype=float32>,), kwargs={}\r\nTraceback (most recent call last):\r\n  File \"/mnt/disks/data/src/repro.py\", line 24, in <module>\r\n    main()\r\n  File \"/mnt/disks/data/src/repro.py\", line 21, in main\r\n    tf.keras.models.load_model(\"/tmp/my_model\")\r\n  File \"/mnt/disks/data/src/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File \"/mnt/disks/data/src/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 1078, in op_dispatch_handler\r\n    result = api_dispatcher.Dispatch(args, kwargs)\r\nTypeError: Missing required positional argument\r\n```\r\n</details>"
        },
        {
            "Timestamp": "2022-08-31T22:04:15Z",
            "EntityIds": [
                16668746,
                84765720
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "RAJIP5E0M7YN"
            ],
            "Context": "Tried to export a function which references 'untracked' resource Tensor. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nsource\n\n### Tensorflow Version\n\n2.8.2\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\nColab\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n3.7\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nI am not able to export models with a custom signature that contains preprocessing layers as part of the model graph.\r\n\r\nThis issue happens for different kinds of layers, in my case it was `Normalization`, `IntegerLookup` and `StringLookup`.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nLink for colab: https://colab.research.google.com/drive/15pPBp8uVBMpdHscljUz1kk_OylDp43-G?usp=sharing\r\n\r\n\r\ndef model_fn():\r\n    age_input = L.Input(shape=(1,), dtype=tf.float32, name='age')\r\n    sex_input = L.Input(shape=(1,), dtype=tf.float32, name='sex')\r\n    cp_input = L.Input(shape=(len(cp_vocab),), dtype=tf.float32, name='cp')\r\n    thal_input = L.Input(shape=(len(thal_vocab),), dtype=tf.float32, name='thal')\r\n\r\n    concat_inputs = L.Concatenate()([age_input, sex_input, cp_input, thal_input])\r\n    x = L.Dense(32, activation=\"relu\")(concat_inputs)\r\n    x = L.Dropout(0.5)(x)\r\n    output = L.Dense(1, activation=\"sigmoid\")(x)\r\n\r\n    return tf.keras.models.Model(inputs=[age_input, sex_input, cp_input, thal_input], outputs=output)\r\n\r\nmodel = model_fn()\r\n\r\ndef custom_signature(model):\r\n    input_signature = [\r\n        tf.TensorSpec([1,], tf.int64, name=\"age\"), \r\n        tf.TensorSpec([1,], tf.int64, name=\"sex\"), \r\n        tf.TensorSpec([1,], tf.int64, name=\"cp\"), \r\n        tf.TensorSpec([1,], tf.string, name=\"thal\")\r\n    ]\r\n    @tf.function(input_signature=[input_signature])\r\n    def serving_fn(input):\r\n        age_processed = age_preprocessing(input[0])\r\n        sex_processed = tf.cast(sex_preprocessing(input[1]), \r\n                                dtype=tf.float32)\r\n        cp_processed = cp_preprocessing(input[2])\r\n        thal_processed = thal_preprocessing(input[3])\r\n\r\n        preprocessed_inputs = {\"age\": age_processed, \r\n                              \"sex\": sex_processed, \r\n                              \"cp\": tf.expand_dims(cp_processed, 0), \r\n                              \"thal\": tf.expand_dims(thal_processed, 0)}\r\n        probs = model(preprocessed_inputs)\r\n        return {\"probs\": probs}\r\n\r\n    return serving_fn\r\n\r\ntf.saved_model.save(\r\n        obj=model,\r\n        export_dir=\"signature_model/\",\r\n        signatures={\r\n            \"serving_default\": custom_signature(model)\r\n        },\r\n    )\r\n```\n```\n\n\n### Relevant log output\n\n```shell\nAssertionError: Tried to export a function which references 'untracked' resource Tensor(\"3629:0\", shape=(), dtype=resource). TensorFlow objects (e.g. tf.Variable) captured by functions must be 'tracked' by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.\r\n\r\n Trackable Python objects referring to this tensor (from gc.get_referrers, limited to two hops):\r\n<tensorflow.python.ops.lookup_ops.StaticHashTable object at 0x7f1d051b2e10>\n```\n</details>"
        },
        {
            "Timestamp": "2022-08-31T21:27:11Z",
            "EntityIds": [
                323199
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "HY3EXZLS8JL6"
            ],
            "Context": "Fix invalid conflict resolution. Signed-off-by: Mihai Maruseac <mihaimaruseac@google.com>"
        },
        {
            "Timestamp": "2022-08-31T21:27:11Z",
            "Entity Ids": [
                323199
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "HY3EXZLS8JL6",
                "UMO9WZB4FHM5"
            ],
            "Context": "Fix invalid conflict resolution. Signed-off-by: Mihai Maruseac <mihaimaruseac@google.com>"
        },
        {
            "Timestamp": "2022-08-31T21:19:52Z",
            "EntityIds": [
                323199
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "LFWKGKAZQZYZ"
            ],
            "Context": "Fix build on r2.7. Signed-off-by: Mihai Maruseac <mihaimaruseac@google.com>"
        },
        {
            "Timestamp": "2022-08-31T21:19:52Z",
            "Entity Ids": [
                323199
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "LFWKGKAZQZYZ",
                "AX5EV9SI8L5Z"
            ],
            "Context": "Fix build on r2.7. Signed-off-by: Mihai Maruseac <mihaimaruseac@google.com>"
        },
        {
            "Timestamp": "2022-08-31T21:19:41Z",
            "EntityIds": [
                323199
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "R106UYJNYODP"
            ],
            "Context": "Fix build on r2.8. Signed-off-by: Mihai Maruseac <mihaimaruseac@google.com>"
        },
        {
            "Timestamp": "2022-08-31T21:19:41Z",
            "Entity Ids": [
                323199
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "R106UYJNYODP",
                "4AZ7VWDQEQLS"
            ],
            "Context": "Fix build on r2.8. Signed-off-by: Mihai Maruseac <mihaimaruseac@google.com>"
        },
        {
            "Timestamp": "2022-08-31T21:19:41Z",
            "Entity Ids": [
                323199
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "R106UYJNYODP",
                "8LMCRMLHN7QZ"
            ],
            "Context": "Fix build on r2.8. Signed-off-by: Mihai Maruseac <mihaimaruseac@google.com>"
        },
        {
            "Timestamp": "2022-08-31T20:59:10Z",
            "EntityIds": [
                10923599,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "CI59WJ35I4X2"
            ],
            "Context": "[TF-TRT] Allow `bool` dtype as IO of TRTEngineOps. This PR allows `bool` dtype as input or output dtype of `TRTEngineOp`."
        },
        {
            "Timestamp": "2022-08-31T20:59:10Z",
            "Entity Ids": [
                10923599,
                48215717,
                35820639
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "CI59WJ35I4X2",
                "F7EEOZXQD3DW"
            ],
            "Context": "[TF-TRT] Allow `bool` dtype as IO of TRTEngineOps. This PR allows `bool` dtype as input or output dtype of `TRTEngineOp`."
        },
        {
            "Timestamp": "2022-08-31T20:54:04Z",
            "EntityIds": [
                80416898,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "HBGT8ARB1I92"
            ],
            "Context": "[TFTRT]: Remove shape optimization profile WAR for new TRT versions. In dynamic shape mode, if an input shape value tensor has min=opt=max profiles, then TRT 7 was pruning this tensor from the network (since its value could be deduced from the profile). TF-TRT introduced `FixShapeValueProfile` to modify the profiles which prevented TRT from pruning these inputs.\r\n\r\nThis workaround is not necessary in TRT8, and actually can be harmful, because it can lead to inconsistent input profiles. Remove this WAR for newer versions of TRT.\r\n\r\ncc: @tfeher @bixia1 @DEKHTIARJonathan "
        },
        {
            "Timestamp": "2022-08-31T20:54:04Z",
            "Entity Ids": [
                80416898,
                48215717,
                35820639
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "HBGT8ARB1I92",
                "IH9MJIWWWL51"
            ],
            "Context": "[TFTRT]: Remove shape optimization profile WAR for new TRT versions. In dynamic shape mode, if an input shape value tensor has min=opt=max profiles, then TRT 7 was pruning this tensor from the network (since its value could be deduced from the profile). TF-TRT introduced `FixShapeValueProfile` to modify the profiles which prevented TRT from pruning these inputs.\r\n\r\nThis workaround is not necessary in TRT8, and actually can be harmful, because it can lead to inconsistent input profiles. Remove this WAR for newer versions of TRT.\r\n\r\ncc: @tfeher @bixia1 @DEKHTIARJonathan "
        },
        {
            "Timestamp": "2022-08-31T20:42:53Z",
            "EntityIds": [
                77295044,
                86464649
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "BUVOMP863FTF"
            ],
            "Context": "Not enough flexibility to choose actual accelerator in CoreML delegate. Only [two options exist](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/coreml/coreml_delegate.h) when creating a CoreML delegate:\r\n```\r\ntypedef enum {\r\n  // Create Core ML delegate only on devices with Apple Neural Engine.\r\n  // Returns nullptr otherwise.\r\n  TfLiteCoreMlDelegateDevicesWithNeuralEngine,\r\n  // Always create Core ML delegate\r\n  TfLiteCoreMlDelegateAllDevices\r\n} TfLiteCoreMlDelegateEnabledDevices;\r\n```\r\n\r\nThese don't quite fit what's possible with CoreML, [as documented here](https://developer.apple.com/documentation/coreml/mlcomputeunits?changes=latest_major&language=objc). Ideally, we should have a way to specify whether we want to use any accelerator (including neural engine), CPU only, or CPU and GPU (excluding neural engine). iOS 16 will also introduce a way to use CPU and neural engine, i.e. excluding GPU.\r\n\r\nCurrently the CoreML delegate always uses `MLComputeUnitsAll` in [coreml_executor.mm](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/coreml/coreml_executor.mm).\r\n"
        },
        {
            "Timestamp": "2022-08-31T20:31:54Z",
            "EntityIds": [
                77295044,
                86464649
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "Z868W4FAMLWA"
            ],
            "Context": "TfLiteCoreMlDelegateOptions documentation is not up-to-date. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/delegates/coreml\r\n\r\nIt currently shows the following structure, which is not up to date:\r\n```\r\ntypedef struct {\r\n // We have dummy for now as we can't have empty struct in C.\r\n char dummy;\r\n} TfLiteCoreMlDelegateOptions;\r\n```\r\n\r\nSee current definition in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/coreml/coreml_delegate.h.\r\n"
        },
        {
            "Timestamp": "2022-08-31T19:27:31Z",
            "EntityIds": [
                42785357,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "Y7FZ44O631KN"
            ],
            "Context": "Adding TensorFlow_PR_Life_Cycle.md document to walk users through the TF PR Life Cycle. Fixes Github https://github.com/tensorflow/tensorflow/issues/33802"
        },
        {
            "Timestamp": "2022-08-31T19:27:31Z",
            "Entity Ids": [
                42785357,
                48215717
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "Y7FZ44O631KN",
                "IXNL0LW5F4PJ"
            ],
            "Context": "Adding TensorFlow_PR_Life_Cycle.md document to walk users through the TF PR Life Cycle. Fixes Github https://github.com/tensorflow/tensorflow/issues/33802"
        },
        {
            "Timestamp": "2022-08-31T19:05:55Z",
            "EntityIds": [
                6932348,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "UK8I6J7GQWU1"
            ],
            "Context": "Update curl to 7.85.0. \r\nThis PR updates curl to 7.85.0 (7.85.0 covers the following vulnerabilities):\r\n\r\nCVE-2022-35252: control code in cookie denial of service\r\n\r\nSee https://curl.se/docs/security.html for details\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>"
        },
        {
            "Timestamp": "2022-08-31T19:05:55Z",
            "Entity Ids": [
                6932348,
                48215717,
                323199
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "UK8I6J7GQWU1",
                "1HFQ3HX2ZA7L"
            ],
            "Context": "Update curl to 7.85.0. \r\nThis PR updates curl to 7.85.0 (7.85.0 covers the following vulnerabilities):\r\n\r\nCVE-2022-35252: control code in cookie denial of service\r\n\r\nSee https://curl.se/docs/security.html for details\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>"
        },
        {
            "Timestamp": "2022-08-31T19:05:55Z",
            "Entity Ids": [
                6932348,
                48215717,
                323199
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "UK8I6J7GQWU1",
                "CD9SZQDNUR33"
            ],
            "Context": "Update curl to 7.85.0. \r\nThis PR updates curl to 7.85.0 (7.85.0 covers the following vulnerabilities):\r\n\r\nCVE-2022-35252: control code in cookie denial of service\r\n\r\nSee https://curl.se/docs/security.html for details\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>"
        },
        {
            "Timestamp": "2022-08-31T18:04:59Z",
            "EntityIds": [
                577149,
                86464649
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "SZ0AON089A4S"
            ],
            "Context": "Where can I find the list of ops from TensorFlow's Python API supported by default in TensorFlowLite. <details><summary>Click to expand!</summary> \r\n \r\n ### Issue Type\r\n\r\nOthers\r\n\r\n### Source\r\n\r\nsource\r\n\r\n### Tensorflow Version\r\n\r\n2.9.1\r\n\r\n### Custom Code\r\n\r\nNo\r\n\r\n### OS Platform and Distribution\r\n\r\n_No response_\r\n\r\n### Mobile device\r\n\r\n_No response_\r\n\r\n### Python version\r\n\r\n_No response_\r\n\r\n### Bazel version\r\n\r\n_No response_\r\n\r\n### GCC/Compiler version\r\n\r\n_No response_\r\n\r\n### CUDA/cuDNN version\r\n\r\n_No response_\r\n\r\n### GPU model and memory\r\n\r\n_No response_\r\n\r\n### Current Behaviour?\r\n\r\nHi. I'm trying to figure out what from TensorFlow's Python API is supported by TensorFlowLite. I know there's a list of [supported MLIR ops](https://www.tensorflow.org/mlir/tfl_ops), but that is still one level of indirection from the Python API. I've also found other locations where the builtins are specified e.g. in the [generated schema](https://github.com/tensorflow/tensorflow/blob/681b73dd2e4216d883007139a53beb6c2f60cf94/tensorflow/lite/schema/schema_generated.h#L1231) or say the kernels specified in [tensorflow/lite/kernels/BUILD](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/BUILD#L562) but again, I'm not sure how these names map to TensorFlow's Python API.\r\n\r\nIs there a location in the code or a script I can run to find the mapping?\r\n\r\n\r\n### Standalone code to reproduce the issue\r\n\r\n```shell\r\nn/a\r\n```\r\n\r\n\r\n### Relevant log output\r\n\r\n_No response_</details>"
        },
        {
            "Timestamp": "2022-08-31T15:53:10Z",
            "EntityIds": [
                106367904
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "Z6U3EPFSIDBD"
            ],
            "Context": "Add ordered sparse index validation.. Option to check that the indices tensor is lexicographically ordered,\r\nwhich is required by some ops.\r\n\r\nPiperOrigin-RevId: 460978686"
        },
        {
            "Timestamp": "2022-08-31T15:53:10Z",
            "Entity Ids": [
                106367904
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "Z6U3EPFSIDBD",
                "3J85X7QF4PFX"
            ],
            "Context": "Add ordered sparse index validation.. Option to check that the indices tensor is lexicographically ordered,\r\nwhich is required by some ops.\r\n\r\nPiperOrigin-RevId: 460978686"
        },
        {
            "Timestamp": "2022-08-31T15:50:17Z",
            "EntityIds": [
                50210727,
                1491091,
                81610181
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "JDS17J1404RB"
            ],
            "Context": "hlo-legalize-to-linalg crashes on convolution op. <details><summary>Click to expand!</summary> \r\n \r\n ### Issue Type\r\n\r\nBug\r\n\r\n### Source\r\n\r\nsource\r\n\r\n### Tensorflow Version\r\n\r\nSHA 551852a9ea9bf4e99856ce75c63516ad6d372239\r\n\r\n### Custom Code\r\n\r\nNo\r\n\r\n### OS Platform and Distribution\r\n\r\n_No response_\r\n\r\n### Mobile device\r\n\r\n_No response_\r\n\r\n### Python version\r\n\r\n_No response_\r\n\r\n### Bazel version\r\n\r\n_No response_\r\n\r\n### GCC/Compiler version\r\n\r\n_No response_\r\n\r\n### CUDA/cuDNN version\r\n\r\n_No response_\r\n\r\n### GPU model and memory\r\n\r\n_No response_\r\n\r\n### Current Behaviour?\r\n\r\n\r\nI found a bug in `hlo-legalize-to-linalg` where it will crash for certain convolution operators.  Here's one example of an op that causes the crash\r\n\r\n```shell\r\nfunc.func @main(%arg0: tensor<1x13x13x32xf32>, %arg1: tensor<1x11x11x64xf32>) -> tensor<3x3x32x64xf32> {\r\n  %0 = \"mhlo.convolution\"(%arg0, %arg1) {batch_group_count = 1 : i64, dimension_numbers = #mhlo.conv<[f, 0, 1, b]x[i, 0, 1, o]->[0, 1, b, f]>, feature_group_count = 1 : i64, lhs_dilation = dense<1> : tensor<2xi64>, padding = dense<0> : tensor<2x2xi64>, rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<1> : tensor<2xi64>} : (tensor<1x13x13x32xf32>, tensor<1x11x11x64xf32>) -> tensor<3x3x32x64xf32>\r\n  return %0 : tensor<3x3x32x64xf32>\r\n}\r\n```\r\n\r\nThe crash appears to happen on this line https://github.com/tensorflow/tensorflow/commit/763d55e7e33ca888a2aa14fa89ec413047daf1e5#diff-524cc00a6c4fc699fbad5fe46d08167e30aecdb4d19edcded46028f17f1f4837R2247.  I printed out the expressions in all 3 arguments and it appears that dstExpr still has a null in it.  Here's what they look like.\r\n\r\n```\r\nsrcExprs\r\nd0\r\nd2 + d3\r\nd4 + d5\r\nd6\r\nwindowExprs\r\nd0\r\nd3\r\nd5\r\nd1\r\ndstExprs\r\nd2\r\nd4\r\n<<NULL AFFINE EXPR>>\r\nd6\r\n```\r\nRun command in standalone code section on the IR provided above\r\n\r\n\r\n### Standalone code to reproduce the issue\r\n\r\n```shell\r\ntf-opt --hlo-legalize-to-linalg\r\n```\r\n\r\n\r\n### Relevant log output\r\n\r\n```shell\r\nStack dump:\r\n0.      Program arguments: tf-opt --hlo-legalize-to-linalg convolution.mlir\r\n1.      Program arguments: tf-opt --hlo-legalize-to-linalg convolution.mlir\r\n #0 0x00007f089dc9a437 llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/../../../_solib_k8/_U_S_Stensorflow_Scompiler_Smlir_Ctf-opt___Utensorflow/libtensorflow_framework.so.2+0x1382437)\r\n #1 0x00007f089dc97a35 llvm::sys::RunSignalHandlers() (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/../../../_solib_k8/_U_S_Stensorflow_Scompiler_Smlir_Ctf-opt___Utensorflow/libtensorflow_framework.so.2+0x137fa35)\r\n #2 0x00007f089dc98a85 SignalHandler(int) Signals.cpp:0:0\r\n #3 0x00007f089c78f3c0 __restore_rt (/lib/x86_64-linux-gnu/libpthread.so.0+0x143c0)\r\n #4 0x00005616013e56aa mlir::AffineExpr::walk(std::function<void (mlir::AffineExpr)>) const (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10f026aa)\r\n #5 0x00005616013ef532 mlir::AffineMap::inferFromExprList(llvm::ArrayRef<llvm::ArrayRef<mlir::AffineExpr>>) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10f0c532)\r\n #6 0x00005615fbdcf44e mlir::mhlo::(anonymous namespace)::ConvolutionOpGeneralConversion::matchAndRewrite(mlir::mhlo::ConvolutionOp, mlir::mhlo::ConvolutionOpAdaptor, mlir::ConversionPatternRewriter&) const legalize_to_linalg.cc:0:0\r\n #7 0x00005615fbcff44b mlir::OpConversionPattern<mlir::mhlo::ConvolutionOp>::matchAndRewrite(mlir::Operation*, llvm::ArrayRef<mlir::Value>, mlir::ConversionPatternRewriter&) const (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0xb81c44b)\r\n #8 0x000056160124d76d mlir::ConversionPattern::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&) const (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10d6a76d)\r\n #9 0x00005616012a7243 mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<mlir::LogicalResult (mlir::Pattern const&)>) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10dc4243)\r\n#10 0x00005616012584ec (anonymous namespace)::OperationLegalizer::legalize(mlir::Operation*, mlir::ConversionPatternRewriter&) DialectConversion.cpp:0:0\r\n#11 0x000056160125e257 (anonymous namespace)::OperationConverter::convertOperations(llvm::ArrayRef<mlir::Operation*>, llvm::function_ref<void (mlir::Diagnostic&)>) DialectConversion.cpp:0:0\r\n#12 0x000056160125e5f1 mlir::applyPartialConversion(llvm::ArrayRef<mlir::Operation*>, mlir::ConversionTarget&, mlir::FrozenRewritePatternSet const&, llvm::DenseSet<mlir::Operation*, llvm::DenseMapInfo<mlir::Operation*, void>>*) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10d7b5f1)\r\n#13 0x000056160125e677 mlir::applyPartialConversion(mlir::Operation*, mlir::ConversionTarget&, mlir::FrozenRewritePatternSet const&, llvm::DenseSet<mlir::Operation*, llvm::DenseMapInfo<mlir::Operation*, void>>*) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10d7b677)\r\n#14 0x00005615fbdd6a98 mlir::mhlo::(anonymous namespace)::HloLegalizeToLinalgPass::runOnOperation() legalize_to_linalg.cc:0:0\r\n#15 0x000056160138d792 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10eaa792)\r\n#16 0x000056160138ea42 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10eaba42)\r\n#17 0x000056160138ca05 mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10ea9a05)\r\n#18 0x000056160138d3a2 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10eaa3a2)\r\n#19 0x000056160138ea42 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10eaba42)\r\n#20 0x000056160138f5a6 mlir::PassManager::run(mlir::Operation*) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10eac5a6)\r\n#21 0x00005615fcf7cfd3 performActions(llvm::raw_ostream&, bool, bool, llvm::SourceMgr&, mlir::MLIRContext*, llvm::function_ref<mlir::LogicalResult (mlir::PassManager&)>) (.constprop.0) MlirOptMain.cpp:0:0\r\n#22 0x00005615fcf7d526 processBuffer(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, bool, bool, bool, bool, llvm::function_ref<mlir::LogicalResult (mlir::PassManager&)>, mlir::DialectRegistry&, llvm::ThreadPool*) MlirOptMain.cpp:0:0\r\n#23 0x00005615fcf7d731 mlir::LogicalResult llvm::function_ref<mlir::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>::callback_fn<mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<mlir::LogicalResult (mlir::PassManager&)>, mlir::DialectRegistry&, bool, bool, bool, bool, bool)::'lambda'(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>(long, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&) MlirOptMain.cpp:0:0\r\n#24 0x00005616014d9d73 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<mlir::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, bool, bool) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10ff6d73)\r\n#25 0x00005615fcf7ca72 mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<mlir::LogicalResult (mlir::PassManager&)>, mlir::DialectRegistry&, bool, bool, bool, bool, bool) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0xca99a72)\r\n#26 0x00005615fcf7cb23 mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::PassPipelineCLParser const&, mlir::DialectRegistry&, bool, bool, bool, bool, bool) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0xca99b23)\r\n#27 0x00005615fcf7dfa4 mlir::MlirOptMain(int, char**, llvm::StringRef, mlir::DialectRegistry&, bool) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0xca9afa4)\r\n#28 0x00005615fb7001fb main (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0xb21d1fb)\r\n#29 0x00007f089c3b00b3 __libc_start_main /build/glibc-sMfBJT/glibc-2.31/csu/../csu/libc-start.c:342:3\r\n#30 0x00005615f3bae94e _start (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x36cb94e)\r\n #0 0x00007f089dc9a437 llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/../../../_solib_k8/_U_S_Stensorflow_Scompiler_Smlir_Ctf-opt___Utensorflow/libtensorflow_framework.so.2+0x1382437)\r\n #1 0x00007f089dc97a35 llvm::sys::RunSignalHandlers() (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/../../../_solib_k8/_U_S_Stensorflow_Scompiler_Smlir_Ctf-opt___Utensorflow/libtensorflow_framework.so.2+0x137fa35)\r\n #2 0x00007f089dc98a85 SignalHandler(int) Signals.cpp:0:0\r\n #3 0x00007f089c78f3c0 __restore_rt (/lib/x86_64-linux-gnu/libpthread.so.0+0x143c0)\r\n #4 0x00005616013e56aa mlir::AffineExpr::walk(std::function<void (mlir::AffineExpr)>) const (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10f026aa)\r\n #5 0x00005616013ef532 mlir::AffineMap::inferFromExprList(llvm::ArrayRef<llvm::ArrayRef<mlir::AffineExpr>>) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10f0c532)\r\n #6 0x00005615fbdcf44e mlir::mhlo::(anonymous namespace)::ConvolutionOpGeneralConversion::matchAndRewrite(mlir::mhlo::ConvolutionOp, mlir::mhlo::ConvolutionOpAdaptor, mlir::ConversionPatternRewriter&) const legalize_to_linalg.cc:0:0\r\n #7 0x00005615fbcff44b mlir::OpConversionPattern<mlir::mhlo::ConvolutionOp>::matchAndRewrite(mlir::Operation*, llvm::ArrayRef<mlir::Value>, mlir::ConversionPatternRewriter&) const (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0xb81c44b)\r\n #8 0x000056160124d76d mlir::ConversionPattern::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&) const (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10d6a76d)\r\n #9 0x00005616012a7243 mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<mlir::LogicalResult (mlir::Pattern const&)>) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10dc4243)\r\n#10 0x00005616012584ec (anonymous namespace)::OperationLegalizer::legalize(mlir::Operation*, mlir::ConversionPatternRewriter&) DialectConversion.cpp:0:0\r\n#11 0x000056160125e257 (anonymous namespace)::OperationConverter::convertOperations(llvm::ArrayRef<mlir::Operation*>, llvm::function_ref<void (mlir::Diagnostic&)>) DialectConversion.cpp:0:0\r\n#12 0x000056160125e5f1 mlir::applyPartialConversion(llvm::ArrayRef<mlir::Operation*>, mlir::ConversionTarget&, mlir::FrozenRewritePatternSet const&, llvm::DenseSet<mlir::Operation*, llvm::DenseMapInfo<mlir::Operation*, void>>*) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10d7b5f1)\r\n#13 0x000056160125e677 mlir::applyPartialConversion(mlir::Operation*, mlir::ConversionTarget&, mlir::FrozenRewritePatternSet const&, llvm::DenseSet<mlir::Operation*, llvm::DenseMapInfo<mlir::Operation*, void>>*) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10d7b677)\r\n#14 0x00005615fbdd6a98 mlir::mhlo::(anonymous namespace)::HloLegalizeToLinalgPass::runOnOperation() legalize_to_linalg.cc:0:0\r\n#15 0x000056160138d792 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10eaa792)\r\n#16 0x000056160138ea42 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10eaba42)\r\n#17 0x000056160138ca05 mlir::detail::OpToOpPassAdaptor::runOnOperationAsyncImpl(bool) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10ea9a05)\r\n#18 0x000056160138d3a2 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10eaa3a2)\r\n#19 0x000056160138ea42 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10eaba42)\r\n#20 0x000056160138f5a6 mlir::PassManager::run(mlir::Operation*) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10eac5a6)\r\n#21 0x00005615fcf7cfd3 performActions(llvm::raw_ostream&, bool, bool, llvm::SourceMgr&, mlir::MLIRContext*, llvm::function_ref<mlir::LogicalResult (mlir::PassManager&)>) (.constprop.0) MlirOptMain.cpp:0:0\r\n#22 0x00005615fcf7d526 processBuffer(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, bool, bool, bool, bool, llvm::function_ref<mlir::LogicalResult (mlir::PassManager&)>, mlir::DialectRegistry&, llvm::ThreadPool*) MlirOptMain.cpp:0:0\r\n#23 0x00005615fcf7d731 mlir::LogicalResult llvm::function_ref<mlir::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>::callback_fn<mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<mlir::LogicalResult (mlir::PassManager&)>, mlir::DialectRegistry&, bool, bool, bool, bool, bool)::'lambda'(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>(long, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&) MlirOptMain.cpp:0:0\r\n#24 0x00005616014d9d73 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<mlir::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, bool, bool) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x10ff6d73)\r\n#25 0x00005615fcf7ca72 mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<mlir::LogicalResult (mlir::PassManager&)>, mlir::DialectRegistry&, bool, bool, bool, bool, bool) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0xca99a72)\r\n#26 0x00005615fcf7cb23 mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::PassPipelineCLParser const&, mlir::DialectRegistry&, bool, bool, bool, bool, bool) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0xca99b23)\r\n#27 0x00005615fcf7dfa4 mlir::MlirOptMain(int, char**, llvm::StringRef, mlir::DialectRegistry&, bool) (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0xca9afa4)\r\n#28 0x00005615fb7001fb main (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0xb21d1fb)\r\n#29 0x00007f089c3b00b3 __libc_start_main /build/glibc-sMfBJT/glibc-2.31/csu/../csu/libc-start.c:342:3\r\n#30 0x00005615f3bae94e _start (/.cache/bazel/_bazel/1a972990889a509d49bb6421d8d05ae2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tf-opt+0x36cb94e)\r\nSegmentation fault (core dumped)\r\n```\r\n</details>"
        },
        {
            "Timestamp": "2022-08-31T15:42:06Z",
            "EntityIds": [
                106367904
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "LD9K0ELQNGN2"
            ],
            "Context": "Add index check to ValidateSparseTensor.. The validation check now verifies all index entries are within correct bounds.\r\nThis is to prevent memory access errors.\r\n\r\nPiperOrigin-RevId: 450695916"
        },
        {
            "Timestamp": "2022-08-31T15:42:06Z",
            "Entity Ids": [
                106367904
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "LD9K0ELQNGN2",
                "MVL4LGHGZFR1"
            ],
            "Context": "Add index check to ValidateSparseTensor.. The validation check now verifies all index entries are within correct bounds.\r\nThis is to prevent memory access errors.\r\n\r\nPiperOrigin-RevId: 450695916"
        },
        {
            "Timestamp": "2022-08-31T15:09:27Z",
            "EntityIds": [
                45400368,
                73069040
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "KX2NR48ANA3L"
            ],
            "Context": "NNAPI delegate issue on Snapdragon 888. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nsource\n\n### Tensorflow Version\n\ntf 2.9\n\n### Custom Code\n\nNo\n\n### OS Platform and Distribution\n\nAndroid\n\n### Mobile device\n\nSnapdragon 888 (tested with Android 12)\n\n### Python version\n\n_No response_\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nWe faced two major issues on Snapdragon 888, when inferring our quantized (INT8) tflite models with the NNAPI delegate:\r\n  \r\n1-On devices with Snapdragon 888 (tested with Android 12), the NNAPI delegate always crashes when there is a Quantize node right before a Concatenation node.\r\n\r\n2-On devices with Snapdragon 888 (tested with Android 12), the INT8 tflite version of a model in which the kernel size in at least one of the Dense layers is larger than a specific threshold, always crashes with the NNAPI delegate.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nWe have implemented a small tool (with comprehensive documentation) to reproduce the mentioned issues. Here is the link to the repository:\r\n\r\nhttps://github.com/Bahar-BM/Concat_NNAPI\n```\n\n\n### Relevant log output\n\n_No response_</details>"
        },
        {
            "Timestamp": "2022-08-31T12:56:52Z",
            "EntityIds": [
                20746434,
                86464649
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "9UOJKW8EP8XD"
            ],
            "Context": "error: 'tf.Conv2D' op is neither a custom op nor a flex op. ### 1. System information\r\n\r\n- Windows 10:\r\n- TensorFlow 2.9.1 installed via pip\r\n\r\n### 2. Code\r\n\r\nProvide code to help us reproduce your issues using one of the following options:\r\n\r\n#### Option A: Reference colab notebooks\r\nhttps://colab.research.google.com/gist/andreaskoelsch/c5f82bca1aa4289724dd827d4d6cf89e/tensorflow-lite-debugger-colab.ipynb\r\n\r\n### 3. Failure after conversion\r\nConversion of a very simple model does not work. `error: 'tf.Conv2D' op is neither a custom op nor a flex op`\r\nIf either the `GroupNormalization` or the second `Conv2D` layer is commented, the conversion works. The combination of the two seems to be a problem.\r\n"
        },
        {
            "Timestamp": "2022-08-31T11:38:19Z",
            "EntityIds": [
                58871163,
                86464649
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "JWAYBCBXJ1IX"
            ],
            "Context": "Saving tensorflow logs to a log file in python. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nSupport\n\n### Source\n\nbinary\n\n### Tensorflow Version\n\ntf 2.2\n\n### Custom Code\n\nNo\n\n### OS Platform and Distribution\n\nWindows 10\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n3.7\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nWhile running a script that uses tf, it prints some logs such as info and warning that comes from inside the tensorflow library. Instead of printing this on console how can a user save it into a seperate log file and another log file for other modules. That is saving logs of tensorflow alone into one file and the python logging as per user preference.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nimport logging\r\n\r\n# get TF logger\r\nlog = logging.getLogger('tensorflow')\r\nlog.setLevel(logging.DEBUG)\r\n\r\n# create formatter and add it to the handlers\r\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\r\n\r\n# create file handler which logs even debug messages\r\nfh = logging.FileHandler('tensorflow.log')\r\nfh.setLevel(logging.DEBUG)\r\nfh.setFormatter(formatter)\r\nlog.addHandler(fh)\n```\n\n\n### Relevant log output\n\n_No response_</details>"
        },
        {
            "Timestamp": "2022-08-31T11:03:40Z",
            "EntityIds": [
                33950866,
                84765720
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "IRL98PA7YL61"
            ],
            "Context": "Why are tensors used after they are freed in a gpu sync operation?. <details><summary>Click to expand!</summary> \r\n \r\n ### Issue Type\r\n\r\nOthers\r\n\r\n### Source\r\n\r\nsource\r\n\r\n### Tensorflow Version\r\n\r\n2.8\r\n\r\n### Custom Code\r\n\r\nYes\r\n\r\n### OS Platform and Distribution\r\n\r\nLinux\r\n\r\n### Mobile device\r\n\r\nNo\r\n\r\n### Python version\r\n\r\n3.8\r\n\r\n### Current Behaviour?\r\n\r\nWhy are tensors used after they are freed in a gpu sync operation?\r\nexample in softmax_op_gpu.cu.cc\r\n```shell\r\n  void Compute(OpKernelContext* context) override {\r\n      ............\r\n      Tensor max_logits;\r\n      Tensor sum_probs;\r\n      OP_REQUIRES_OK(context,\r\n                     context->allocate_temp(DataTypeToEnum<T>::value,\r\n                                            softmax_out->shape(), &max_logits));\r\n\r\n      typedef typename softmax_traits<T>::accumulator_type acc_type;\r\n      OP_REQUIRES_OK(context,\r\n                     context->allocate_temp(DataTypeToEnum<acc_type>::value,\r\n                                            softmax_out->shape(), &sum_probs));\r\n\r\n        .................\r\n        TF_CHECK_OK(GpuLaunchKernel(\r\n            GenerateNormalizedProb<T, acc_type, kUnroll>, numBlocks,\r\n            numThreadsPerBlock, 0, cu_stream,\r\n            reinterpret_cast<const T*>(logits_in_.flat<T>().data()),\r\n            reinterpret_cast<const acc_type*>(\r\n                sum_probs.flat<acc_type>().data()),\r\n            reinterpret_cast<const T*>(max_logits.flat<T>().data()),\r\n            const_cast<T*>(softmax_out->flat<T>().data()), rows, cols, log_));\r\n        ....................\r\n    }\r\n  }\r\n```\r\n\r\n\r\n### Standalone code to reproduce the issue\r\n\r\n1. ```max_logits ```and ```sum_probs``` will be free when ```Compute``` function over, because they are temporary variant.\r\n2. ```GpuLaunchKernel``` will async use ```max_logits``` and ```sum_probs``` in kernel launch. \r\nSo ```max_logits ```and ```sum_probs``` maybe used after they are freed.\r\n\r\nTensor is a ref and TensorBuffer guaranteed memory/GPU memory is used. but in the above example, when function over and temporary tensor destruct, GPU Memory in TensorBuffer will be freed to BFCAllocator and in sametime this GPU Memory maybe be allocated by other GPU op.\r\nwe move Administrative rights from TensorBuffer to BFCAllocator.  Is it the right way?\r\n\r\n\r\n### Relevant log output\r\n\r\n```shell\r\nvoid Compute(OpKernelContext* context) override {\r\n      ............\r\n      Tensor max_logits;\r\n      Tensor sum_probs;\r\n      OP_REQUIRES_OK(context,\r\n                     context->allocate_temp(DataTypeToEnum<T>::value,\r\n                                            softmax_out->shape(), &max_logits));\r\n\r\n      typedef typename softmax_traits<T>::accumulator_type acc_type;\r\n      OP_REQUIRES_OK(context,\r\n                     context->allocate_temp(DataTypeToEnum<acc_type>::value,\r\n                                            softmax_out->shape(), &sum_probs));\r\n\r\n        .................\r\n        TF_CHECK_OK(GpuLaunchKernel(\r\n            GenerateNormalizedProb<T, acc_type, kUnroll>, numBlocks,\r\n            numThreadsPerBlock, 0, cu_stream,\r\n            reinterpret_cast<const T*>(logits_in_.flat<T>().data()),\r\n            reinterpret_cast<const acc_type*>(\r\n                sum_probs.flat<acc_type>().data()),\r\n            reinterpret_cast<const T*>(max_logits.flat<T>().data()),\r\n            const_cast<T*>(softmax_out->flat<T>().data()), rows, cols, log_));\r\n        ....................\r\n         TensorRef ref0(max_logits);\r\n         TensorRef ref1(sum_probs);\r\n         auto done = [ref0, ref1](){\r\n           ref0.Unref;\r\n           ref1.Unref;\r\n         };\r\n         device->event_mgr->ThenExecute(device->stream(), done);\r\n    }\r\n  }\r\n```\r\nI found the same behavior in many GPU sync operations, is this the correct approach?\r\n</details>"
        },
        {
            "Timestamp": "2022-08-31T07:40:44Z",
            "EntityIds": [
                45327670,
                84765720
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "FIXUTNFFKWX4"
            ],
            "Context": "tf.image.rot90 should add a note for the case k<0. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nDocumentation Feature Request\n\n### Source\n\nsource\n\n### Tensorflow Version\n\nTF2.8\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\n_No response_\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n_No response_\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nThe documentation only describes how the code runs when k>0, and dont mention k<0. The code shows that when k<0, the image will be rotated clockwise. I think a note should be added to explain what happens when k<0\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nimport tensorflow as tf\r\nresults={}\r\ntry:\r\n  arg_0 = tf.saturate_cast(tf.random.uniform([2, 2, 1], minval=-256, maxval=257, dtype=tf.int64), dtype=tf.int32)\r\n  k = -1\r\n  results[\"res\"] = tf.image.rot90(arg_0,k=k,)\r\nexcept Exception as e:\r\n  results[\"err\"] = \"Error:\"+str(e)\r\nprint(results)\n```\n\n\n### Relevant log output\n\n_No response_</details>"
        },
        {
            "Timestamp": "2022-08-31T06:53:00Z",
            "EntityIds": [
                22957388,
                73069040
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "WQ1SC0DPACO5"
            ],
            "Context": "Why is `tf.Conv2D` treated as a SELECT op?. ### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS (Intel)\r\n- TensorFlow installation (pip package or built from source): `pip`\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): TensorFlow 2.9.1\r\n\r\n### 2. Code\r\n\r\n```py\r\nfrom transformers import TFMobileViTForImageClassification\r\nimport tensorflow as tf\r\n\r\nmodel = TFMobileViTForImageClassification.from_pretrained(\"apple/mobilevit-xx-small\")\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_model = converter.convert()\r\nwith open(\"mobilevit_xxs.tflite\", \"wb\") as f:\r\n    f.write(tflite_model)\r\n```\r\n\r\nInstall `transformers` by running `pip install git+https://github.com/sayakpaul/transformers@feat/tf-mobilevit`.\r\n\r\n### 3. Failure ~after~ before conversion\r\n\r\n```bash\r\nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select\r\nTF Select ops: Conv2D\r\nDetails:\r\n\ttf.Conv2D(tensor<?x?x?x?xf32>, tensor<1x1x64x48xf32>) -> (tensor<?x?x?x48xf32>) : {data_format = \"NHWC\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\r\n\ttf.Conv2D(tensor<?x?x?x?xf32>, tensor<1x1x80x64xf32>) -> (tensor<?x?x?x64xf32>) : {data_format = \"NHWC\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\r\n\ttf.Conv2D(tensor<?x?x?x?xf32>, tensor<1x1x96x80xf32>) -> (tensor<?x?x?x80xf32>) : {data_format = \"NHWC\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\r\n\r\nTraceback (most recent call last):\r\n  File \"playground_tf.py\", line 72, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"/Users/sayakpaul/.local/bin/.virtualenvs/hf/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 929, in wrapper\r\n    return self._convert_and_export_metrics(convert_func, *args, **kwargs)\r\n  File \"/Users/sayakpaul/.local/bin/.virtualenvs/hf/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 908, in _convert_and_export_metrics\r\n    result = convert_func(self, *args, **kwargs)\r\n  File \"/Users/sayakpaul/.local/bin/.virtualenvs/hf/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 1338, in convert\r\n    saved_model_convert_result = self._convert_as_saved_model()\r\n  File \"/Users/sayakpaul/.local/bin/.virtualenvs/hf/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 1320, in _convert_as_saved_model\r\n    return super(TFLiteKerasModelConverterV2,\r\n  File \"/Users/sayakpaul/.local/bin/.virtualenvs/hf/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 1131, in convert\r\n    result = _convert_graphdef(\r\n  File \"/Users/sayakpaul/.local/bin/.virtualenvs/hf/lib/python3.8/site-packages/tensorflow/lite/python/convert_phase.py\", line 212, in wrapper\r\n    raise converter_error from None  # Re-throws the exception.\r\n  File \"/Users/sayakpaul/.local/bin/.virtualenvs/hf/lib/python3.8/site-packages/tensorflow/lite/python/convert_phase.py\", line 205, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/Users/sayakpaul/.local/bin/.virtualenvs/hf/lib/python3.8/site-packages/tensorflow/lite/python/convert.py\", line 794, in convert_graphdef\r\n    data = convert(\r\n  File \"/Users/sayakpaul/.local/bin/.virtualenvs/hf/lib/python3.8/site-packages/tensorflow/lite/python/convert.py\", line 311, in convert\r\n    raise converter_error\r\ntensorflow.lite.python.convert_phase.ConverterError: /Users/sayakpaul/.local/bin/.virtualenvs/hf/lib/python3.8/site-packages/keras/engine/base_layer.py:1014:0: error: 'tf.Conv2D' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"]): called from\r\n/Users/sayakpaul/.local/bin/.virtualenvs/hf/lib/python3.8/site-packages/keras/engine/base_layer.py:1014:0: note: Error code: ERROR_NEEDS_FLEX_OPS\r\n/Users/sayakpaul/.local/bin/.virtualenvs/hf/lib/python3.8/site-packages/keras/engine/base_layer.py:1014:0: error: 'tf.Conv2D' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"]): called from\r\n/Users/sayakpaul/.local/bin/.virtualenvs/hf/lib/python3.8/site-packages/keras/engine/base_layer.py:1014:0: note: Error code: ERROR_NEEDS_FLEX_OPS\r\n/Users/sayakpaul/.local/bin/.virtualenvs/hf/lib/python3.8/site-packages/keras/engine/base_layer.py:1014:0: error: 'tf.Conv2D' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"]): called from\r\n/Users/sayakpaul/.local/bin/.virtualenvs/hf/lib/python3.8/site-packages/keras/engine/base_layer.py:1014:0: note: Error code: ERROR_NEEDS_FLEX_OPS\r\n<unknown>:0: error: failed while converting: 'main':\r\nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select\r\nTF Select ops: Conv2D\r\nDetails:\r\n\ttf.Conv2D(tensor<?x?x?x?xf32>, tensor<1x1x64x48xf32>) -> (tensor<?x?x?x48xf32>) : {data_format = \"NHWC\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\r\n\ttf.Conv2D(tensor<?x?x?x?xf32>, tensor<1x1x80x64xf32>) -> (tensor<?x?x?x64xf32>) : {data_format = \"NHWC\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\r\n\ttf.Conv2D(tensor<?x?x?x?xf32>, tensor<1x1x96x80xf32>) -> (tensor<?x?x?x80xf32>) : {data_format = \"NHWC\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\r\n```\r\n\r\nIf I add the select OPS during conversion, it passes:\r\n\r\n```py\r\nconverter.target_spec.supported_ops = [\r\n    tf.lite.OpsSet.TFLITE_BUILTINS,  # Enable TensorFlow Lite ops.\r\n    tf.lite.OpsSet.SELECT_TF_OPS,  # Enable TensorFlow ops.\r\n]\r\n```\r\n\r\nWith the following info:\r\n\r\n```bash\r\nWARNING:absl:Found untraced functions such as conv_stem_layer_call_fn, conv_stem_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, conv_1x1_exp_layer_call_fn while saving (showing 5 of 512). These functions will not be directly callable after loading.\r\n2022-08-31 12:21:18.548394: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\r\n2022-08-31 12:21:18.548415: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\r\n2022-08-31 12:21:23.916667: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1901] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\r\nFlex ops: FlexConv2D\r\nDetails:\r\n\ttf.Conv2D(tensor<?x?x?x?xf32>, tensor<1x1x64x48xf32>) -> (tensor<?x?x?x48xf32>) : {data_format = \"NHWC\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\r\n\ttf.Conv2D(tensor<?x?x?x?xf32>, tensor<1x1x80x64xf32>) -> (tensor<?x?x?x64xf32>) : {data_format = \"NHWC\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\r\n\ttf.Conv2D(tensor<?x?x?x?xf32>, tensor<1x1x96x80xf32>) -> (tensor<?x?x?x80xf32>) : {data_format = \"NHWC\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\r\nSee instructions: https://www.tensorflow.org/lite/guide/ops_select\r\n```\r\n\r\n_**But my question is, why is Conv2D a select OP?**_\r\n\r\nAttached is the SavedModel file for better investigation. \r\n\r\n[1.zip](https://github.com/tensorflow/tensorflow/files/9459235/1.zip)\r\n\r\n\r\n### 4. (optional) RNN conversion support\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n### 5. (optional) Any other info / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n"
        },
        {
            "Timestamp": "2022-08-31T05:33:30Z",
            "EntityIds": [
                2286292,
                84765720
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "R3QQQR56UCEB"
            ],
            "Context": "M1 tf.gather_nd: InvalidArgumentError: Multiple OpKernel registrations match NodeDef at the same priority. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nsource\n\n### Tensorflow Version\n\n2.9.2\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\nMacOS Monterey 12.5\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n3.10\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\ntf.gather_nd should properly have a gradient of shape (2,6) in the code below connecting the (very bad and toy) loss to the defined variable. However, it appears that the kernel sets the same priority for some operations and cannot resolve the graph.\r\n\r\nFurthermore, I have observed the following *extremely weird* behavior:\r\n\r\nIf you change the code to `indexed_v = tf.gather_nd(v + 0.0, indices)`, there is no error.\r\n\r\nI have also confirmed that this issue does not occur if I go back to a much older version of tensorflow: `2.4.0-rc0`\r\n\r\nLastly, for reproducibility, I set up my virtual environment with the following executions\r\n\r\n>>> conda create -n tf_bug_test python=3.10\r\n>>> conda activate tf_bug_test\r\n>>> conda install -c apple tensorflow-deps\r\n>>> python -m pip install tensorflow-macos\r\n\r\nNote that if I install tensorflow-metal, the same error will happen but it will specify the computation is on GPU instead of CPU.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ntime = 100\r\nproducts = 6\r\nvar_dim = 2\r\n\r\nwhich_parameter_to_grab = np.random.binomial(1, p=0.1,size=(time, products))\r\nv = tf.Variable(tf.ones((2,products)),name=\"test\",dtype=tf.float32,shape=(var_dim,products))\r\n# generate random indices for grabbing a parameter \r\nindices = np.stack(\r\n    (which_parameter_to_grab, np.tile(np.arange(products)[None, :], (time, 1))),\r\n    axis=2,\r\n).astype(int)\r\n\r\nopt_fcn = tf.keras.optimizers.Adam(learning_rate=1e-3)\r\n\r\nwith tf.GradientTape() as tape:\r\n    indexed_v = tf.gather_nd(v, indices)\r\n    loss_val = tf.reduce_mean(tf.math.square(indexed_v))\r\ngrads = tape.gradient(loss_val, [v])\n```\n\n\n### Relevant log output\n\n```shell\nTraceback (most recent call last):\r\n  File \"/Users/ryansaxe/Documents/bug_reproduce.py\", line 21, in <module>\r\n    grads = tape.gradient(loss_val, [v])\r\n  File \"/Users/ryansaxe/miniforge3/envs/tf_bug_test/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py\", line 1100, in gradient\r\n    flat_grad = imperative_grad.imperative_grad(\r\n  File \"/Users/ryansaxe/miniforge3/envs/tf_bug_test/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py\", line 67, in imperative_grad\r\n    return pywrap_tfe.TFE_Py_TapeGradient(\r\n  File \"/Users/ryansaxe/miniforge3/envs/tf_bug_test/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py\", line 157, in _gradient_function\r\n    return grad_fn(mock_op, *out_grads)\r\n  File \"/Users/ryansaxe/miniforge3/envs/tf_bug_test/lib/python3.10/site-packages/tensorflow/python/ops/array_grad.py\", line 736, in _ResourceGatherNdGrad\r\n    ref_shape = gen_resource_variable_ops.variable_shape(ref, indices.dtype)\r\n  File \"/Users/ryansaxe/miniforge3/envs/tf_bug_test/lib/python3.10/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 1341, in variable_shape\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/Users/ryansaxe/miniforge3/envs/tf_bug_test/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 7164, in raise_from_not_ok_status\r\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Multiple OpKernel registrations match NodeDef at the same priority '{{node VariableShape}}': 'op: \"VariableShape\" device_type: \"CPU\" constraint { name: \"out_type\" allowed_values { list { type: DT_INT64 } } }' and 'op: \"VariableShape\" device_type: \"CPU\" constraint { name: \"out_type\" allowed_values { list { type: DT_INT64 } } }'\r\n\t when instantiating VariableShape [Op:VariableShape]\n```\n</details>"
        },
        {
            "Timestamp": "2022-08-31T04:15:15Z",
            "EntityIds": [
                16867443,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "GW9OY5QKR1ET"
            ],
            "Context": "Lite: Only requires NEON_2_SSE on x86 CPUs (Support Apple Silicon). This is to support building on M1 Macs. ARM CPU provide these instructions so there no need for the translation layer.\r\n\r\nThis var can be set when building https://cmake.org/cmake/help/latest/variable/CMAKE_SYSTEM_PROCESSOR.html\r\nor it's provided if You use this build in https://gitlab.kitware.com/cmake/cmake/-/blob/v3.15.7/Modules/CMakeDetermineSystem.cmake#L35\r\n\r\nRegardless to have the least impact if it's not set, the current behavoir is mainted and the dependency is pulled in.\r\n\r\nThis code change does assume it's set correctly\r\n\r\n***\r\n\r\nI've been working on sharing this project in ConanCenter as I am a community member and discovered this was a patch that the community added some time ago and I want to contribute it back!"
        },
        {
            "Timestamp": "2022-08-31T04:15:15Z",
            "Entity Ids": [
                16867443,
                48215717,
                2908505
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "GW9OY5QKR1ET",
                "7QPRTJ48ONEV"
            ],
            "Context": "Lite: Only requires NEON_2_SSE on x86 CPUs (Support Apple Silicon). This is to support building on M1 Macs. ARM CPU provide these instructions so there no need for the translation layer.\r\n\r\nThis var can be set when building https://cmake.org/cmake/help/latest/variable/CMAKE_SYSTEM_PROCESSOR.html\r\nor it's provided if You use this build in https://gitlab.kitware.com/cmake/cmake/-/blob/v3.15.7/Modules/CMakeDetermineSystem.cmake#L35\r\n\r\nRegardless to have the least impact if it's not set, the current behavoir is mainted and the dependency is pulled in.\r\n\r\nThis code change does assume it's set correctly\r\n\r\n***\r\n\r\nI've been working on sharing this project in ConanCenter as I am a community member and discovered this was a patch that the community added some time ago and I want to contribute it back!"
        },
        {
            "Timestamp": "2022-08-31T00:25:24Z",
            "EntityIds": [
                106367904
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "E6Z8ZHJV67PX"
            ],
            "Context": "Add ordered sparse index validation.. Option to check that the indices tensor is lexicographically ordered,\r\nwhich is required by some ops.\r\n\r\nPiperOrigin-RevId: 460978686"
        },
        {
            "Timestamp": "2022-08-31T00:25:24Z",
            "Entity Ids": [
                106367904
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "E6Z8ZHJV67PX",
                "HIIX5JIIR21K"
            ],
            "Context": "Add ordered sparse index validation.. Option to check that the indices tensor is lexicographically ordered,\r\nwhich is required by some ops.\r\n\r\nPiperOrigin-RevId: 460978686"
        },
        {
            "Timestamp": "2022-08-31T00:07:31Z",
            "EntityIds": [
                106367904
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "CGGOAWE273F2"
            ],
            "Context": "Add index check to ValidateSparseTensor.. The validation check now verifies all index entries are within correct bounds.\r\nThis is to prevent memory access errors.\r\n\r\nPiperOrigin-RevId: 450695916"
        },
        {
            "Timestamp": "2022-08-31T00:07:31Z",
            "Entity Ids": [
                106367904
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "CGGOAWE273F2",
                "9TXX3YIKXHO8"
            ],
            "Context": "Add index check to ValidateSparseTensor.. The validation check now verifies all index entries are within correct bounds.\r\nThis is to prevent memory access errors.\r\n\r\nPiperOrigin-RevId: 450695916"
        },
        {
            "Timestamp": "2022-08-30T23:44:42Z",
            "EntityIds": [
                106367904
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "R15P3CKDVEIP"
            ],
            "Context": "Add ordered sparse index validation.. Option to check that the indices tensor is lexicographically ordered,\r\nwhich is required by some ops.\r\n\r\nPiperOrigin-RevId: 460978686"
        },
        {
            "Timestamp": "2022-08-30T23:44:42Z",
            "Entity Ids": [
                106367904
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "R15P3CKDVEIP",
                "0HVSA5J9B30V"
            ],
            "Context": "Add ordered sparse index validation.. Option to check that the indices tensor is lexicographically ordered,\r\nwhich is required by some ops.\r\n\r\nPiperOrigin-RevId: 460978686"
        },
        {
            "Timestamp": "2022-08-30T23:07:37Z",
            "EntityIds": [
                106367904
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "UDR300NGRI61"
            ],
            "Context": "Revert \"Add ordered sparse index validation.\". Reverts tensorflow/tensorflow#57542"
        },
        {
            "Timestamp": "2022-08-30T23:07:37Z",
            "Entity Ids": [
                106367904
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "UDR300NGRI61",
                "JQG6O99X0MFV"
            ],
            "Context": "Revert \"Add ordered sparse index validation.\". Reverts tensorflow/tensorflow#57542"
        },
        {
            "Timestamp": "2022-08-30T22:26:22Z",
            "EntityIds": [
                106367904
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "UPUXKNQDXUQH"
            ],
            "Context": "Add index check to ValidateSparseTensor.. The validation check now verifies all index entries are within correct bounds.\r\nThis is to prevent memory access errors.\r\n\r\nPiperOrigin-RevId: 450695916"
        },
        {
            "Timestamp": "2022-08-30T22:26:22Z",
            "Entity Ids": [
                106367904
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "UPUXKNQDXUQH",
                "3MX4ICGW6GEE"
            ],
            "Context": "Add index check to ValidateSparseTensor.. The validation check now verifies all index entries are within correct bounds.\r\nThis is to prevent memory access errors.\r\n\r\nPiperOrigin-RevId: 450695916"
        },
        {
            "Timestamp": "2022-08-30T21:27:46Z",
            "EntityIds": [
                106367904
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "TI3I3AV0FDKA"
            ],
            "Context": "Add ordered sparse index validation.. Option to check that the indices tensor is lexicographically ordered,\r\nwhich is required by some ops.\r\n\r\nPiperOrigin-RevId: 460978686"
        },
        {
            "Timestamp": "2022-08-30T21:27:46Z",
            "Entity Ids": [
                106367904
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "TI3I3AV0FDKA",
                "5RSDAG4NU2VL"
            ],
            "Context": "Add ordered sparse index validation.. Option to check that the indices tensor is lexicographically ordered,\r\nwhich is required by some ops.\r\n\r\nPiperOrigin-RevId: 460978686"
        },
        {
            "Timestamp": "2022-08-30T20:45:31Z",
            "EntityIds": [
                16359713
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "FQVJDBC48K90"
            ],
            "Context": "r2.7 cherry-pick: 5c089662eb7 \"Add ValidateSparseTensor function to sparse_utils.\". Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/5c089662eb7cd1abb76f0687bca8c4f64d8e1fdf"
        },
        {
            "Timestamp": "2022-08-30T20:45:31Z",
            "Entity Ids": [
                16359713
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "FQVJDBC48K90",
                "CZLTD30NRL94"
            ],
            "Context": "r2.7 cherry-pick: 5c089662eb7 \"Add ValidateSparseTensor function to sparse_utils.\". Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/5c089662eb7cd1abb76f0687bca8c4f64d8e1fdf"
        },
        {
            "Timestamp": "2022-08-30T20:33:41Z",
            "EntityIds": [
                41713505,
                84765720
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "7SFNLJTP1EDM"
            ],
            "Context": "Please make different versions of Tensorflow compatible with each other.. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nFeature Request\n\n### Source\n\nsource\n\n### Tensorflow Version\n\nAll versions\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\n_No response_\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n_No response_\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nTensorflow X.11 is completely incompatible with Tensorflow X.12.  If I try to run a colab notebook, and the notebook was written using Tensorflow X.11, but the newest version of Tensorflow is now X.12 or later, then the notebook will not work.  It would be nice to have some consistency between versions so I don't have to know the version of Tensorflow that the notebook was written in to run it.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nLiterally use any notebook more than a year old.\n```\n\n\n### Relevant log output\n\n_No response_</details>"
        },
        {
            "Timestamp": "2022-08-30T20:09:00Z",
            "EntityIds": [
                16359713
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "AQ4UOL893SCG"
            ],
            "Context": "r2.8 cherry-pick: 5c089662eb7 \"Add ValidateSparseTensor function to sparse_utils.\". Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/5c089662eb7cd1abb76f0687bca8c4f64d8e1fdf"
        },
        {
            "Timestamp": "2022-08-30T20:09:00Z",
            "Entity Ids": [
                16359713
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "AQ4UOL893SCG",
                "JZCR17O18JVK"
            ],
            "Context": "r2.8 cherry-pick: 5c089662eb7 \"Add ValidateSparseTensor function to sparse_utils.\". Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/5c089662eb7cd1abb76f0687bca8c4f64d8e1fdf"
        },
        {
            "Timestamp": "2022-08-30T18:29:31Z",
            "EntityIds": [
                16359713
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "KBBI06H4CDRX"
            ],
            "Context": "r2.9 cherry-pick: 5c089662eb7 \"Add ValidateSparseTensor function to sparse_utils.\". Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/5c089662eb7cd1abb76f0687bca8c4f64d8e1fdf"
        },
        {
            "Timestamp": "2022-08-30T18:29:31Z",
            "Entity Ids": [
                16359713
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "KBBI06H4CDRX",
                "3BD479L07MCR"
            ],
            "Context": "r2.9 cherry-pick: 5c089662eb7 \"Add ValidateSparseTensor function to sparse_utils.\". Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/5c089662eb7cd1abb76f0687bca8c4f64d8e1fdf"
        },
        {
            "Timestamp": "2022-08-30T17:25:54Z",
            "EntityIds": [
                86808158,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "NNN2VJVTQOMC"
            ],
            "Context": "Fix duplicate nodes as a result of graph freezing. Updates `_ResourceGather.convert_variable_to_constant` to avoid adding duplicate constant nodes on repeated calls, modifying the existing node instead."
        },
        {
            "Timestamp": "2022-08-30T17:25:54Z",
            "Entity Ids": [
                86808158,
                48215717
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "NNN2VJVTQOMC",
                "1ZEX5AN70BVW"
            ],
            "Context": "Fix duplicate nodes as a result of graph freezing. Updates `_ResourceGather.convert_variable_to_constant` to avoid adding duplicate constant nodes on repeated calls, modifying the existing node instead."
        },
        {
            "Timestamp": "2022-08-30T16:19:53Z",
            "EntityIds": [
                11022453,
                86464649
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "WQTGH0RWV6PW"
            ],
            "Context": "Indentation bug in TensorFlow main expert tutorial. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nDocumentation Bug\n\n### Source\n\nbinary\n\n### Tensorflow Version\n\n2.8\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\n_No response_\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n_No response_\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nThere is an indentation bug in the main Tensorflow expert colab tutorial located here: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb. The code does not run because there is an indentation problem.\r\n\r\n@tf.function\r\ndef train_step(images, labels):\r\n  with tf.GradientTape() as tape:\r\n    # training=True is only needed if there are layers with different\r\n    # behavior during training versus inference (e.g. Dropout).\r\n    predictions = model(images, training=True)\r\n    loss = loss_object(labels, predictions)\r\n  gradients = tape.gradient(loss, model.trainable_variables)  #PROBLEM!!! NEEDS INDENTATION!\r\n  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n\r\n  train_loss(loss)\r\n  train_accuracy(labels, predictions)\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nRun the colab all the way through, and you will see that it chokes on the last step.\r\n\r\nhttps://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb\n```\n\n\n### Relevant log output\n\n_No response_</details>"
        },
        {
            "Timestamp": "2022-08-30T16:13:05Z",
            "EntityIds": [
                108412181,
                84765720
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "NAEK9FEKXK0V"
            ],
            "Context": "Forward gradient does not support `axis=[0]` for `tf.concat`. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nbinary\n\n### Tensorflow Version\n\ntf 2.9.1\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\nLinux Ubuntu 20.04\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n3.9\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nInconsistent `axis` shape check for `tf.concat`: when `axis=[0]`, direct execution and reverse gradient computation both will succeed, but forward gradient does not support it and throws error.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nimport tensorflow as tf\r\n\r\nx = tf.random.uniform([12, 1, 1, 1], minval=0, maxval=2.0, dtype=tf.float32)\r\ny = tf.random.uniform([12, 1, 1, 1], minval=0, maxval=2.0, dtype=tf.float32)\r\naxis = [0]\r\nresult = tf.concat([x, y], axis)\r\nprint(result.shape) # Pass\r\n\r\nwith tf.GradientTape() as tape:\r\n    tape.watch(x)\r\n    result = tf.concat([x, y], axis)\r\nprint(result.shape)\r\nprint(tape.gradient(result, x).shape) # Reverse mode AD pass\r\n\r\ntangent = tf.reshape(tf.one_hot(1, tf.size(x), dtype=x.dtype), shape=x.shape)\r\nwith tf.autodiff.ForwardAccumulator(x, tangent) as acc:\r\n    result = tf.concat([x, y], axis) # Forward mode AD fail\n```\n\n\n### Relevant log output\n\n```shell\n(24, 1, 1, 1) \r\n(24, 1, 1, 1) \r\n(12, 1, 1, 1) \r\nNode: 'gradient_tape/ConcatOffset' \r\nConcat dim tensor should be a scalar integer, but got shape [1] \r\n [[{{node gradient_tape/ConcatOffset}}]] [Op:__inference__jvp_helper_wrapper_78]\n```\n</details>"
        },
        {
            "Timestamp": "2022-08-30T15:49:47Z",
            "EntityIds": [
                108412181,
                81610181
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "YICV3IRMXZ1A"
            ],
            "Context": "`tf.pad` fails when executing in `tf.autodiff.ForwardAccumulator`. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nbinary\n\n### Tensorflow Version\n\ntf 2.9.1\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\nLinux Ubuntu 20.04\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n3.9\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\n`tf.pad` fails when executing in `tf.autodiff.ForwardAccumulator` and throws `TypeError`. However, if we run `tf.pad` outside of `ForwardAccumulator` with the same input, it will pass.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nimport tensorflow as tf\r\n\r\ninput_tensor = tf.random.uniform([3, 1, 1, 1], minval=2.0, maxval=3.0, dtype=tf.float32)\r\npaddings = tf.random.uniform([4, 2], minval=0, maxval=5, dtype=tf.int64) \r\nmode = \"CONSTANT\"\r\nconstant_values = 0 \r\nresult = tf.pad(input_tensor, paddings, mode=mode, constant_values=constant_values, ) \r\nprint(result.shape) # Pass\r\n\r\ntangent = tf.reshape(tf.one_hot(1, tf.size(input_tensor), dtype=input_tensor.dtype), shape=input_tensor.shape)\r\nwith tf.autodiff.ForwardAccumulator(input_tensor, tangent) as acc:\r\n    result = tf.pad(input_tensor, paddings, mode=mode, constant_values=constant_values, ) # Fail\n```\n\n\n### Relevant log output\n\n```shell\n(8, 3, 8, 4)\r\nTypeError: Input 'y' of 'Sub' Op has type int64 that does not match type int32 of argument 'x'.\n```\n</details>"
        },
        {
            "Timestamp": "2022-08-30T15:45:54Z",
            "EntityIds": [
                84091837,
                86464649
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "IJCKK1J6EA50"
            ],
            "Context": "I observe TfLiteXNNPackDelegateDelete is called when disable XNNPACK in Tensorflow Lite. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBuild/Install\n\n### Source\n\nsource\n\n### Tensorflow Version\n\n2.4\n\n### Custom Code\n\nNo\n\n### OS Platform and Distribution\n\nUbuntu 20.04\n\n### Mobile device\n\nARMV7\n\n### Python version\n\n3.8\n\n### Bazel version\n\ncmake instead of bazel\n\n### GCC/Compiler version\n\n9.3.0\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nBuilt tensorflow lite with -DTFLITE_ENABLE_XNNPACK=OFF in cmake, and I got tensorflow-lite library as below.\r\nI expected no XNNPack functions be called, am I right?\r\nIt looks like Macro DTFLITE_WITHOUT_XNNPACK is not working as expected.\r\n\r\n\r\n\r\nThanks.\r\nroro\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nNone, just building issue.\n```\n\n\n### Relevant log output\n\n```shell\n./recipe-sysroot-native/usr/bin/arm-rdkmllib32-linux-gnueabi/arm-rdkmllib32-linux-gnueabi-readelf -a image/usr/lib/libtensorflow-lite.so |grep XNNPack\r\n0025cd28  00008315 R_ARM_GLOB_DAT    00000000   TfLiteXNNPackDelegateD\r\n0025ea44  00008516 R_ARM_JUMP_SLOT   00000000   TfLiteXNNPackDelegateO\r\n0025ea48  00008416 R_ARM_JUMP_SLOT   00000000   TfLiteXNNPackDelegateC\r\n   131: 00000000     0 NOTYPE  GLOBAL DEFAULT  UND TfLiteXNNPackDelegateDele\r\n   132: 00000000     0 NOTYPE  GLOBAL DEFAULT  UND TfLiteXNNPackDelegateCrea\r\n   133: 00000000     0 NOTYPE  GLOBAL DEFAULT  UND TfLiteXNNPackDelegateOpti\r\n  7898: 00000000     0 NOTYPE  GLOBAL DEFAULT  UND TfLiteXNNPackDelegateDele\r\n  7899: 00000000     0 NOTYPE  GLOBAL DEFAULT  UND TfLiteXNNPackDelegateCrea\r\n  7900: 00000000     0 NOTYPE  GLOBAL DEFAULT  UND TfLiteXNNPackDelegateOpti\n```\n</details>"
        },
        {
            "Timestamp": "2022-08-30T14:15:23Z",
            "EntityIds": [
                18442791,
                73069040
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "SEL8KGMIV04C"
            ],
            "Context": "Nonquantized tflite model using tflite_model_maker. ### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installation (pip package or built from source):\r\n- TensorFlow library (version, if pip package or github SHA, if built from source):\r\n\r\n### 2. Code\r\n\r\nmodel.export(export_dir='.', tflite_filename='model_fp16.tflite', quantization_config=config)\r\nHow to convert the trained model to tflite which is not quantized for models trined using tmm.\r\n\r\n#### Option A: Reference colab notebooks\r\n\r\n1)  Reference [TensorFlow Lite Model Colab]: https://www.tensorflow.org/lite/models/modify/model_maker/object_detection(https://colab.research.google.com/gist/ymodak/0dfeb28255e189c5c48d9093f296e9a8/tensorflow-lite-debugger-colab.ipynb): Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).\r\n\r\n"
        },
        {
            "Timestamp": "2022-08-30T14:14:50Z",
            "EntityIds": [
                45662732,
                81610181
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "LMCGA8QSMXIC"
            ],
            "Context": "Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBuild/Install\n\n### Source\n\nsource\n\n### Tensorflow Version\n\ntf 2.9\n\n### Custom Code\n\nNo\n\n### OS Platform and Distribution\n\nwindows 10\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n3.10\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n8.1\n\n### GPU model and memory\n\nA5000 \n\n### Current Behaviour?\n\n```shell\nAfter fresh installition of windows 10 and gpu driver, \r\n\r\nI have followed this installition -> https://www.tensorflow.org/install/pip?hl=en#windows-native\r\n\r\nCreated venv using conda create --name tf python=3.9\r\nThen activated venv and used command conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0\r\nThen used, pip install tensorflow\r\n\r\ntensorflow successfully detects GPU, however when before starting to training, it gave cudart64_110.dll not found error. I confirmed that cudart64_110.dll is exist inside virtual env in local path \"Library\\bin\"\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nconda create --name tf python=3.9\r\nconda activate tf\r\nconda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0\r\npip install tensorflow\r\n\r\ntrain any word2vec/lstm model and error pops\n```\n\n\n### Relevant log output\n\n_No response_</details>"
        },
        {
            "Timestamp": "2022-08-30T14:11:01Z",
            "EntityIds": [
                19678,
                48215717
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "ZEVKIC4MXZMO"
            ],
            "Context": "[mhlo] fix segfault from dereferencing a non-existent value. This patch fixes a runtime segfault caused by calling `value()` on\r\noptional types in the predicate of `if` statements.  This patch replaces\r\nthe predicates with `has_value()` so that dereferencing the values later\r\nis safe.\r\n\r\nThanks to @fortianyou for diagnosing the problem!\r\n\r\ncc: @burmako"
        },
        {
            "Timestamp": "2022-08-30T14:11:01Z",
            "Entity Ids": [
                19678,
                48215717,
                1835471
            ],
            "Symbol": "Pull Request Creation",
            "Relational IDs": [
                "ZEVKIC4MXZMO",
                "1Q9ITG5T4SXR"
            ],
            "Context": "[mhlo] fix segfault from dereferencing a non-existent value. This patch fixes a runtime segfault caused by calling `value()` on\r\noptional types in the predicate of `if` statements.  This patch replaces\r\nthe predicates with `has_value()` so that dereferencing the values later\r\nis safe.\r\n\r\nThanks to @fortianyou for diagnosing the problem!\r\n\r\ncc: @burmako"
        },
        {
            "Timestamp": "2022-08-30T14:04:55Z",
            "EntityIds": [
                45327670,
                84765720
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "2TLK1PA90KJH"
            ],
            "Context": "tf.image.convert_image_dtype dont check the validity of input. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nsource\n\n### Tensorflow Version\n\nTF2.4\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\n_No response_\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n_No response_\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nImages that are represented using floating point values are expected to have values in the range [0,1) on documentation. However, when image is floating point values greater than 1, the code works. It should throw an exception.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nimport tensorflow as tf\r\nresults={}\r\ntry:\r\n  arg_0 = [[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]],[[7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]]\r\n  dtype = tf.uint64\r\n  saturate = False\r\n  results[\"res\"] = tf.image.convert_image_dtype(arg_0,dtype=dtype,saturate=saturate,)\r\nexcept Exception as e:\r\n  results[\"err\"] = \"Error:\"+str(e)\r\nprint(results)\r\n'''\r\n{'res': <tf.Tensor: shape=(2, 2, 3), dtype=uint64, numpy=\r\narray([[[9223372036854775808, 9223372036854775808, 9223372036854775808],\r\n        [9223372036854775808, 9223372036854775808, 9223372036854775808]],\r\n       [[9223372036854775808, 9223372036854775808, 9223372036854775808],\r\n        [9223372036854775808, 9223372036854775808, 9223372036854775808]]],\r\n      dtype=uint64)>}\r\n'''\n```\n\n\n### Relevant log output\n\n_No response_</details>"
        },
        {
            "Timestamp": "2022-08-30T13:55:40Z",
            "EntityIds": [
                37875281,
                84765720
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "1EJ1NDORZU2L"
            ],
            "Context": "\"Segmentation fault\" and \"Floating point exception\" popped up while training using Intel CPUs with oneDNN optimizations enabled. <details><summary>Click to expand!</summary> \r\n \r\n ### Issue Type\r\n\r\nBug\r\n\r\n### Source\r\n\r\nbinary\r\n\r\n### Tensorflow Version\r\n\r\ntf 2.9\r\n\r\n### Custom Code\r\n\r\nNo\r\n\r\n### OS Platform and Distribution\r\n\r\nLinux Ubuntu 18.04\r\n\r\n### Mobile device\r\n\r\n_No response_\r\n\r\n### Python version\r\n\r\n3.7\r\n\r\n### Bazel version\r\n\r\n_No response_\r\n\r\n### GCC/Compiler version\r\n\r\n_No response_\r\n\r\n### CUDA/cuDNN version\r\n\r\n_No response_\r\n\r\n### GPU model and memory\r\n\r\n_No response_\r\n\r\n### Current Behaviour?\r\n\r\n```shell\r\nWhile I trained a 3D-UNet-like model using Intel CPUs with oneDNN optimizations enabled, \r\n\"Segmentation fault\" and \"Floating point exception\" popped up with specific configurations.\r\n\r\nConfig 1:\r\n  Input size: [512, 512, 7, 1] ([H, W, C, N])\r\n  Batch size: 80\r\n  --> Error: Segmentation fault (core dumped)\r\n\r\nConfig 2:\r\n  Input size: [512, 512, 8, 1]\r\n  Batch size: 80\r\n  --> Runs without any error\r\n\r\nConfig 3:\r\n  Input size: [512, 512, 32, 1]\r\n  Batch size: 1, 4, 16 (any of them have the same reuslt)\r\n  --> Error: Floating point exception (core dumped)\r\n```\r\n\r\n\r\n### Standalone code to reproduce the issue\r\n\r\n```shell\r\nThis is the link to the source code:\r\nhttps://drive.google.com/file/d/1NOqcAW8MJU4QnqpnVxYX_C85Kvcb7W05/view?usp=sharing\r\nIt is a zip file with 2 python scripts in it.\r\n\"train.py\" is the script that defines data loader and the train task.\r\n\"unet_3d_layers.py\" is the script that defines the model.\r\n\r\nNote: Because the dataset we're using is private, I used numpy to generate random \r\ntrain data in the source code to reproduce the problem\r\n\r\nTo reproduce:\r\nConfig 1:\r\n  1. Open train.py\r\n  2. Uncomment line 17, 41, and 42\r\n  3. Comment line 18, 19, 44, 45, 47, and 48\r\n  4. In the terminal, run \"python train.py\" to run the code\r\n\r\nConfig 2:\r\n  1. Open train.py\r\n  2. Uncomment line 18, 44, and 45\r\n  3. Comment line 17, 19, 41, 42, 47, and 48\r\n  4. In the terminal, run \"python train.py\" to run the code\r\n\r\nConfig 3:\r\n  1. Open train.py\r\n  2. Uncomment line 19, 47, and 48\r\n  3. Modify the variable \"batch_size\" in line 48\r\n  4. Comment line 17, 18, 41, 42, 44, and 45\r\n  5. In the terminal, run \"python train.py\" to run the code\r\n```\r\n\r\n\r\n### Relevant log output\r\n\r\nSegmentation fault:\r\n```shell\r\n2022-08-31 10:29:25.997447: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\r\n2022-08-31 10:29:26.001968: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2022-08-31 10:29:26.001989: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2022-08-31 10:29:27.476182: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2022-08-31 10:29:27.476213: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\r\n2022-08-31 10:29:27.476230: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (user-COB-1932C): /proc/driver/nvidia/version does not exist\r\n2022-08-31 10:29:27.476445: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nEpoch 1/10\r\n2022-08-31 10:29:31.296605: W tensorflow/core/common_runtime/forward_type_inference.cc:231] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\r\ntype_id: TFT_OPTIONAL\r\nargs {\r\n  type_id: TFT_PRODUCT\r\n  args {\r\n    type_id: TFT_TENSOR\r\n    args {\r\n      type_id: TFT_BOOL\r\n    }\r\n  }\r\n}\r\n is neither a subtype nor a supertype of the combined inputs preceding it:\r\ntype_id: TFT_OPTIONAL\r\nargs {\r\n  type_id: TFT_PRODUCT\r\n  args {\r\n    type_id: TFT_TENSOR\r\n    args {\r\n      type_id: TFT_LEGACY_VARIANT\r\n    }\r\n  }\r\n}\r\n\r\n\twhile inferring type of node 'dice_loss/cond/output/_11'\r\n 2/40 [>.............................] - ETA: 29:12 - loss: 2.1932Segmentation fault (core dumped)\r\n```\r\nFloating point exception:\r\n```shell\r\n2022-08-31 10:27:02.379986: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\r\n2022-08-31 10:27:02.384512: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2022-08-31 10:27:02.384533: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2022-08-31 10:27:03.883968: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2022-08-31 10:27:03.883996: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\r\n2022-08-31 10:27:03.884012: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (user-COB-1932C): /proc/driver/nvidia/version does not exist\r\n2022-08-31 10:27:03.884231: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nEpoch 1/10\r\n2022-08-31 10:27:07.807669: W tensorflow/core/common_runtime/forward_type_inference.cc:231] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\r\ntype_id: TFT_OPTIONAL\r\nargs {\r\n  type_id: TFT_PRODUCT\r\n  args {\r\n    type_id: TFT_TENSOR\r\n    args {\r\n      type_id: TFT_BOOL\r\n    }\r\n  }\r\n}\r\n is neither a subtype nor a supertype of the combined inputs preceding it:\r\ntype_id: TFT_OPTIONAL\r\nargs {\r\n  type_id: TFT_PRODUCT\r\n  args {\r\n    type_id: TFT_TENSOR\r\n    args {\r\n      type_id: TFT_LEGACY_VARIANT\r\n    }\r\n  }\r\n}\r\n\r\n\twhile inferring type of node 'dice_loss/cond/output/_11'\r\nFloating point exception (core dumped)\r\n```\r\n</details>"
        },
        {
            "Timestamp": "2022-08-30T13:54:54Z",
            "EntityIds": [
                45327670,
                81610181
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "FRQA73993R2U"
            ],
            "Context": "when dtype is tf.uint64, tf.image.convert_image_dtype throws exception. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nsource\n\n### Tensorflow Version\n\nTF2.4\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\n_No response_\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n_No response_\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\ntf.image.convert_image_dtype supports data types (for image and dtype) of uint8, uint16, uint32, uint64, int8, int16, int32, int64, float16, float32, float64, bfloat16. But when dtype is uint64, it throws exception.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nimport tensorflow as tf\r\nresults={}\r\ntry:\r\n  arg_0 = [[[1, 2, 3], [4, 5, 6]],[[7, 8, 9], [10, 11, 12]]]\r\n  dtype = tf.uint64\r\n  saturate = False\r\n  results[\"res\"] = tf.image.convert_image_dtype(arg_0,dtype=dtype,saturate=saturate,)\r\nexcept Exception as e:\r\n  results[\"err\"] = \"Error:\"+str(e)\r\nprint(results)\r\n'''\r\n{'err': \"Error:Value for attr 'T' of uint64 is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, int64, complex64, complex128\\n\\t; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul]\"}\r\n'''\n```\n\n\n### Relevant log output\n\n_No response_</details>"
        },
        {
            "Timestamp": "2022-08-30T12:42:08Z",
            "EntityIds": [
                45327670,
                84765720
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "EC1BBSCME3IR"
            ],
            "Context": "When input is a tensor, the 'axis' is not type checked in tf.concat. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nsource\n\n### Tensorflow Version\n\nTF2.8\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\n_No response_\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n_No response_\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nAxis must be in the range [-rank(values), rank(values)) written on documentation [https://tensorflow.google.cn/versions/r2.4/api_docs/python/tf/concat#args]. When input is a list of tensor, axis will validate the range. However, when input is a single tensor, axis won't check the range.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nimport tensorflow as tf\r\nt1 = [[[1, 2], [2, 3]], [[4, 4], [5, 3]]]\r\nt2 = [[[7, 4], [8, 4]], [[2, 10], [15, 11]]]\r\nres = tf.concat([t1, t2], -100)\r\nprint(res)\r\n'''\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Expected concatenating dimensions in the range [-3, 3), but got -100 [Op:ConcatV2]\r\n'''\r\n\r\nAbove code will check the validity of axis, but the following code wont.\r\n\r\nimport tensorflow as tf\r\nresults={}\r\ntry:\r\n  arg_0 = tf.saturate_cast(tf.random.uniform([2, 4], minval=-256, maxval=257, dtype=tf.int64), dtype=tf.int64)\r\n  axis = -200\r\n  results[\"res\"] = tf.concat(arg_0,axis=axis,)\r\nexcept Exception as e:\r\n  results[\"err\"] = \"Error:\"+str(e)\r\nprint(results)\r\n'''\r\n{'res': <tf.Tensor: shape=(2, 4), dtype=int64, numpy=\r\narray([[ 140,  236, -151,   66],\r\n       [ 154,   28,  -82,   23]])>}\r\n'''\n```\n\n\n### Relevant log output\n\n_No response_</details>"
        },
        {
            "Timestamp": "2022-08-30T12:18:29Z",
            "EntityIds": [
                45327670,
                84765720
            ],
            "Symbol": "Issue Creation",
            "Relational ID": [
                "1SMAFKQ94Q0N"
            ],
            "Context": "tf.clip_by_norm documentation wrong. <details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nDocumentation Bug\n\n### Source\n\nsource\n\n### Tensorflow Version\n\nTF2.8\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\n_No response_\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n_No response_\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nclip_norm should be a 0-D (scalar) Tensor > 0 written on documentation https://tensorflow.google.cn/versions/r2.4/api_docs/python/tf/clip_by_norm#args. However, when the clip_norm is a negative integral, the code works.\n```\n\n\n### Standalone code to reproduce the issue\n\n```shell\nimport tensorflow as tf\r\nresults={}\r\ntry:\r\n  arg_0 = tf.random.uniform([1, 5], dtype=tf.float32)\r\n  results[\"res\"] = tf.clip_by_norm(arg_0,clip_norm=-1)\r\nexcept Exception as e:\r\n  results[\"err\"] = \"Error:\"+str(e)\r\nprint(results)\r\n'''\r\n{'res': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\r\narray([[-0.54458696, -0.59545624, -0.31598726, -0.20027176, -0.4570559 ]],dtype=float32)>}\r\n'''\n```\n\n\n### Relevant log output\n\n_No response_</details>"
        }
    ]
}